<!-- prettier-ignore -->

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.rllib.algorithms.impala.impala &#8212; Ray 3.0.0.dev0</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../../../../../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../../../../../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../../../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/css/termynal.css?v=2fc3cb5e" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/css/csat.css?v=c8f39c76" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/css/assistant.css?v=d345c55e" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/css/dismissable-banner.css?v=8dc8f27e" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/css/custom.css?v=93e2ace9" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/docsearch.css?v=45fb5152" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/pydata-docsearch-custom.css?v=7fb92720" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../../../../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script src="../../../../../_static/documentation_options.js?v=d1493c90"></script>
    <script src="../../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../../_static/copybutton.js?v=9a29e97e"></script>
    <script defer="defer" src="../../../../../_static/js/termynal.js?v=67cfcf08"></script>
    <script defer="defer" src="../../../../../_static/js/custom.js?v=dda55d6b"></script>
    <script defer="defer" src="../../../../../_static/js/csat.js?v=b1216bff"></script>
    <script defer="defer" src="../../../../../_static/js/assistant.js?v=73fdc522"></script>
    <script defer="defer" src="../../../../../_static/js/dismissable-banner.js?v=87d30ac4"></script>
    <script defer="defer" src="../../../../../_static/docsearch.js?v=77274085"></script>
    <script defer="defer" src="../../../../../_static/docsearch_config.js?v=d25523ed"></script>
    <script src="../../../../../_static/design-tabs.js?v=36754332"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/ray/rllib/algorithms/impala/impala';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.14.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://antgroup.github.io/ant-ray/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'main';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = false;
        </script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/rllib/algorithms/impala/impala.html" />
    <link rel="icon" href="../../../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../../../genindex.html" /><!-- Extra header to include at the top of each template.
Kept separately so that it can easily be included in any templates
that need to be overridden for individual pages; e.g. included
both in the usual template (layout.html) as well as (index.html). -->

<link rel="preconnect" href="https://fonts.googleapis.com" />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link
  href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;900&family=Roboto:wght@400;500;700&display=swap"
  rel="stylesheet"
/>
<link
  rel="stylesheet"
  title="light"
  href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
  disabled="disabled"
/>
<link
  rel="stylesheet"
  title="dark"
  href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css"
  disabled="disabled"
/>
<link
  href="https://cdn.jsdelivr.net/npm/remixicon@4.1.0/fonts/remixicon.css"
  rel="stylesheet"
/>

<!-- Used for text embedded in html on the index page  -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- Parser used to call hljs on responses from Ray Assistant -->
<script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

<!-- Sanitizer for Ray Assistant AI -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/dompurify/2.3.3/purify.min.js"></script>

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<!-- Google Tag Manager -->
<script>
  (function (w, d, s, l, i) {
    w[l] = w[l] || [];
    w[l].push({
      'gtm.start': new Date().getTime(),
      event: 'gtm.js',
    });
    var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s),
      dl = l != 'dataLayer' ? '&l=' + l : '';
    j.async = true;
    j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
    f.parentNode.insertBefore(j, f);
  })(window, document, 'script', 'dataLayer', 'GTM-N7VD67MZ');
</script>
<!-- End Google Tag Manager -->

<!-- Data to be shared with JS on every page -->
<script>
  window.data = {
      copyIconSrc: "../../../../../_static/copy-button.svg"
  };
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>


  <div class="bd-header-announcement container-fluid bd-header-announcement">
    <div class="bd-header-announcement__content">Join us at Ray Summit 2025 — <a target="_blank" href="https://www.anyscale.com/ray-summit/2025?utm_source=ray_docs&utm_medium=docs&utm_campaign=banner">Register early and save.</a><button type="button" id="close-banner" aria-label="Close banner">&times;</button></div>
  </div>

  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../../../../index.html">
  <svg width="400" height="201" viewBox="0 0 400 201" xmlns="http://www.w3.org/2000/svg">
<path id="ray-text" d="M325.949 134.356V109.785L302.442 66.6406H314.244L330.495 97.3062H331.946L348.198 66.6406H360L336.493 109.785V134.356H325.949ZM253.043 134.364L272.391 66.648H290.771L310.021 134.364H299.283L294.834 118.402H268.328L263.878 134.364H253.043ZM270.94 108.728H292.222L282.354 73.1294H280.807L270.94 108.728ZM198.887 134.364V66.648H227.327C231.519 66.648 235.195 67.3896 238.355 68.8729C241.58 70.2918 244.063 72.3555 245.804 75.0641C247.61 77.7727 248.513 80.9973 248.513 84.7378V85.8019C248.513 90.0583 247.481 93.4763 245.417 96.0559C243.418 98.5711 240.967 100.345 238.065 101.376V102.924C240.516 103.053 242.483 103.892 243.966 105.439C245.449 106.923 246.191 109.083 246.191 111.921V134.364H235.647V113.372C235.647 111.631 235.195 110.244 234.292 109.212C233.39 108.18 231.938 107.664 229.939 107.664H209.334V134.364H198.887ZM209.334 98.1842H226.166C229.907 98.1842 232.809 97.249 234.873 95.3788C236.937 93.4441 237.968 90.8322 237.968 87.5431V86.7692C237.968 83.4802 236.937 80.9005 234.873 79.0303C232.874 77.0956 229.971 76.1282 226.166 76.1282H209.334V98.1842Z" fill="black"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M143.63 101.311L98.3087 146.632L94.9903 143.313L140.311 97.9925L143.63 101.311ZM141.953 102.334L51.4454 102.334V97.6409L141.953 97.6409V102.334ZM94.992 55.9863L140.313 101.307L143.631 97.9886L98.3105 52.6679L94.992 55.9863Z" fill="#02A0CF"/>
<path d="M40 88.3163H62.6604V110.977H40V88.3163ZM85.3207 88.3163H107.981V110.977H85.3207V88.3163ZM85.3207 43H107.981V65.6604H85.3207V43ZM85.3207 133.645H107.981V156.306H85.3207V133.645ZM130.641 88.3163H153.301V110.977H130.641V88.3163Z" fill="#02A0CF"/>
</svg>

</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <div class="navbar-content docutils container">
<ul class="navbar-toplevel">
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/getting-started.html" title="Get Started"><span class="navbar-link-title">Get Started</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/use-cases.html" title="Use Cases"><span class="navbar-link-title">Use Cases</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/examples.html" title="Example Gallery"><span class="navbar-link-title">Example Gallery</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/installation.html" title="Library"><span class="navbar-link-title">Library</span></a></p>
<i class="fa-solid fa-chevron-down"></i></div>
<div class="navbar-dropdown docutils container">
<ul class="navbar-sublevel">
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-core/walkthrough.html" title="Ray Core"><span class="navbar-link-title">Ray Core</span>Scale general Python applications</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../data/data.html" title="Ray Data"><span class="navbar-link-title">Ray Data</span>Scale data ingest and preprocessing</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../train/train.html" title="Ray Train"><span class="navbar-link-title">Ray Train</span>Scale machine learning training</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../tune/index.html" title="Ray Tune"><span class="navbar-link-title">Ray Tune</span>Scale hyperparameter tuning</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../serve/index.html" title="Ray Serve"><span class="navbar-link-title">Ray Serve</span>Scale model serving</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../rllib/index.html" title="Ray RLlib"><span class="navbar-link-title">Ray RLlib</span>Scale reinforcement learning</a></p>
</div>
</li>
</ul>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../index.html" title="Docs"><span class="navbar-link-title">Docs</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://discuss.ray.io" title="Resources"><span class="navbar-link-title">Resources</span></a></p>
<i class="fa-solid fa-chevron-down"></i></div>
<div class="navbar-dropdown docutils container">
<ul class="navbar-sublevel">
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://discuss.ray.io" title="Discussion Forum"><span class="navbar-link-title">Discussion Forum</span>Get your Ray questions answered</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://github.com/ray-project/ray-educational-materials" title="Training"><span class="navbar-link-title">Training</span>Hands-on learning</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/blog" title="Blog"><span class="navbar-link-title">Blog</span>Updates, best practices, user-stories</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/events" title="Events"><span class="navbar-link-title">Events</span>Webinars, meetups, office hours</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/blog/how-ray-and-anyscale-make-it-easy-to-do-massive-scale-machine-learning-on" title="Success Stories"><span class="navbar-link-title">Success Stories</span>Real-world workload examples</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/ray-libraries.html" title="Ecosystem"><span class="navbar-link-title">Ecosystem</span>Libraries integrated with Ray</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.ray.io/community" title="Community"><span class="navbar-link-title">Community</span>Connect with us</a></p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>

</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          <div id="docsearch"></div>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="versionswitcherbutton" type="button" role="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-bs-toggle="dropdown" aria-haspopup="listbox" aria-controls="versionswitcherlist" aria-label="Version switcher list">
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="versionswitcherlist" class="version-switcher__menu dropdown-menu list-group-flush py-0" role="listbox" aria-labelledby="versionswitcherbutton">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
      
        <div class="navbar-item"><a
  id="try-anyscale-href"
  href="https://console.anyscale.com/register/ha?render_flow=ray&utm_source=ray_docs&utm_medium=docs&utm_campaign=navbar"
  target="_blank"
  rel="noopener noreferrer"
>
  <div id="try-anyscale-text">
    <span>Try Managed Ray</span>
  </div>
</a></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile"><div id="docsearch"></div>
    </div>
  

  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <div class="navbar-content docutils container">
<ul class="navbar-toplevel">
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/getting-started.html" title="Get Started"><span class="navbar-link-title">Get Started</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/use-cases.html" title="Use Cases"><span class="navbar-link-title">Use Cases</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/examples.html" title="Example Gallery"><span class="navbar-link-title">Example Gallery</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/installation.html" title="Library"><span class="navbar-link-title">Library</span></a></p>
<i class="fa-solid fa-chevron-down"></i></div>
<div class="navbar-dropdown docutils container">
<ul class="navbar-sublevel">
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-core/walkthrough.html" title="Ray Core"><span class="navbar-link-title">Ray Core</span>Scale general Python applications</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../data/data.html" title="Ray Data"><span class="navbar-link-title">Ray Data</span>Scale data ingest and preprocessing</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../train/train.html" title="Ray Train"><span class="navbar-link-title">Ray Train</span>Scale machine learning training</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../tune/index.html" title="Ray Tune"><span class="navbar-link-title">Ray Tune</span>Scale hyperparameter tuning</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../serve/index.html" title="Ray Serve"><span class="navbar-link-title">Ray Serve</span>Scale model serving</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../rllib/index.html" title="Ray RLlib"><span class="navbar-link-title">Ray RLlib</span>Scale reinforcement learning</a></p>
</div>
</li>
</ul>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../index.html" title="Docs"><span class="navbar-link-title">Docs</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://discuss.ray.io" title="Resources"><span class="navbar-link-title">Resources</span></a></p>
<i class="fa-solid fa-chevron-down"></i></div>
<div class="navbar-dropdown docutils container">
<ul class="navbar-sublevel">
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://discuss.ray.io" title="Discussion Forum"><span class="navbar-link-title">Discussion Forum</span>Get your Ray questions answered</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://github.com/ray-project/ray-educational-materials" title="Training"><span class="navbar-link-title">Training</span>Hands-on learning</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/blog" title="Blog"><span class="navbar-link-title">Blog</span>Updates, best practices, user-stories</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/events" title="Events"><span class="navbar-link-title">Events</span>Webinars, meetups, office hours</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/blog/how-ray-and-anyscale-make-it-easy-to-do-massive-scale-machine-learning-on" title="Success Stories"><span class="navbar-link-title">Success Stories</span>Real-world workload examples</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/ray-libraries.html" title="Ecosystem"><span class="navbar-link-title">Ecosystem</span>Libraries integrated with Ray</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.ray.io/community" title="Community"><span class="navbar-link-title">Community</span>Connect with us</a></p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>

</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="versionswitcherbutton" type="button" role="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-bs-toggle="dropdown" aria-haspopup="listbox" aria-controls="versionswitcherlist" aria-label="Version switcher list">
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="versionswitcherlist" class="version-switcher__menu dropdown-menu list-group-flush py-0" role="listbox" aria-labelledby="versionswitcherbutton">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
        
          <div class="navbar-item"><a
  id="try-anyscale-href"
  href="https://console.anyscale.com/register/ha?render_flow=ray&utm_source=ray_docs&utm_medium=docs&utm_campaign=navbar"
  target="_blank"
  rel="noopener noreferrer"
>
  <div id="try-anyscale-text">
    <span>Try Managed Ray</span>
  </div>
</a></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><nav id="main-sidebar" class="bd-docs-nav bd-links" aria-label="Section Navigation">
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-overview/index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-overview/getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-overview/installation.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../ray-overview/use-cases.html">Use Cases</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-air/getting-started.html">Ray for ML Infrastructure</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../ray-overview/examples/index.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-multimodal-ai-workloads/README.html">Multi-modal AI pipeline</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-multimodal-ai-workloads/notebooks/01-Batch-Inference.html">Batch inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-multimodal-ai-workloads/notebooks/02-Distributed-Training.html">Distributed training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-multimodal-ai-workloads/notebooks/03-Online-Serving.html">Online serving</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-overview/examples/entity-recognition-with-llms/README.html">LLM training and inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-audio/README.html">Audio batch inference</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-xgboost/README.html">Distributed XGBoost pipeline</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-xgboost/notebooks/01-Distributed_Training.html">Distributed training of an XGBoost model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-xgboost/notebooks/02-Validation.html">Model validation using offline batch inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-xgboost/notebooks/03-Serving.html">Scalable online XGBoost inference with Ray Serve</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-timeseries/README.html">Time-series forecasting</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-timeseries/e2e_timeseries/01-Distributed-Training.html">Distributed training of a DLinear time-series model</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-timeseries/e2e_timeseries/02-Validation.html">DLinear model validation using offline batch inference</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-timeseries/e2e_timeseries/03-Serving.html">Online serving for DLinear model using Ray Serve</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-overview/examples/object-detection/README.html">Scalable video processing</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/object-detection/1.object_detection_train.html">Fine-tuning a face mask detection model with Faster R-CNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/object-detection/2.object_detection_batch_inference_eval.html">Object detection batch inference on test dataset and metrics calculation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/object-detection/3.video_processing_batch_inference.html">Video processing with object detection using batch inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/object-detection/4.object_detection_serve.html">Host an object detection model as a service</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-rag/README.html">Distributed RAG pipeline</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-rag/notebooks/01_%28Optional%29_Regular_Document_Processing_Pipeline.html">Build a Regular RAG Document Ingestion Pipeline  (No Ray required)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-rag/notebooks/02_Scalable_RAG_Data_Ingestion_with_Ray_Data.html">Scalable RAG Data Ingestion and Pagination with Ray Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-rag/notebooks/03_Deploy_LLM_with_Ray_Serve.html">Deploy LLM with Ray Serve LLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-rag/notebooks/04_Build_Basic_RAG_Chatbot.html">Build Basic RAG App</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-rag/notebooks/05_Improve_RAG_with_Prompt_Engineering.html">Improve RAG with Prompt Engineering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-rag/notebooks/06_%28Optional%29_Evaluate_RAG_with_Online_Inference.html">Evaluate RAG with Online Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/e2e-rag/notebooks/07_Evaluate_RAG_with_Ray_Data_LLM_Batch_inference.html">Evaluate RAG using Batch Inference with Ray Data LLM</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-overview/examples/mcp-ray-serve/README.html">Deploy MCP servers</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/mcp-ray-serve/01%20Deploy_custom_mcp_in_streamable_http_with_ray_serve.html">Deploying a custom MCP in Streamable HTTP mode with Ray Serve</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/mcp-ray-serve/02%20Build_mcp_gateway_with_existing_ray_serve_apps.html">Deploy an MCP Gateway with existing Ray Serve apps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/mcp-ray-serve/03%20Deploy_single_mcp_stdio_docker_image_with_ray_serve.html">Deploying an MCP STDIO Server as a scalable HTTP service with Ray Serve</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/mcp-ray-serve/04%20Deploy_multiple_mcp_stdio_docker_images_with_ray_serve.html">Deploying multiple MCP services with Ray Serve</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-overview/examples/mcp-ray-serve/05%20%28Optional%29%20Build_docker_image_for_mcp_server.html">Build a Docker image for an MCP server</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-overview/ray-libraries.html">Ecosystem</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../ray-core/walkthrough.html">Ray Core</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-core/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-core/user-guide.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/tasks.html">Tasks</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/tasks/nested-tasks.html">Nested Remote Functions</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/actors.html">Actors</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/named-actors.html">Named Actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/terminating-actors.html">Terminating Actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/async_api.html">AsyncIO / Concurrency for Actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/concurrency_group_api.html">Limiting Concurrency Per-Method with Concurrency Groups</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/actor-utils.html">Utility Classes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/out-of-band-communication.html">Out-of-band Communication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/task-orders.html">Actor Task Execution Order</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/objects.html">Objects</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/objects/serialization.html">Serialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/objects/object-spilling.html">Object Spilling</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/handling-dependencies.html">Environment Dependencies</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/scheduling/index.html">Scheduling</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/scheduling/labels.html">Use labels to control scheduling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/scheduling/resources.html">Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/scheduling/accelerators.html">Accelerator Support</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/scheduling/placement-group.html">Placement Groups</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/scheduling/memory-management.html">Memory Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/scheduling/ray-oom-prevention.html">Out-Of-Memory Prevention</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/fault-tolerance.html">Fault tolerance</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/fault_tolerance/tasks.html">Task Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/fault_tolerance/actors.html">Actor Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/fault_tolerance/objects.html">Object Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/fault_tolerance/nodes.html">Node Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/fault_tolerance/gcs.html">GCS Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/fault_tolerance/head-ha.html">Head High-Availability Feature</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/patterns/index.html">Design Patterns &amp; Anti-patterns</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/nested-tasks.html">Pattern: Using nested tasks to achieve nested parallelism</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/generators.html">Pattern: Using generators to reduce heap memory usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/limit-pending-tasks.html">Pattern: Using ray.wait to limit the number of pending tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/limit-running-tasks.html">Pattern: Using resources to limit the number of concurrently running tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/concurrent-operations-async-actor.html">Pattern: Using asyncio to run actor methods concurrently</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/actor-sync.html">Pattern: Using an actor to synchronize other tasks and actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/tree-of-actors.html">Pattern: Using a supervisor actor to manage a tree of actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/pipelining.html">Pattern: Using pipelining to increase throughput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/return-ray-put.html">Anti-pattern: Returning ray.put() ObjectRefs from a task harms performance and fault tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/nested-ray-get.html">Anti-pattern: Calling ray.get on task arguments harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/ray-get-loop.html">Anti-pattern: Calling ray.get in a loop harms parallelism</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/unnecessary-ray-get.html">Anti-pattern: Calling ray.get unnecessarily harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/ray-get-submission-order.html">Anti-pattern: Processing results in submission order using ray.get increases runtime</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/ray-get-too-many-objects.html">Anti-pattern: Fetching too many objects at once with ray.get causes failure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/too-fine-grained-tasks.html">Anti-pattern: Over-parallelizing with too fine-grained tasks harms speedup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/redefine-task-actor-loop.html">Anti-pattern: Redefining the same remote function or class harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/pass-large-arg-by-value.html">Anti-pattern: Passing the same large argument by value repeatedly harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/closure-capture-large-objects.html">Anti-pattern: Closure capturing large objects harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/global-variables.html">Anti-pattern: Using global variables to share state between tasks and actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/out-of-band-object-ref-serialization.html">Anti-pattern: Serialize ray.ObjectRef out of band</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/fork-new-processes.html">Anti-pattern: Forking new processes in application code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/direct-transport.html">Ray Direct Transport (RDT)</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/compiled-graph/ray-compiled-graph.html">Ray Compiled Graph (beta)</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/compiled-graph/quickstart.html">Quickstart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/compiled-graph/profiling.html">Profiling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/compiled-graph/overlap.html">Experimental: Overlapping communication and computation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/compiled-graph/troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/compiled-graph/compiled-graph-api.html">Compiled Graph API</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/advanced-topics.html">Advanced topics</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/tips-for-first-time.html">Tips for first-time users</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/type-hint.html">Type hints in Ray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/starting-ray.html">Starting Ray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/ray-generator.html">Ray Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/namespaces.html">Using Namespaces</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/cross-language.html">Cross-language programming</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/using-ray-with-jupyter.html">Working with Jupyter Notebooks &amp; JupyterLab</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/ray-dag.html">Lazy Computation Graphs with the Ray DAG API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/miscellaneous.html">Miscellaneous Topics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/runtime_env_auth.html">Authenticating Remote URIs in runtime_env</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/user-spawn-processes.html">Lifetimes of a User-Spawn Process</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-core/examples/overview.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/batch_prediction.html">Batch Prediction with Ray Core</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/gentle_walkthrough.html">A Gentle Introduction to Ray Core by Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/highly_parallel.html">Using Ray for Highly Parallelizable Tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/map_reduce.html">A Simple MapReduce Example with Ray Core</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/monte_carlo_pi.html">Monte Carlo Estimation of π</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/plot_hyperparameter.html">Simple Parallel Model Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/plot_parameter_server.html">Parameter Server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/plot_pong_example.html">Learning to Play Pong</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/web_crawler.html">Speed up your web crawler by parallelizing it with Ray</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-core/api/index.html">Ray Core API</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/core.html">Core API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/scheduling.html">Scheduling API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/runtime-env.html">Runtime Env API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/utility.html">Utility</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/exceptions.html">Exceptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/cli.html">Ray Core CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/reference/cli.html">State CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/reference/api.html">State API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/direct-transport.html">Ray Direct Transport (RDT) API</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-core/internals.html">Internals</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/internals/task-lifecycle.html">Task Lifecycle</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/internals/autoscaler-v2.html">Autoscaler v2</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../data/data.html">Ray Data</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../data/quickstart.html">Ray Data Quickstart</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../data/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../data/user-guide.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/loading-data.html">Loading Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/inspecting-data.html">Inspecting Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/transforming-data.html">Transforming Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/iterating-over-data.html">Iterating over Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/joining-data.html">Joining datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/shuffling-data.html">Shuffling Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/saving-data.html">Saving Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/working-with-images.html">Working with Images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/working-with-text.html">Working with Text</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/working-with-tensors.html">Working with Tensors / NumPy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/working-with-pytorch.html">Working with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/working-with-llms.html">Working with LLMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/monitoring-your-workload.html">Monitoring Your Workload</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/execution-configurations.html">Execution Configurations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/batch_inference.html">End-to-end: Offline Batch Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/performance-tips.html">Advanced: Performance Tips and Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/custom-datasource-example.html">Advanced: Read and Write Custom File Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/aggregations.html">Aggregations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../data/examples.html">Examples</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../data/api/api.html">Ray Data API</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/input_output.html">Input/Output</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/dataset.html">Dataset API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/data_iterator.html">DataIterator API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/execution_options.html">ExecutionOptions API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/aggregate.html">Aggregation API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/grouped_data.html">GroupedData API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/expressions.html">Expressions API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/datatype.html">Data types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/data_context.html">Global configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/preprocessor.html">Preprocessor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/llm.html">Large Language Model (LLM) API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/from_other_data_libs.html">API Guide for Users from Other Data Libraries</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../data/comparisons.html">Comparing Ray Data to other systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../data/benchmark.html">Ray Data Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../data/data-internals.html">Ray Data Internals</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../train/train.html">Ray Train</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/getting-started-pytorch.html">PyTorch Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/getting-started-pytorch-lightning.html">PyTorch Lightning Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/getting-started-transformers.html">Hugging Face Transformers Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/getting-started-xgboost.html">XGBoost Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/getting-started-jax.html">JAX Guide</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../train/more-frameworks.html">More Frameworks</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/huggingface-accelerate.html">Hugging Face Accelerate Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/deepspeed.html">DeepSpeed Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/distributed-tensorflow-keras.html">TensorFlow and Keras Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/getting-started-lightgbm.html">LightGBM Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/horovod.html">Horovod Guide</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../train/user-guides.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/data-loading-preprocessing.html">Data Loading and Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/using-gpus.html">Configuring Scale and GPUs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/persistent-storage.html">Configuring Persistent Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/monitoring-logging.html">Monitoring and Logging Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/checkpoints.html">Saving and Loading Checkpoints</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/asynchronous-validation.html">Validating checkpoints asynchronously</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/experiment-tracking.html">Experiment Tracking</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/results.html">Inspecting Training Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/fault-tolerance.html">Handling Failures and Node Preemption</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/reproducibility.html">Reproducibility</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/hyperparameter-optimization.html">Hyperparameter Optimization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/benchmarks.html">Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/api/api.html">Ray Train API</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../tune/index.html">Ray Tune</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../tune/getting-started.html">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../tune/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../tune/tutorials/overview.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-run.html">Running Basic Experiments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-output.html">Logging and Outputs in Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-resources.html">Setting Trial Resources</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-search-spaces.html">Using Search Spaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-stopping.html">How to Define Stopping Criteria for a Ray Tune Experiment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-trial-checkpoints.html">How to Save and Load Trial Checkpoints</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-storage.html">How to Configure Persistent Storage in Ray Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-fault-tolerance.html">How to Enable Fault Tolerance in Ray Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-metrics.html">Using Callbacks and Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune_get_data_in_and_out.html">Getting Data in and out of Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/tune_analyze_results.html">Analyzing Tune Experiment Results</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../tune/examples/pbt_guide.html">A Guide to Population Based Training with Tune</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/pbt_visualization/pbt_visualization.html">Visualizing and Understanding PBT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-distributed.html">Deploying Tune in the Cloud</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-lifecycle.html">Tune Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-scalability.html">Scalability Benchmarks</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../tune/examples/index.html">Ray Tune Examples</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-31"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/tune-pytorch-cifar.html">PyTorch Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/tune-pytorch-lightning.html">PyTorch Lightning Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/tune-xgboost.html">XGBoost Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/lightgbm_example.html">LightGBM Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/pbt_transformers.html">Hugging Face Transformers Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/pbt_ppo_example.html">Ray RLlib Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/tune_mnist_keras.html">Keras Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/tune-wandb.html">Weights &amp; Biases Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/tune-mlflow.html">MLflow Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/tune-aim.html">Aim Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/tune-comet.html">Comet Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/ax_example.html">Ax Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/hyperopt_example.html">HyperOpt Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/bayesopt_example.html">Bayesopt Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/bohb_example.html">BOHB Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/nevergrad_example.html">Nevergrad Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/optuna_example.html">Optuna Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../tune/faq.html">Ray Tune FAQ</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../tune/api/api.html">Ray Tune API</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-32"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/execution.html">Tune Execution (tune.Tuner)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/result_grid.html">Tune Experiment Results (tune.ResultGrid)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/trainable.html">Training in Tune (tune.Trainable, tune.report)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/search_space.html">Tune Search Space API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/suggestion.html">Tune Search Algorithms (tune.search)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/schedulers.html">Tune Trial Schedulers (tune.schedulers)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/stoppers.html">Tune Stopping Mechanisms (tune.stopper)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/reporters.html">Tune Console Output (Reporters)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/syncing.html">Syncing in Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/logging.html">Tune Loggers (tune.logger)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/callbacks.html">Tune Callbacks (tune.Callback)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/env.html">Environment variables used by Ray Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/integration.html">External library integrations for Ray Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/internals.html">Tune Internals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/cli.html">Tune CLI (Experimental)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../serve/index.html">Ray Serve</a><input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-33"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/getting_started.html">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/develop-and-deploy.html">Develop and Deploy an ML Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/model_composition.html">Deploy Compositions of Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/multi-app.html">Deploy Multiple Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/model-multiplexing.html">Model Multiplexing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/configure-serve-deployment.html">Configure Ray Serve deployments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/http-guide.html">Set Up FastAPI and HTTP</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../serve/llm/index.html">Serving LLMs</a><input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-34"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/llm/quick-start.html">Quickstart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/llm/examples.html">Examples</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../serve/llm/user-guides/index.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-35"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/user-guides/model-loading.html">Model loading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/user-guides/prefill-decode.html">Prefill/decode disaggregation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/user-guides/prefix-aware-routing.html">Prefix-aware routing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/user-guides/multi-lora.html">Multi-LoRA deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/user-guides/vllm-compatibility.html">vLLM compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/user-guides/fractional-gpu.html">Fractional GPU serving</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/user-guides/observability.html">Observability and monitoring</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../serve/llm/architecture/index.html">Architecture</a><input class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-36"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/architecture/overview.html">Architecture overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/architecture/core.html">Core components</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/architecture/serving-patterns/index.html">Serving patterns</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/architecture/routing-policies.html">Request routing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/llm/benchmarks.html">Benchmarks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/llm/troubleshooting.html">Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../serve/production-guide/index.html">Production Guide</a><input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-37"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/production-guide/config.html">Serve Config Files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/production-guide/kubernetes.html">Deploy on Kubernetes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/production-guide/docker.html">Custom Docker Images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/production-guide/fault-tolerance.html">Add End-to-End Fault Tolerance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/production-guide/handling-dependencies.html">Handle Dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/production-guide/best-practices.html">Best practices in production</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/monitoring.html">Monitor Your Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/resource-allocation.html">Resource Allocation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/autoscaling-guide.html">Ray Serve Autoscaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/asynchronous-inference.html">Asynchronous Inference</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../serve/advanced-guides/index.html">Advanced Guides</a><input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-38"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/app-builder-guide.html">Pass Arguments to Applications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/advanced-autoscaling.html">Advanced Ray Serve Autoscaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/performance.html">Performance Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/dyn-req-batch.html">Dynamic Request Batching</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/inplace-updates.html">Updating Applications In-Place</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/dev-workflow.html">Development Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/grpc-guide.html">Set Up a gRPC Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/replica-ranks.html">Replica ranks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/managing-java-deployments.html">Experimental Java API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/deploy-vm.html">Deploy on VM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/multi-app-container.html">Run Multiple Applications in Different Containers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/custom-request-router.html">Use Custom Algorithm for Request Routing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/multi-node-gpu-troubleshooting.html">Troubleshoot multi-node GPU serving on KubeRay</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/architecture.html">Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/api/index.html">Ray Serve API</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../rllib/index.html">Ray RLlib</a><input class="toctree-checkbox" id="toctree-checkbox-39" name="toctree-checkbox-39" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-39"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../rllib/getting-started.html">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../rllib/key-concepts.html">Key concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../rllib/rllib-env.html">Environments</a><input class="toctree-checkbox" id="toctree-checkbox-40" name="toctree-checkbox-40" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-40"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/multi-agent-envs.html">Multi-Agent Environments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/hierarchical-envs.html">Hierarchical Environments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/external-envs.html">External Environments and Applications</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../rllib/algorithm-config.html">AlgorithmConfig API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../rllib/rllib-algorithms.html">Algorithms</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../rllib/user-guides.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-41" name="toctree-checkbox-41" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-41"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-advanced-api.html">Advanced Python APIs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-callback.html">Callbacks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/checkpoints.html">Checkpointing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/metrics-logger.html">MetricsLogger API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/single-agent-episode.html">Episodes</a></li>

<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/connector-v2.html">ConnectorV2 and ConnectorV2 pipelines</a><input class="toctree-checkbox" id="toctree-checkbox-42" name="toctree-checkbox-42" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-42"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/env-to-module-connector.html">Env-to-module pipelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/learner-connector.html">Learner connector pipelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-replay-buffers.html">Replay Buffers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-offline.html">Working with offline data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rl-modules.html">RL Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-learner.html">Learner (Alpha)</a></li>



<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-torch2x.html">Using RLlib with torch 2.x compile</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-fault-tolerance.html">Fault Tolerance And Elastic Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-dev.html">Install RLlib for Development</a></li>




<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/scaling-guide.html">RLlib scaling guide</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../rllib/rllib-examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../rllib/new-api-stack-migration-guide.html">New API stack migration guide</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/index.html">Ray RLlib API</a><input class="toctree-checkbox" id="toctree-checkbox-43" name="toctree-checkbox-43" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-43"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/algorithm-config.html">Algorithm Configuration API</a><input class="toctree-checkbox" id="toctree-checkbox-44" name="toctree-checkbox-44" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-44"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_algo.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_algo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.is_multi_agent.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.is_multi_agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.is_offline.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.is_offline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learner_class.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learner_class</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.model_config.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.model_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.rl_module_spec.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.rl_module_spec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.total_train_batch_size.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.total_train_batch_size</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_learner_class.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_learner_class</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_rl_module_spec.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_rl_module_spec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_evaluation_config_object.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_evaluation_config_object</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_rl_module_spec.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_rl_module_spec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_agent_setup.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_agent_setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_rollout_fragment_length.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_rollout_fragment_length</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.copy.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.validate.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.validate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.freeze.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.freeze</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/algorithm.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-45" name="toctree-checkbox-45" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-45"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.html">ray.rllib.algorithms.algorithm.Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.setup.html">ray.rllib.algorithms.algorithm.Algorithm.setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.get_default_config.html">ray.rllib.algorithms.algorithm.Algorithm.get_default_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.env_runner.html">ray.rllib.algorithms.algorithm.Algorithm.env_runner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.eval_env_runner.html">ray.rllib.algorithms.algorithm.Algorithm.eval_env_runner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.train.html">ray.rllib.algorithms.algorithm.Algorithm.train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.training_step.html">ray.rllib.algorithms.algorithm.Algorithm.training_step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.save_to_path.html">ray.rllib.algorithms.algorithm.Algorithm.save_to_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.restore_from_path.html">ray.rllib.algorithms.algorithm.Algorithm.restore_from_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.from_checkpoint.html">ray.rllib.algorithms.algorithm.Algorithm.from_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.get_state.html">ray.rllib.algorithms.algorithm.Algorithm.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.set_state.html">ray.rllib.algorithms.algorithm.Algorithm.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.evaluate.html">ray.rllib.algorithms.algorithm.Algorithm.evaluate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.get_module.html">ray.rllib.algorithms.algorithm.Algorithm.get_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.add_policy.html">ray.rllib.algorithms.algorithm.Algorithm.add_policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.remove_policy.html">ray.rllib.algorithms.algorithm.Algorithm.remove_policy</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/callback.html">Callback APIs</a><input class="toctree-checkbox" id="toctree-checkbox-46" name="toctree-checkbox-46" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-46"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.html">ray.rllib.callbacks.callbacks.RLlibCallback</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_algorithm_init.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_algorithm_init</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_sample_end.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_sample_end</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_train_result.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_train_result</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_evaluate_start.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_evaluate_start</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_evaluate_end.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_evaluate_end</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_env_runners_recreated.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_env_runners_recreated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_checkpoint_loaded.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_checkpoint_loaded</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_environment_created.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_environment_created</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_created.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_created</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_start.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_start</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_step.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_end.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_end</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/env.html">Environments</a><input class="toctree-checkbox" id="toctree-checkbox-47" name="toctree-checkbox-47" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-47"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/env_runner.html">EnvRunner API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/single_agent_env_runner.html">SingleAgentEnvRunner API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/single_agent_episode.html">SingleAgentEpisode API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/multi_agent_env.html">MultiAgentEnv API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/multi_agent_env_runner.html">MultiAgentEnvRunner API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/multi_agent_episode.html">MultiAgentEpisode API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/external.html">External Envs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/utils.html">Env Utils</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/rl_modules.html">RLModule APIs</a><input class="toctree-checkbox" id="toctree-checkbox-48" name="toctree-checkbox-48" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-48"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.build.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.build</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.module_class.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.module_class</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.observation_space.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.observation_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.action_space.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.action_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.inference_only.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.inference_only</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.learner_only.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.learner_only</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.model_config.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.model_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.build.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.build</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.default_model_config.DefaultModelConfig.html">ray.rllib.core.rl_module.default_model_config.DefaultModelConfig</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.html">ray.rllib.core.rl_module.rl_module.RLModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.observation_space.html">ray.rllib.core.rl_module.rl_module.RLModule.observation_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.action_space.html">ray.rllib.core.rl_module.rl_module.RLModule.action_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.inference_only.html">ray.rllib.core.rl_module.rl_module.RLModule.inference_only</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.model_config.html">ray.rllib.core.rl_module.rl_module.RLModule.model_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.setup.html">ray.rllib.core.rl_module.rl_module.RLModule.setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.as_multi_rl_module.html">ray.rllib.core.rl_module.rl_module.RLModule.as_multi_rl_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration.html">ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_inference.html">ray.rllib.core.rl_module.rl_module.RLModule.forward_inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_train.html">ray.rllib.core.rl_module.rl_module.RLModule.forward_train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule._forward.html">ray.rllib.core.rl_module.rl_module.RLModule._forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule._forward_exploration.html">ray.rllib.core.rl_module.rl_module.RLModule._forward_exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule._forward_inference.html">ray.rllib.core.rl_module.rl_module.RLModule._forward_inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule._forward_train.html">ray.rllib.core.rl_module.rl_module.RLModule._forward_train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.save_to_path.html">ray.rllib.core.rl_module.rl_module.RLModule.save_to_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.restore_from_path.html">ray.rllib.core.rl_module.rl_module.RLModule.restore_from_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.from_checkpoint.html">ray.rllib.core.rl_module.rl_module.RLModule.from_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.get_state.html">ray.rllib.core.rl_module.rl_module.RLModule.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.set_state.html">ray.rllib.core.rl_module.rl_module.RLModule.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.setup.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.as_multi_rl_module.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.as_multi_rl_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.add_module.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.add_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.remove_module.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.remove_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.save_to_path.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.save_to_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.restore_from_path.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.restore_from_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.from_checkpoint.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.from_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.get_state.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.set_state.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.set_state</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/distributions.html">Distribution API</a><input class="toctree-checkbox" id="toctree-checkbox-49" name="toctree-checkbox-49" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-49"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.html">ray.rllib.models.distributions.Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.from_logits.html">ray.rllib.models.distributions.Distribution.from_logits</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.sample.html">ray.rllib.models.distributions.Distribution.sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.rsample.html">ray.rllib.models.distributions.Distribution.rsample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.logp.html">ray.rllib.models.distributions.Distribution.logp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.kl.html">ray.rllib.models.distributions.Distribution.kl</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/learner.html">LearnerGroup API</a><input class="toctree-checkbox" id="toctree-checkbox-50" name="toctree-checkbox-50" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-50"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learners.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learners</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner_group.LearnerGroup.html">ray.rllib.core.learner.learner_group.LearnerGroup</a></li>
</ul>
</li>

<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/offline.html">Offline RL API</a><input class="toctree-checkbox" id="toctree-checkbox-51" name="toctree-checkbox-51" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-51"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learners.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learners</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.env_runners.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.env_runners</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_env_runner.OfflineSingleAgentEnvRunner.html">ray.rllib.offline.offline_env_runner.OfflineSingleAgentEnvRunner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_data.OfflineData.html">ray.rllib.offline.offline_data.OfflineData</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_data.OfflineData.__init__.html">ray.rllib.offline.offline_data.OfflineData.__init__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_data.OfflineData.sample.html">ray.rllib.offline.offline_data.OfflineData.sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_data.OfflineData.default_map_batches_kwargs.html">ray.rllib.offline.offline_data.OfflineData.default_map_batches_kwargs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_data.OfflineData.default_iter_batches_kwargs.html">ray.rllib.offline.offline_data.OfflineData.default_iter_batches_kwargs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner.__init__.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner.__init__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.SCHEMA.html">ray.rllib.offline.offline_prelearner.SCHEMA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner.__call__.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner.__call__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner._map_to_episodes.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner._map_to_episodes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner._map_sample_batch_to_episode.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner._map_sample_batch_to_episode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner._should_module_be_updated.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner._should_module_be_updated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner.default_prelearner_buffer_class.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner.default_prelearner_buffer_class</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner.default_prelearner_buffer_kwargs.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner.default_prelearner_buffer_kwargs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/package_ref/connector-v2.html">ConnectorV2 API</a></li>

<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/replay-buffers.html">Replay Buffer API</a><input class="toctree-checkbox" id="toctree-checkbox-52" name="toctree-checkbox-52" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-52"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.StorageUnit.html">ray.rllib.utils.replay_buffers.replay_buffer.StorageUnit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.prioritized_replay_buffer.PrioritizedReplayBuffer.html">ray.rllib.utils.replay_buffers.prioritized_replay_buffer.PrioritizedReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.reservoir_replay_buffer.ReservoirReplayBuffer.html">ray.rllib.utils.replay_buffers.reservoir_replay_buffer.ReservoirReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.sample.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.add.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.add</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.get_state.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.set_state.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.multi_agent_replay_buffer.MultiAgentReplayBuffer.html">ray.rllib.utils.replay_buffers.multi_agent_replay_buffer.MultiAgentReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer.html">ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.utils.update_priorities_in_replay_buffer.html">ray.rllib.utils.replay_buffers.utils.update_priorities_in_replay_buffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.utils.sample_min_n_steps_from_buffer.html">ray.rllib.utils.replay_buffers.utils.sample_min_n_steps_from_buffer</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/utils.html">RLlib Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-53" name="toctree-checkbox-53" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-53"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.metrics.metrics_logger.MetricsLogger.html">ray.rllib.utils.metrics.metrics_logger.MetricsLogger</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.metrics.metrics_logger.MetricsLogger.peek.html">ray.rllib.utils.metrics.metrics_logger.MetricsLogger.peek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_value.html">ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_value</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_dict.html">ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_dict</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.metrics.metrics_logger.MetricsLogger.aggregate.html">ray.rllib.utils.metrics.metrics_logger.MetricsLogger.aggregate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_time.html">ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_time</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.schedules.scheduler.Scheduler.html">ray.rllib.utils.schedules.scheduler.Scheduler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.schedules.scheduler.Scheduler.validate.html">ray.rllib.utils.schedules.scheduler.Scheduler.validate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.schedules.scheduler.Scheduler.get_current_value.html">ray.rllib.utils.schedules.scheduler.Scheduler.get_current_value</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.schedules.scheduler.Scheduler.update.html">ray.rllib.utils.schedules.scheduler.Scheduler.update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.schedules.scheduler.Scheduler._create_tensor_variable.html">ray.rllib.utils.schedules.scheduler.Scheduler._create_tensor_variable</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.framework.try_import_torch.html">ray.rllib.utils.framework.try_import_torch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.clip_gradients.html">ray.rllib.utils.torch_utils.clip_gradients</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.compute_global_norm.html">ray.rllib.utils.torch_utils.compute_global_norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.convert_to_torch_tensor.html">ray.rllib.utils.torch_utils.convert_to_torch_tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.explained_variance.html">ray.rllib.utils.torch_utils.explained_variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.flatten_inputs_to_1d_tensor.html">ray.rllib.utils.torch_utils.flatten_inputs_to_1d_tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.global_norm.html">ray.rllib.utils.torch_utils.global_norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.one_hot.html">ray.rllib.utils.torch_utils.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.reduce_mean_ignore_inf.html">ray.rllib.utils.torch_utils.reduce_mean_ignore_inf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.sequence_mask.html">ray.rllib.utils.torch_utils.sequence_mask</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.set_torch_seed.html">ray.rllib.utils.torch_utils.set_torch_seed</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.softmax_cross_entropy_with_logits.html">ray.rllib.utils.torch_utils.softmax_cross_entropy_with_logits</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.update_target_network.html">ray.rllib.utils.torch_utils.update_target_network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.aligned_array.html">ray.rllib.utils.numpy.aligned_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.concat_aligned.html">ray.rllib.utils.numpy.concat_aligned</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.convert_to_numpy.html">ray.rllib.utils.numpy.convert_to_numpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.fc.html">ray.rllib.utils.numpy.fc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.flatten_inputs_to_1d_tensor.html">ray.rllib.utils.numpy.flatten_inputs_to_1d_tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.make_action_immutable.html">ray.rllib.utils.numpy.make_action_immutable</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.huber_loss.html">ray.rllib.utils.numpy.huber_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.l2_loss.html">ray.rllib.utils.numpy.l2_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.lstm.html">ray.rllib.utils.numpy.lstm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.one_hot.html">ray.rllib.utils.numpy.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.relu.html">ray.rllib.utils.numpy.relu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.sigmoid.html">ray.rllib.utils.numpy.sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.softmax.html">ray.rllib.utils.numpy.softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.checkpoints.try_import_msgpack.html">ray.rllib.utils.checkpoints.try_import_msgpack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.checkpoints.Checkpointable.html">ray.rllib.utils.checkpoints.Checkpointable</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../ray-more-libs/index.html">More Libraries</a><input class="toctree-checkbox" id="toctree-checkbox-54" name="toctree-checkbox-54" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-54"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/joblib.html">Distributed Scikit-learn / Joblib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/multiprocessing.html">Distributed multiprocessing.Pool</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/ray-collective.html">Ray Collective Communication Lib</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-more-libs/dask-on-ray.html">Using Dask on Ray</a><input class="toctree-checkbox" id="toctree-checkbox-55" name="toctree-checkbox-55" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-55"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.RayDaskCallback.html">ray.util.dask.RayDaskCallback</a><input class="toctree-checkbox" id="toctree-checkbox-56" name="toctree-checkbox-56" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-56"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.RayDaskCallback.ray_active.html">ray.util.dask.RayDaskCallback.ray_active</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_presubmit.html">ray.util.dask.callbacks.RayDaskCallback._ray_presubmit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit.html">ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_pretask.html">ray.util.dask.callbacks.RayDaskCallback._ray_pretask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_posttask.html">ray.util.dask.callbacks.RayDaskCallback._ray_posttask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit_all.html">ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_finish.html">ray.util.dask.callbacks.RayDaskCallback._ray_finish</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/raydp.html">Using Spark on Ray (RayDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/mars-on-ray.html">Using Mars on Ray</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/modin/index.html">Using Pandas on Ray (Modin)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/data_juicer_distributed_data_processing.html">Distributed Data Processing in Data-Juicer</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../cluster/getting-started.html">Ray Clusters</a><input class="toctree-checkbox" id="toctree-checkbox-57" name="toctree-checkbox-57" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-57"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../cluster/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/index.html">Deploying on Kubernetes</a><input class="toctree-checkbox" id="toctree-checkbox-58" name="toctree-checkbox-58" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-58"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/getting-started.html">Getting Started with KubeRay</a><input class="toctree-checkbox" id="toctree-checkbox-59" name="toctree-checkbox-59" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-59"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/getting-started/kuberay-operator-installation.html">KubeRay Operator Installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/getting-started/raycluster-quick-start.html">RayCluster Quickstart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/getting-started/rayjob-quick-start.html">RayJob Quickstart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/getting-started/rayservice-quick-start.html">RayService Quickstart</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-60" name="toctree-checkbox-60" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-60"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/rayservice.html">Deploy Ray Serve Apps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/rayservice-no-ray-serve-replica.html">RayService worker Pods aren’t ready</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/rayservice-high-availability.html">RayService high availability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/observability.html">KubeRay Observability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/upgrade-guide.html">KubeRay upgrade guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/k8s-cluster-setup.html">Managed Kubernetes services</a></li>




<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/storage.html">Best Practices for Storage and Dependencies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/config.html">RayCluster Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/configuring-autoscaling.html">KubeRay Autoscaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/kuberay-gcs-ft.html">GCS fault tolerance in KubeRay</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/kuberay-gcs-persistent-ft.html">Tuning Redis for a Persistent Fault Tolerant GCS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/gke-gcs-bucket.html">Configuring KubeRay to use Google Cloud Storage Buckets in GKE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/persist-kuberay-custom-resource-logs.html">Persist KubeRay custom resource logs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/persist-kuberay-operator-logs.html">Persist KubeRay Operator Logs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/gpu.html">Using GPUs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/tpu.html">Use TPUs with KubeRay</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/pod-command.html">Specify container commands for Ray head/worker Pods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/helm-chart-rbac.html">Helm Chart RBAC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/tls.html">TLS Authentication</a></li>






<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/k8s-autoscaler.html">(Advanced) Understanding the Ray Autoscaler in the Context of Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/kubectl-plugin.html">Use kubectl plugin (beta)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/kuberay-auth.html">Configure Ray clusters with authentication and access control using KubeRay</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/reduce-image-pull-latency.html">Reducing image pull latency on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/uv.html">Using <code class="docutils literal notranslate"><span class="pre">uv</span></code> for Python package management in KubeRay</a></li>

<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/kuberay-dashboard.html">Use KubeRay dashboard (experimental)</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/examples.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-61" name="toctree-checkbox-61" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-61"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/mnist-training-example.html">Train a PyTorch model on Fashion MNIST with CPUs on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/stable-diffusion-rayservice.html">Serve a StableDiffusion text-to-image model on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/tpu-serve-stable-diffusion.html">Serve a Stable Diffusion model on GKE with TPUs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/mobilenet-rayservice.html">Serve a MobileNet image classifier on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/text-summarizer-rayservice.html">Serve a text summarizer on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/rayjob-batch-inference-example.html">RayJob Batch Inference Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/rayjob-kueue-priority-scheduling.html">Priority Scheduling with RayJob and Kueue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/rayjob-kueue-gang-scheduling.html">Gang Scheduling with RayJob and Kueue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/distributed-checkpointing-with-gcsfuse.html">Distributed checkpointing with KubeRay and GCSFuse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/modin-example.html">Use Modin with Ray on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/rayserve-llm-example.html">Serve a Large Language Model using Ray Serve LLM on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/rayserve-deepseek-example.html">Serve Deepseek R1 using Ray Serve LLM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/verl-post-training.html">Reinforcement Learning with Human Feedback (RLHF) for LLMs with verl on KubeRay</a></li>








</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem.html">KubeRay Ecosystem</a><input class="toctree-checkbox" id="toctree-checkbox-62" name="toctree-checkbox-62" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-62"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/ingress.html">Ingress</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/metrics-references.html">KubeRay metrics references</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/prometheus-grafana.html">Using Prometheus and Grafana</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/pyspy.html">Profiling with py-spy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/volcano.html">KubeRay integration with Volcano</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/yunikorn.html">KubeRay integration with Apache YuniKorn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/kueue.html">Gang scheduling and Priority scheduling for KubeRay CRDs with Kueue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/istio.html">mTLS and L7 observability with Istio</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/scheduler-plugins.html">KubeRay integration with scheduler plugins</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/benchmarks.html">KubeRay Benchmarks</a><input class="toctree-checkbox" id="toctree-checkbox-63" name="toctree-checkbox-63" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-63"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/benchmarks/memory-scalability-benchmark.html">KubeRay memory and scalability benchmark</a></li>

</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/troubleshooting.html">KubeRay Troubleshooting</a><input class="toctree-checkbox" id="toctree-checkbox-64" name="toctree-checkbox-64" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-64"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/troubleshooting/troubleshooting.html">Troubleshooting guide</a></li>

<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/troubleshooting/rayservice-troubleshooting.html">RayService troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/kubernetes/references.html">API Reference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../cluster/vms/index.html">Deploying on VMs</a><input class="toctree-checkbox" id="toctree-checkbox-65" name="toctree-checkbox-65" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-65"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/vms/getting-started.html">Getting Started</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/vms/user-guides/index.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-66" name="toctree-checkbox-66" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-66"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/user-guides/launching-clusters/index.html">Launching Ray Clusters on AWS, GCP, Azure, vSphere, On-Prem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/user-guides/large-cluster-best-practices.html">Best practices for deploying large clusters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/user-guides/configuring-autoscaling.html">Configuring Autoscaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/user-guides/logging.html">Log Persistence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/user-guides/community/index.html">Community Supported Cluster Managers</a></li>

</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/vms/examples/index.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-67" name="toctree-checkbox-67" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-67"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/examples/ml-example.html">Ray Train XGBoostTrainer on VMs</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/vms/references/index.html">API References</a><input class="toctree-checkbox" id="toctree-checkbox-68" name="toctree-checkbox-68" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-68"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/references/ray-cluster-cli.html">Cluster Launcher Commands</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/references/ray-cluster-configuration.html">Cluster YAML Configuration Options</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../cluster/metrics.html">Collecting and monitoring metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../cluster/configure-manage-dashboard.html">Configuring and Managing Ray Dashboard</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../cluster/running-applications/index.html">Applications Guide</a><input class="toctree-checkbox" id="toctree-checkbox-69" name="toctree-checkbox-69" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-69"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/index.html">Ray Jobs Overview</a><input class="toctree-checkbox" id="toctree-checkbox-70" name="toctree-checkbox-70" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-70"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/quickstart.html">Quickstart using the Ray Jobs CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/sdk.html">Python SDK Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/jobs-package-ref.html">Python SDK API Reference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/cli.html">Ray Jobs CLI API Reference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/rest.html">Ray Jobs REST API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/ray-client.html">Ray Client</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/running-applications/autoscaling/reference.html">Programmatic Cluster Scaling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../cluster/faq.html">FAQ</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../cluster/package-overview.html">Ray Cluster Management API</a><input class="toctree-checkbox" id="toctree-checkbox-71" name="toctree-checkbox-71" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-71"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/cli.html">Cluster Management CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/jobs-package-ref.html">Python SDK API Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/cli.html">Ray Jobs CLI API Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/running-applications/autoscaling/reference.html">Programmatic Cluster Scaling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../cluster/usage-stats.html">Usage Stats Collection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../virtual-cluster/getting-started.html">Ray Virtual Clusters</a><input class="toctree-checkbox" id="toctree-checkbox-72" name="toctree-checkbox-72" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-72"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../virtual-cluster/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../virtual-cluster/design-overview.html">Design Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../virtual-cluster/management.html">Virtual Cluster Management API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../virtual-cluster/cli.html">Virtual Cluster CLI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../virtual-cluster/examples.html">Examples</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../ray-observability/index.html">Monitoring and Debugging</a><input class="toctree-checkbox" id="toctree-checkbox-73" name="toctree-checkbox-73" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-73"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-observability/getting-started.html">Ray Dashboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-observability/ray-distributed-debugger.html">Ray Distributed Debugger</a></li>



<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-observability/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-observability/user-guides/index.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-74" name="toctree-checkbox-74" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-74"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/index.html">Debugging Applications</a><input class="toctree-checkbox" id="toctree-checkbox-75" name="toctree-checkbox-75" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-75"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/general-debugging.html">Common Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/debug-memory.html">Debugging Memory Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/debug-hangs.html">Debugging Hangs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/debug-failures.html">Debugging Failures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/optimize-performance.html">Optimizing Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/ray-distributed-debugger.html">Ray Distributed Debugger</a></li>



<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/ray-debugging.html">Using the Ray Debugger</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/user-guides/cli-sdk.html">Monitoring with the CLI or SDK</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/user-guides/configure-logging.html">Configuring Logging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/user-guides/profiling.html">Profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/user-guides/add-app-metrics.html">Adding Application-Level Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/user-guides/ray-tracing.html">Tracing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/user-guides/ray-event-export.html">Ray Event Export</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-observability/reference/index.html">Reference</a><input class="toctree-checkbox" id="toctree-checkbox-76" name="toctree-checkbox-76" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-76"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/reference/api.html">State API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/reference/cli.html">State CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/reference/system-metrics.html">System Metrics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../ray-contribute/index.html">Developer Guides</a><input class="toctree-checkbox" id="toctree-checkbox-77" name="toctree-checkbox-77" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-77"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-contribute/stability.html">API Stability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-contribute/api-policy.html">API Policy</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-contribute/getting-involved.html">Getting Involved / Contributing</a><input class="toctree-checkbox" id="toctree-checkbox-78" name="toctree-checkbox-78" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-78"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/development.html">Building Ray from Source</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/ci.html">CI Testing Workflow on PRs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/docs.html">Contributing to the Ray Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/writing-code-snippets.html">How to write code snippets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/fake-autoscaler.html">Testing Autoscaling Locally</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/testing-tips.html">Tips for testing Ray programs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/debugging.html">Debugging for Ray Developers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/profiling.html">Profiling for Ray Developers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-core/configure.html">Configuring Ray</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-contribute/whitepaper.html">Architecture Whitepapers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-references/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-security/index.html">Security</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">ray.rllib.al...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <h1>Source code for ray.rllib.algorithms.impala.impala</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">queue</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Self</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray</span><span class="w"> </span><span class="kn">import</span> <span class="n">ObjectRef</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray._common.deprecation</span><span class="w"> </span><span class="kn">import</span> <span class="n">DEPRECATED_VALUE</span><span class="p">,</span> <span class="n">deprecation_warning</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib</span><span class="w"> </span><span class="kn">import</span> <span class="n">SampleBatch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.algorithms.algorithm</span><span class="w"> </span><span class="kn">import</span> <span class="n">Algorithm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.algorithms.algorithm_config</span><span class="w"> </span><span class="kn">import</span> <span class="n">AlgorithmConfig</span><span class="p">,</span> <span class="n">NotProvided</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.connectors.learner</span><span class="w"> </span><span class="kn">import</span> <span class="n">AddOneTsToEpisodesAndTruncate</span><span class="p">,</span> <span class="n">NumpyToTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.core</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">COMPONENT_ENV_TO_MODULE_CONNECTOR</span><span class="p">,</span>
    <span class="n">COMPONENT_MODULE_TO_ENV_CONNECTOR</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.core.learner.training_data</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingData</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.core.rl_module.rl_module</span><span class="w"> </span><span class="kn">import</span> <span class="n">RLModuleSpec</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.execution.buffers.mixin_replay_buffer</span><span class="w"> </span><span class="kn">import</span> <span class="n">MixInMultiAgentReplayBuffer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.execution.learner_thread</span><span class="w"> </span><span class="kn">import</span> <span class="n">LearnerThread</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.execution.multi_gpu_learner_thread</span><span class="w"> </span><span class="kn">import</span> <span class="n">MultiGPULearnerThread</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.policy.policy</span><span class="w"> </span><span class="kn">import</span> <span class="n">Policy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.policy.sample_batch</span><span class="w"> </span><span class="kn">import</span> <span class="n">concat_samples</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.utils.annotations</span><span class="w"> </span><span class="kn">import</span> <span class="n">OldAPIStack</span><span class="p">,</span> <span class="n">override</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.utils.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">AGGREGATOR_ACTOR_RESULTS</span><span class="p">,</span>
    <span class="n">ALL_MODULES</span><span class="p">,</span>
    <span class="n">ENV_RUNNER_RESULTS</span><span class="p">,</span>
    <span class="n">LEARNER_GROUP</span><span class="p">,</span>
    <span class="n">LEARNER_RESULTS</span><span class="p">,</span>
    <span class="n">LEARNER_UPDATE_TIMER</span><span class="p">,</span>
    <span class="n">MEAN_NUM_EPISODE_LISTS_RECEIVED</span><span class="p">,</span>
    <span class="n">MEAN_NUM_LEARNER_RESULTS_RECEIVED</span><span class="p">,</span>
    <span class="n">MEAN_NUM_LEARNER_GROUP_UPDATE_CALLED</span><span class="p">,</span>
    <span class="n">NUM_AGENT_STEPS_SAMPLED</span><span class="p">,</span>
    <span class="n">NUM_AGENT_STEPS_TRAINED</span><span class="p">,</span>
    <span class="n">NUM_ENV_STEPS_SAMPLED</span><span class="p">,</span>
    <span class="n">NUM_ENV_STEPS_SAMPLED_LIFETIME</span><span class="p">,</span>
    <span class="n">NUM_ENV_STEPS_TRAINED</span><span class="p">,</span>
    <span class="n">NUM_ENV_STEPS_TRAINED_LIFETIME</span><span class="p">,</span>
    <span class="n">NUM_SYNCH_WORKER_WEIGHTS</span><span class="p">,</span>
    <span class="n">NUM_TRAINING_STEP_CALLS_SINCE_LAST_SYNCH_WORKER_WEIGHTS</span><span class="p">,</span>
    <span class="n">SYNCH_WORKER_WEIGHTS_TIMER</span><span class="p">,</span>
    <span class="n">SAMPLE_TIMER</span><span class="p">,</span>
    <span class="n">TIMERS</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.utils.metrics.learner_info</span><span class="w"> </span><span class="kn">import</span> <span class="n">LearnerInfoBuilder</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.utils.metrics.ray_metrics</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">DEFAULT_HISTOGRAM_BOUNDARIES_SHORT_EVENTS</span><span class="p">,</span>
    <span class="n">TimerAndPrometheusLogger</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.utils.replay_buffers.multi_agent_replay_buffer</span><span class="w"> </span><span class="kn">import</span> <span class="n">ReplayMode</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.utils.replay_buffers.replay_buffer</span><span class="w"> </span><span class="kn">import</span> <span class="n">_ALL_POLICIES</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.utils.schedules.scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">Scheduler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.utils.typing</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">LearningRateOrSchedule</span><span class="p">,</span>
    <span class="n">PolicyID</span><span class="p">,</span>
    <span class="n">ResultDict</span><span class="p">,</span>
    <span class="n">SampleBatchType</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ray.util.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">Histogram</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="n">LEARNER_RESULTS_CURR_ENTROPY_COEFF_KEY</span> <span class="o">=</span> <span class="s2">&quot;curr_entropy_coeff&quot;</span>


<div class="viewcode-block" id="IMPALAConfig">
<a class="viewcode-back" href="../../../../../rllib/rllib-algorithms.html#ray.rllib.algorithms.impala.impala.IMPALAConfig">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">IMPALAConfig</span><span class="p">(</span><span class="n">AlgorithmConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Defines a configuration class from which an Impala can be built.</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        from ray.rllib.algorithms.impala import IMPALAConfig</span>

<span class="sd">        config = (</span>
<span class="sd">            IMPALAConfig()</span>
<span class="sd">            .environment(&quot;CartPole-v1&quot;)</span>
<span class="sd">            .env_runners(num_env_runners=1)</span>
<span class="sd">            .training(lr=0.0003, train_batch_size_per_learner=512)</span>
<span class="sd">            .learners(num_learners=1)</span>
<span class="sd">        )</span>
<span class="sd">        # Build a Algorithm object from the config and run 1 training iteration.</span>
<span class="sd">        algo = config.build()</span>
<span class="sd">        algo.train()</span>
<span class="sd">        del algo</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        from ray.rllib.algorithms.impala import IMPALAConfig</span>
<span class="sd">        from ray import tune</span>

<span class="sd">        config = (</span>
<span class="sd">            IMPALAConfig()</span>
<span class="sd">            .environment(&quot;CartPole-v1&quot;)</span>
<span class="sd">            .env_runners(num_env_runners=1)</span>
<span class="sd">            .training(lr=tune.grid_search([0.0001, 0.0002]), grad_clip=20.0)</span>
<span class="sd">            .learners(num_learners=1)</span>
<span class="sd">        )</span>
<span class="sd">        # Run with tune.</span>
<span class="sd">        tune.Tuner(</span>
<span class="sd">            &quot;IMPALA&quot;,</span>
<span class="sd">            param_space=config,</span>
<span class="sd">            run_config=tune.RunConfig(stop={&quot;training_iteration&quot;: 1}),</span>
<span class="sd">        ).fit()</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">algo_class</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes a IMPALAConfig instance.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exploration_config</span> <span class="o">=</span> <span class="p">{</span>  <span class="c1"># @OldAPIstack</span>
            <span class="c1"># The Exploration class to use. In the simplest case, this is the name</span>
            <span class="c1"># (str) of any class present in the `rllib.utils.exploration` package.</span>
            <span class="c1"># You can also provide the python class directly or the full location</span>
            <span class="c1"># of your class (e.g. &quot;ray.rllib.utils.exploration.epsilon_greedy.</span>
            <span class="c1"># EpsilonGreedy&quot;).</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;StochasticSampling&quot;</span><span class="p">,</span>
            <span class="c1"># Add constructor kwargs here (if any).</span>
        <span class="p">}</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">algo_class</span><span class="o">=</span><span class="n">algo_class</span> <span class="ow">or</span> <span class="n">IMPALA</span><span class="p">)</span>

        <span class="c1"># fmt: off</span>
        <span class="c1"># __sphinx_doc_begin__</span>

        <span class="c1"># IMPALA specific settings:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vtrace</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vtrace_clip_rho_threshold</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vtrace_clip_pg_rho_threshold</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learner_queue_size</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">timeout_s_sampler_manager</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">timeout_s_aggregator_manager</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_interval</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_gpu_loader_threads</span> <span class="o">=</span> <span class="mi">8</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">grad_clip</span> <span class="o">=</span> <span class="mf">40.0</span>
        <span class="c1"># Note: Only when using enable_rl_module_and_learner=True can the clipping mode</span>
        <span class="c1"># be configured by the user. On the old API stack, RLlib will always clip by</span>
        <span class="c1"># global_norm, no matter the value of `grad_clip_by`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad_clip_by</span> <span class="o">=</span> <span class="s2">&quot;global_norm&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vf_loss_coeff</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coeff</span> <span class="o">=</span> <span class="mf">0.01</span>

        <span class="c1"># Override some of AlgorithmConfig&#39;s default values with IMPALA-specific values.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_learners</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_aggregator_actors_per_learner</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rollout_fragment_length</span> <span class="o">=</span> <span class="mi">50</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_env_runners</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0005</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_time_s_per_iteration</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="c1"># __sphinx_doc_end__</span>
        <span class="c1"># fmt: on</span>

        <span class="c1"># IMPALA takes care of its own EnvRunner (weights, connector, metrics) synching.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dont_auto_sync_env_runner_states</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># `.debugging()`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_env_runners_only</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_skip_learners</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedule</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># @OldAPIStack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coeff_schedule</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># @OldAPIStack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_multi_gpu_tower_stacks</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_buffer_size</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_proportion</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer_num_slots</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learner_queue_timeout</span> <span class="o">=</span> <span class="mi">300</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt_type</span> <span class="o">=</span> <span class="s2">&quot;adam&quot;</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decay</span> <span class="o">=</span> <span class="mf">0.99</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_separate_vf_optimizer</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lr_vf</span> <span class="o">=</span> <span class="mf">0.0005</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_gpus</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># @OldAPIstack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tf_policy_handles_more_than_one_loss</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># @OldAPIstack</span>

        <span class="c1"># Deprecated settings.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_aggregation_workers</span> <span class="o">=</span> <span class="n">DEPRECATED_VALUE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_requests_in_flight_per_aggregator_worker</span> <span class="o">=</span> <span class="n">DEPRECATED_VALUE</span>

<div class="viewcode-block" id="IMPALAConfig.training">
<a class="viewcode-back" href="../../../../../rllib/rllib-algorithms.html#ray.rllib.algorithms.impala.impala.IMPALAConfig.training">[docs]</a>
    <span class="nd">@override</span><span class="p">(</span><span class="n">AlgorithmConfig</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">training</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">vtrace</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">vtrace_clip_rho_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">vtrace_clip_pg_rho_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">num_gpu_loader_threads</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">num_multi_gpu_tower_stacks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">minibatch_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">replay_proportion</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">replay_buffer_num_slots</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">learner_queue_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">learner_queue_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">timeout_s_sampler_manager</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">timeout_s_aggregator_manager</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">broadcast_interval</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">grad_clip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">opt_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">lr_schedule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">decay</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">momentum</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">epsilon</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">vf_loss_coeff</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">entropy_coeff</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LearningRateOrSchedule</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">entropy_coeff_schedule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">_separate_vf_optimizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">_lr_vf</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="c1"># Deprecated args.</span>
        <span class="n">num_aggregation_workers</span><span class="o">=</span><span class="n">DEPRECATED_VALUE</span><span class="p">,</span>
        <span class="n">max_requests_in_flight_per_aggregator_worker</span><span class="o">=</span><span class="n">DEPRECATED_VALUE</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets the training related configuration.</span>

<span class="sd">        Args:</span>
<span class="sd">            vtrace: V-trace params (see vtrace_tf/torch.py).</span>
<span class="sd">            vtrace_clip_rho_threshold:</span>
<span class="sd">            vtrace_clip_pg_rho_threshold:</span>
<span class="sd">            num_gpu_loader_threads: The number of GPU-loader threads (per Learner</span>
<span class="sd">                worker), used to load incoming (CPU) batches to the GPU, if applicable.</span>
<span class="sd">                The incoming batches are produced by each Learner&#39;s LearnerConnector</span>
<span class="sd">                pipeline. After loading the batches on the GPU, the threads place them</span>
<span class="sd">                on yet another queue for the Learner thread (only one per Learner</span>
<span class="sd">                worker) to pick up and perform `forward_train/loss` computations.</span>
<span class="sd">            num_multi_gpu_tower_stacks: For each stack of multi-GPU towers, how many</span>
<span class="sd">                slots should we reserve for parallel data loading? Set this to &gt;1 to</span>
<span class="sd">                load data into GPUs in parallel. This will increase GPU memory usage</span>
<span class="sd">                proportionally with the number of stacks.</span>
<span class="sd">                Example:</span>
<span class="sd">                2 GPUs and `num_multi_gpu_tower_stacks=3`:</span>
<span class="sd">                - One tower stack consists of 2 GPUs, each with a copy of the</span>
<span class="sd">                model/graph.</span>
<span class="sd">                - Each of the stacks will create 3 slots for batch data on each of its</span>
<span class="sd">                GPUs, increasing memory requirements on each GPU by 3x.</span>
<span class="sd">                - This enables us to preload data into these stacks while another stack</span>
<span class="sd">                is performing gradient calculations.</span>
<span class="sd">            minibatch_buffer_size: How many train batches should be retained for</span>
<span class="sd">                minibatching. This conf only has an effect if `num_epochs &gt; 1`.</span>
<span class="sd">            replay_proportion: Set &gt;0 to enable experience replay. Saved samples will</span>
<span class="sd">                be replayed with a p:1 proportion to new data samples.</span>
<span class="sd">            replay_buffer_num_slots: Number of sample batches to store for replay.</span>
<span class="sd">                The number of transitions saved total will be</span>
<span class="sd">                (replay_buffer_num_slots * rollout_fragment_length).</span>
<span class="sd">            learner_queue_size: Max queue size for train batches feeding into the</span>
<span class="sd">                learner.</span>
<span class="sd">            learner_queue_timeout: Wait for train batches to be available in minibatch</span>
<span class="sd">                buffer queue this many seconds. This may need to be increased e.g. when</span>
<span class="sd">                training with a slow environment.</span>
<span class="sd">            timeout_s_sampler_manager: The timeout for waiting for sampling results</span>
<span class="sd">                for workers -- typically if this is too low, the manager won&#39;t be able</span>
<span class="sd">                to retrieve ready sampling results.</span>
<span class="sd">            timeout_s_aggregator_manager: The timeout for waiting for replay worker</span>
<span class="sd">                results -- typically if this is too low, the manager won&#39;t be able to</span>
<span class="sd">                retrieve ready replay requests.</span>
<span class="sd">            broadcast_interval: Number of training step calls before weights are</span>
<span class="sd">                broadcasted to rollout workers that are sampled during any iteration.</span>
<span class="sd">            grad_clip: If specified, clip the global norm of gradients by this amount.</span>
<span class="sd">            opt_type: Either &quot;adam&quot; or &quot;rmsprop&quot;.</span>
<span class="sd">            lr_schedule: Learning rate schedule. In the format of</span>
<span class="sd">                [[timestep, lr-value], [timestep, lr-value], ...]</span>
<span class="sd">                Intermediary timesteps will be assigned to interpolated learning rate</span>
<span class="sd">                values. A schedule should normally start from timestep 0.</span>
<span class="sd">            decay: Decay setting for the RMSProp optimizer, in case `opt_type=rmsprop`.</span>
<span class="sd">            momentum: Momentum setting for the RMSProp optimizer, in case</span>
<span class="sd">                `opt_type=rmsprop`.</span>
<span class="sd">            epsilon: Epsilon setting for the RMSProp optimizer, in case</span>
<span class="sd">                `opt_type=rmsprop`.</span>
<span class="sd">            vf_loss_coeff: Coefficient for the value function term in the loss function.</span>
<span class="sd">            entropy_coeff: Coefficient for the entropy regularizer term in the loss</span>
<span class="sd">                function.</span>
<span class="sd">            entropy_coeff_schedule: Decay schedule for the entropy regularizer.</span>
<span class="sd">            _separate_vf_optimizer: Set this to true to have two separate optimizers</span>
<span class="sd">                optimize the policy-and value networks. Only supported for some</span>
<span class="sd">                algorithms (APPO, IMPALA) on the old API stack.</span>
<span class="sd">            _lr_vf: If _separate_vf_optimizer is True, define separate learning rate</span>
<span class="sd">                for the value network.</span>

<span class="sd">        Returns:</span>
<span class="sd">            This updated AlgorithmConfig object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">num_aggregation_workers</span> <span class="o">!=</span> <span class="n">DEPRECATED_VALUE</span><span class="p">:</span>
            <span class="n">deprecation_warning</span><span class="p">(</span>
                <span class="n">old</span><span class="o">=</span><span class="s2">&quot;config.training(num_aggregation_workers=..)&quot;</span><span class="p">,</span>
                <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Aggregator workers are no longer supported on the old API &quot;</span>
                <span class="s2">&quot;stack! To use aggregation (and GPU pre-loading) on the new API &quot;</span>
                <span class="s2">&quot;stack, activate the new API stack, then set &quot;</span>
                <span class="s2">&quot;`config.learners(num_aggregator_actors_per_learner=..)`. Good &quot;</span>
                <span class="s2">&quot;choices are normally 1 or 2, but this depends on your overall &quot;</span>
                <span class="s2">&quot;setup, especially your `EnvRunner` throughput.&quot;</span><span class="p">,</span>
                <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">max_requests_in_flight_per_aggregator_worker</span> <span class="o">!=</span> <span class="n">DEPRECATED_VALUE</span><span class="p">:</span>
            <span class="n">deprecation_warning</span><span class="p">(</span>
                <span class="n">old</span><span class="o">=</span><span class="s2">&quot;config.training(max_requests_in_flight_per_aggregator_worker=..)&quot;</span><span class="p">,</span>
                <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Aggregator workers are no longer supported on the old API &quot;</span>
                <span class="s2">&quot;stack! To use aggregation (and GPU pre-loading) on the new API &quot;</span>
                <span class="s2">&quot;stack, activate the new API stack and THEN set &quot;</span>
                <span class="s2">&quot;`config.learners(max_requests_in_flight_per_aggregator_actor=..)&quot;</span>
                <span class="s2">&quot;`.&quot;</span><span class="p">,</span>
                <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Pass kwargs onto super&#39;s `training()` method.</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">training</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">vtrace</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vtrace</span> <span class="o">=</span> <span class="n">vtrace</span>
        <span class="k">if</span> <span class="n">vtrace_clip_rho_threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vtrace_clip_rho_threshold</span> <span class="o">=</span> <span class="n">vtrace_clip_rho_threshold</span>
        <span class="k">if</span> <span class="n">vtrace_clip_pg_rho_threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vtrace_clip_pg_rho_threshold</span> <span class="o">=</span> <span class="n">vtrace_clip_pg_rho_threshold</span>
        <span class="k">if</span> <span class="n">num_gpu_loader_threads</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_gpu_loader_threads</span> <span class="o">=</span> <span class="n">num_gpu_loader_threads</span>
        <span class="k">if</span> <span class="n">num_multi_gpu_tower_stacks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_multi_gpu_tower_stacks</span> <span class="o">=</span> <span class="n">num_multi_gpu_tower_stacks</span>
        <span class="k">if</span> <span class="n">minibatch_buffer_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_buffer_size</span> <span class="o">=</span> <span class="n">minibatch_buffer_size</span>
        <span class="k">if</span> <span class="n">replay_proportion</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replay_proportion</span> <span class="o">=</span> <span class="n">replay_proportion</span>
        <span class="k">if</span> <span class="n">replay_buffer_num_slots</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer_num_slots</span> <span class="o">=</span> <span class="n">replay_buffer_num_slots</span>
        <span class="k">if</span> <span class="n">learner_queue_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">learner_queue_size</span> <span class="o">=</span> <span class="n">learner_queue_size</span>
        <span class="k">if</span> <span class="n">learner_queue_timeout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">learner_queue_timeout</span> <span class="o">=</span> <span class="n">learner_queue_timeout</span>
        <span class="k">if</span> <span class="n">broadcast_interval</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_interval</span> <span class="o">=</span> <span class="n">broadcast_interval</span>
        <span class="k">if</span> <span class="n">timeout_s_sampler_manager</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">timeout_s_sampler_manager</span> <span class="o">=</span> <span class="n">timeout_s_sampler_manager</span>
        <span class="k">if</span> <span class="n">timeout_s_aggregator_manager</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">timeout_s_aggregator_manager</span> <span class="o">=</span> <span class="n">timeout_s_aggregator_manager</span>
        <span class="k">if</span> <span class="n">grad_clip</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">grad_clip</span> <span class="o">=</span> <span class="n">grad_clip</span>
        <span class="k">if</span> <span class="n">opt_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">opt_type</span> <span class="o">=</span> <span class="n">opt_type</span>
        <span class="k">if</span> <span class="n">lr_schedule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedule</span> <span class="o">=</span> <span class="n">lr_schedule</span>
        <span class="k">if</span> <span class="n">decay</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decay</span> <span class="o">=</span> <span class="n">decay</span>
        <span class="k">if</span> <span class="n">momentum</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="k">if</span> <span class="n">epsilon</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="k">if</span> <span class="n">vf_loss_coeff</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">vf_loss_coeff</span> <span class="o">=</span> <span class="n">vf_loss_coeff</span>
        <span class="k">if</span> <span class="n">entropy_coeff</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coeff</span> <span class="o">=</span> <span class="n">entropy_coeff</span>
        <span class="k">if</span> <span class="n">entropy_coeff_schedule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coeff_schedule</span> <span class="o">=</span> <span class="n">entropy_coeff_schedule</span>
        <span class="k">if</span> <span class="n">_separate_vf_optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_separate_vf_optimizer</span> <span class="o">=</span> <span class="n">_separate_vf_optimizer</span>
        <span class="k">if</span> <span class="n">_lr_vf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_lr_vf</span> <span class="o">=</span> <span class="n">_lr_vf</span>

        <span class="k">return</span> <span class="bp">self</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">debugging</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">_env_runners_only</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="n">_skip_learners</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">NotProvided</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets the debugging related configuration.</span>

<span class="sd">        Args:</span>
<span class="sd">            _env_runners_only: If True, only run (remote) EnvRunner requests, discard</span>
<span class="sd">                their episode/training data, but log their metrics results. Aggregator-</span>
<span class="sd">                and Learner actors won&#39;t be used.</span>
<span class="sd">            _skip_learners: If True, no `update` requests are sent to the LearnerGroup</span>
<span class="sd">                and Learner actors. Only EnvRunners and aggregator actors (if</span>
<span class="sd">                applicable) are used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">debugging</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">_env_runners_only</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_env_runners_only</span> <span class="o">=</span> <span class="n">_env_runners_only</span>
        <span class="k">if</span> <span class="n">_skip_learners</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">NotProvided</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_skip_learners</span> <span class="o">=</span> <span class="n">_skip_learners</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">AlgorithmConfig</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">validate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Call the super class&#39; validation method first.</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">validate</span><span class="p">()</span>

        <span class="c1"># IMPALA and APPO need vtrace (A3C Policies no longer exist).</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">vtrace</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_value_error</span><span class="p">(</span>
                <span class="s2">&quot;IMPALA and APPO do NOT support vtrace=False anymore! Set &quot;</span>
                <span class="s2">&quot;`config.training(vtrace=True)`.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># New API stack checks.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_env_runner_and_connector_v2</span><span class="p">:</span>
            <span class="c1"># Does NOT support aggregation workers yet or a mixin replay buffer.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_ratio</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_value_error</span><span class="p">(</span>
                    <span class="s2">&quot;The new API stack in combination with the new EnvRunner API &quot;</span>
                    <span class="s2">&quot;does NOT support a mixin replay buffer yet for &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2"> (set `config.replay_proportion` to 0.0)!&quot;</span>
                <span class="p">)</span>
            <span class="c1"># `lr_schedule` checking.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_value_error</span><span class="p">(</span>
                    <span class="s2">&quot;`lr_schedule` is deprecated and must be None! Use the &quot;</span>
                    <span class="s2">&quot;`lr` setting to setup a schedule.&quot;</span>
                <span class="p">)</span>
            <span class="c1"># Entropy coeff schedule checking.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coeff_schedule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_value_error</span><span class="p">(</span>
                    <span class="s2">&quot;`entropy_coeff_schedule` is deprecated and must be None! Use the &quot;</span>
                    <span class="s2">&quot;`entropy_coeff` setting to setup a schedule.&quot;</span>
                <span class="p">)</span>
            <span class="n">Scheduler</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span>
                <span class="n">fixed_value_or_schedule</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">entropy_coeff</span><span class="p">,</span>
                <span class="n">setting_name</span><span class="o">=</span><span class="s2">&quot;entropy_coeff&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="s2">&quot;entropy coefficient&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">rollout_fragment_length</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_train_batch_size</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_value_error</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`minibatch_size` (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_minibatch_size</span><span class="si">}</span><span class="s2">) must either be None &quot;</span>
                    <span class="s2">&quot;or a multiple of `rollout_fragment_length` &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rollout_fragment_length</span><span class="si">}</span><span class="s2">) while at the same time smaller &quot;</span>
                    <span class="s2">&quot;than or equal to `total_train_batch_size` &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">total_train_batch_size</span><span class="si">}</span><span class="s2">)!&quot;</span>
                <span class="p">)</span>
        <span class="c1"># Old API stack checks.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">entropy_coeff</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coeff</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_value_error</span><span class="p">(</span><span class="s2">&quot;`entropy_coeff` must be &gt;= 0.0&quot;</span><span class="p">)</span>

        <span class="c1"># If two separate optimizers/loss terms used for tf, must also set</span>
        <span class="c1"># `_tf_policy_handles_more_than_one_loss` to True.</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">framework_str</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;tf&quot;</span><span class="p">,</span> <span class="s2">&quot;tf2&quot;</span><span class="p">]</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_vf_optimizer</span> <span class="ow">is</span> <span class="kc">True</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tf_policy_handles_more_than_one_loss</span> <span class="ow">is</span> <span class="kc">False</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_value_error</span><span class="p">(</span>
                <span class="s2">&quot;`_tf_policy_handles_more_than_one_loss` must be set to True, for &quot;</span>
                <span class="s2">&quot;TFPolicy to support more than one loss term/optimizer! Try setting &quot;</span>
                <span class="s2">&quot;config.training(_tf_policy_handles_more_than_one_loss=True).&quot;</span>
            <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">replay_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns replay ratio (between 0.0 and 1.0) based off self.replay_proportion.</span>

<span class="sd">        Formula: ratio = 1 / proportion</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_proportion</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_proportion</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">AlgorithmConfig</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_default_learner_class</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework_str</span> <span class="o">==</span> <span class="s2">&quot;torch&quot;</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.algorithms.impala.torch.impala_torch_learner</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
                <span class="n">IMPALATorchLearner</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">return</span> <span class="n">IMPALATorchLearner</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework_str</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;tf2&quot;</span><span class="p">,</span> <span class="s2">&quot;tf&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;TensorFlow is no longer supported on the new API stack! &quot;</span>
                <span class="s2">&quot;Use `framework=&#39;torch&#39;`.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The framework </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">framework_str</span><span class="si">}</span><span class="s2"> is not supported. &quot;</span>
                <span class="s2">&quot;Use `framework=&#39;torch&#39;`.&quot;</span>
            <span class="p">)</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">AlgorithmConfig</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_default_rl_module_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RLModuleSpec</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework_str</span> <span class="o">==</span> <span class="s2">&quot;torch&quot;</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.algorithms.ppo.torch.default_ppo_torch_rl_module</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
                <span class="n">DefaultPPOTorchRLModule</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">return</span> <span class="n">RLModuleSpec</span><span class="p">(</span><span class="n">module_class</span><span class="o">=</span><span class="n">DefaultPPOTorchRLModule</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The framework </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">framework_str</span><span class="si">}</span><span class="s2"> is not supported. &quot;</span>
                <span class="s2">&quot;Use either &#39;torch&#39; or &#39;tf2&#39;.&quot;</span>
            <span class="p">)</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">AlgorithmConfig</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">build_learner_connector</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_observation_space</span><span class="p">,</span>
        <span class="n">input_action_space</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">connector</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">build_learner_connector</span><span class="p">(</span>
            <span class="n">input_observation_space</span><span class="p">,</span>
            <span class="n">input_action_space</span><span class="p">,</span>
            <span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_default_connectors_to_learner_pipeline</span><span class="p">:</span>
            <span class="c1"># Extend all episodes by one artificial timestep to allow the value function</span>
            <span class="c1"># net to compute the bootstrap values (and add a mask to the batch to know,</span>
            <span class="c1"># which slots to mask out).</span>
            <span class="n">connector</span><span class="o">.</span><span class="n">prepend</span><span class="p">(</span><span class="n">AddOneTsToEpisodesAndTruncate</span><span class="p">())</span>
            <span class="c1"># Remove the NumpyToTensor connector if we have the GPULoaderThreads.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_aggregator_actors_per_learner</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">connector</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">NumpyToTensor</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">connector</span></div>



<span class="n">ImpalaConfig</span> <span class="o">=</span> <span class="n">IMPALAConfig</span>


<span class="k">class</span><span class="w"> </span><span class="nc">IMPALA</span><span class="p">(</span><span class="n">Algorithm</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Importance weighted actor/learner architecture (IMPALA) Algorithm</span>

<span class="sd">    == Overview of data flow in IMPALA ==</span>
<span class="sd">    1. Policy evaluation in parallel across `num_env_runners` actors produces</span>
<span class="sd">       batches of size `rollout_fragment_length * num_envs_per_env_runner`.</span>
<span class="sd">    2. If enabled, the replay buffer stores and produces batches of size</span>
<span class="sd">       `rollout_fragment_length * num_envs_per_env_runner`.</span>
<span class="sd">    3. If enabled, the minibatch ring buffer stores and replays batches of</span>
<span class="sd">       size `train_batch_size` up to `num_epochs` times per batch.</span>
<span class="sd">    4. The learner thread executes data parallel SGD across `num_gpus` GPUs</span>
<span class="sd">       on batches of size `train_batch_size`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@classmethod</span>
    <span class="nd">@override</span><span class="p">(</span><span class="n">Algorithm</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_default_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">IMPALAConfig</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">IMPALAConfig</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="nd">@override</span><span class="p">(</span><span class="n">Algorithm</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_default_policy_class</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">AlgorithmConfig</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">Policy</span><span class="p">]]:</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">framework_str</span> <span class="o">==</span> <span class="s2">&quot;torch&quot;</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.algorithms.impala.impala_torch_policy</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
                <span class="n">ImpalaTorchPolicy</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">return</span> <span class="n">ImpalaTorchPolicy</span>

        <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">framework_str</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.algorithms.impala.impala_tf_policy</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
                <span class="n">ImpalaTF1Policy</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">return</span> <span class="n">ImpalaTF1Policy</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">ray.rllib.algorithms.impala.impala_tf_policy</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
                <span class="n">ImpalaTF2Policy</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">return</span> <span class="n">ImpalaTF2Policy</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">Algorithm</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">AlgorithmConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Queue of data to be sent to the Learner.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_to_place_on_learner</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_mixin_buffer</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># @OldAPIStack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_being_built</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># @OldAPIStack</span>

        <span class="c1"># Create extra aggregation workers and assign each rollout worker to one of</span>
        <span class="c1"># them.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_episode_packs_being_built</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ma_batches_being_built</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">i</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_learners</span> <span class="ow">or</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">}</span>

        <span class="c1"># Create local mixin buffer if on old API stack and replay</span>
        <span class="c1"># proportion is set.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">enable_rl_module_and_learner</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">replay_proportion</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">local_mixin_buffer</span> <span class="o">=</span> <span class="n">MixInMultiAgentReplayBuffer</span><span class="p">(</span>
                    <span class="n">capacity</span><span class="o">=</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">replay_buffer_num_slots</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">replay_buffer_num_slots</span> <span class="o">&gt;</span> <span class="mi">0</span>
                        <span class="k">else</span> <span class="mi">1</span>
                    <span class="p">),</span>
                    <span class="n">replay_ratio</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">replay_ratio</span><span class="p">,</span>
                    <span class="n">replay_mode</span><span class="o">=</span><span class="n">ReplayMode</span><span class="o">.</span><span class="n">LOCKSTEP</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># This variable is used to keep track of the statistics from the most recent</span>
        <span class="c1"># update of the learner group</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_results</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">enable_rl_module_and_learner</span><span class="p">:</span>
            <span class="c1"># Create and start the learner thread.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_learner_thread</span> <span class="o">=</span> <span class="n">make_learner_thread</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_learner_thread</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">Algorithm</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">TimerAndPrometheusLogger</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_time</span><span class="p">):</span>
            <span class="c1"># Old API stack.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">enable_rl_module_and_learner</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_step_old_api_stack</span><span class="p">()</span>

            <span class="n">do_async_updates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_learners</span> <span class="o">&gt;</span> <span class="mi">0</span>

            <span class="c1"># Asynchronously request all EnvRunners to sample and return their current</span>
            <span class="c1"># (e.g. ConnectorV2) states and sampling metrics/stats.</span>
            <span class="c1"># Note that each item in `episode_refs` is a reference to a list of Episodes.</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_time</span><span class="p">((</span><span class="n">TIMERS</span><span class="p">,</span> <span class="n">SAMPLE_TIMER</span><span class="p">)):</span>
                <span class="p">(</span>
                    <span class="n">episode_refs</span><span class="p">,</span>
                    <span class="n">connector_states</span><span class="p">,</span>
                    <span class="n">env_runner_metrics</span><span class="p">,</span>
                    <span class="n">env_runner_indices_to_update</span><span class="p">,</span>
                <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_and_get_connector_states</span><span class="p">()</span>
                <span class="c1"># Reduce EnvRunner metrics over the n EnvRunners.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span>
                    <span class="n">env_runner_metrics</span><span class="p">,</span>
                    <span class="n">key</span><span class="o">=</span><span class="n">ENV_RUNNER_RESULTS</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># Log the average number of sample results (list of episodes) received.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">ENV_RUNNER_RESULTS</span><span class="p">,</span> <span class="n">MEAN_NUM_EPISODE_LISTS_RECEIVED</span><span class="p">),</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">episode_refs</span><span class="p">),</span>
                <span class="p">)</span>

            <span class="c1"># Only run EnvRunners, nothing else.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">_env_runners_only</span><span class="p">:</span>
                <span class="k">return</span>

            <span class="c1"># &quot;Batch&quot; collected episode refs into groups, such that exactly</span>
            <span class="c1"># `total_train_batch_size` timesteps are sent to</span>
            <span class="c1"># `LearnerGroup.update()`.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_aggregator_actors_per_learner</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">TimerAndPrometheusLogger</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_aggregator_preprocessing_time</span>
                <span class="p">):</span>
                    <span class="n">data_packages_for_aggregators</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pre_queue_episode_refs</span><span class="p">(</span>
                        <span class="n">episode_refs</span><span class="p">,</span>
                        <span class="n">package_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train_batch_size_per_learner</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">AGGREGATOR_ACTOR_RESULTS</span><span class="p">,</span> <span class="s2">&quot;mean_num_input_packages&quot;</span><span class="p">),</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">episode_refs</span><span class="p">),</span>
                    <span class="p">)</span>

                    <span class="n">ma_batches_refs_remote_results</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_aggregator_actor_manager</span><span class="o">.</span><span class="n">fetch_ready_async_reqs</span><span class="p">(</span>
                            <span class="n">return_obj_refs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">tags</span><span class="o">=</span><span class="s2">&quot;get_batches&quot;</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">ma_batches_refs</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">for</span> <span class="n">call_result</span> <span class="ow">in</span> <span class="n">ma_batches_refs_remote_results</span><span class="p">:</span>
                        <span class="n">ma_batches_refs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="p">(</span><span class="n">call_result</span><span class="o">.</span><span class="n">actor_id</span><span class="p">,</span> <span class="n">call_result</span><span class="o">.</span><span class="n">get</span><span class="p">())</span>
                        <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">AGGREGATOR_ACTOR_RESULTS</span><span class="p">,</span> <span class="s2">&quot;mean_num_output_batches&quot;</span><span class="p">),</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">ma_batches_refs</span><span class="p">),</span>
                    <span class="p">)</span>

                    <span class="k">while</span> <span class="n">data_packages_for_aggregators</span><span class="p">:</span>
                        <span class="n">num_agg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_aggregator_actors_per_learner</span> <span class="o">*</span> <span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_learners</span> <span class="ow">or</span> <span class="mi">1</span>
                        <span class="p">)</span>
                        <span class="n">packs</span><span class="p">,</span> <span class="n">data_packages_for_aggregators</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">data_packages_for_aggregators</span><span class="p">[:</span><span class="n">num_agg</span><span class="p">],</span>
                            <span class="n">data_packages_for_aggregators</span><span class="p">[</span><span class="n">num_agg</span><span class="p">:],</span>
                        <span class="p">)</span>
                        <span class="n">sent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregator_actor_manager</span><span class="o">.</span><span class="n">foreach_actor_async</span><span class="p">(</span>
                            <span class="n">func</span><span class="o">=</span><span class="s2">&quot;get_batch&quot;</span><span class="p">,</span>
                            <span class="n">kwargs</span><span class="o">=</span><span class="p">[</span><span class="nb">dict</span><span class="p">(</span><span class="n">episode_refs</span><span class="o">=</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">packs</span><span class="p">],</span>
                            <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;get_batches&quot;</span><span class="p">,</span>
                        <span class="p">)</span>

                        <span class="n">_dropped</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train_batch_size_per_learner</span> <span class="o">*</span> <span class="p">(</span>
                            <span class="nb">len</span><span class="p">(</span><span class="n">packs</span><span class="p">)</span> <span class="o">-</span> <span class="n">sent</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="n">_dropped</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_env_steps_dropped</span><span class="o">.</span><span class="n">inc</span><span class="p">(</span>
                                <span class="n">value</span><span class="o">=</span><span class="n">_dropped</span>
                            <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                            <span class="p">(</span>
                                <span class="n">AGGREGATOR_ACTOR_RESULTS</span><span class="p">,</span>
                                <span class="s2">&quot;num_env_steps_dropped_lifetime&quot;</span><span class="p">,</span>
                            <span class="p">),</span>
                            <span class="n">_dropped</span><span class="p">,</span>
                            <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="c1"># Get n lists of m ObjRef[MABatch] (m=num_learners) to perform n calls to</span>
                    <span class="c1"># all learner workers with the already GPU-located batches.</span>
                    <span class="n">data_packages_for_learner_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pre_queue_batch_refs</span><span class="p">(</span>
                        <span class="n">ma_batches_refs</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_packages_for_learner_group</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_input_batches</span><span class="o">.</span><span class="n">inc</span><span class="p">(</span>
                            <span class="n">value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data_packages_for_learner_group</span><span class="p">)</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_zero_input_batches</span><span class="o">.</span><span class="n">inc</span><span class="p">(</span>
                            <span class="n">value</span><span class="o">=</span><span class="mi">1</span>
                        <span class="p">)</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">AGGREGATOR_ACTOR_RESULTS</span><span class="p">,</span> <span class="s2">&quot;num_env_steps_aggregated_lifetime&quot;</span><span class="p">),</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train_batch_size_per_learner</span>
                        <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_learners</span> <span class="ow">or</span> <span class="mi">1</span><span class="p">)</span>
                        <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_packages_for_learner_group</span><span class="p">),</span>
                        <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
                        <span class="n">with_throughput</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">data_packages_for_learner_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pre_queue_episode_refs</span><span class="p">(</span>
                    <span class="n">episode_refs</span><span class="p">,</span> <span class="n">package_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">total_train_batch_size</span>
                <span class="p">)</span>

            <span class="c1"># Skip Learner update calls.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">_skip_learners</span><span class="p">:</span>
                <span class="k">return</span>

            <span class="c1"># Call the LearnerGroup&#39;s `update()` method.</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_time</span><span class="p">((</span><span class="n">TIMERS</span><span class="p">,</span> <span class="n">LEARNER_UPDATE_TIMER</span><span class="p">)):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                    <span class="n">key</span><span class="o">=</span><span class="n">MEAN_NUM_LEARNER_GROUP_UPDATE_CALLED</span><span class="p">,</span>
                    <span class="n">value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data_packages_for_learner_group</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="n">rl_module_state</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">num_learner_group_results_received</span> <span class="o">=</span> <span class="mi">0</span>

                <span class="n">return_state</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">peek</span><span class="p">(</span>
                        <span class="n">NUM_TRAINING_STEP_CALLS_SINCE_LAST_SYNCH_WORKER_WEIGHTS</span><span class="p">,</span>
                        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">broadcast_interval</span>
                <span class="p">)</span>
                <span class="k">with</span> <span class="n">TimerAndPrometheusLogger</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_learner_group_loop_time</span>
                <span class="p">):</span>
                    <span class="k">for</span> <span class="p">(</span>
                        <span class="n">batch_ref_or_episode_list_ref</span>
                    <span class="p">)</span> <span class="ow">in</span> <span class="n">data_packages_for_learner_group</span><span class="p">:</span>
                        <span class="n">timesteps</span> <span class="o">=</span> <span class="p">{</span>
                            <span class="n">NUM_ENV_STEPS_SAMPLED_LIFETIME</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">peek</span><span class="p">(</span>
                                <span class="p">(</span><span class="n">ENV_RUNNER_RESULTS</span><span class="p">,</span> <span class="n">NUM_ENV_STEPS_SAMPLED_LIFETIME</span><span class="p">),</span>
                                <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                            <span class="p">),</span>
                            <span class="n">NUM_ENV_STEPS_TRAINED_LIFETIME</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">peek</span><span class="p">(</span>
                                <span class="p">(</span>
                                    <span class="n">LEARNER_RESULTS</span><span class="p">,</span>
                                    <span class="n">ALL_MODULES</span><span class="p">,</span>
                                    <span class="n">NUM_ENV_STEPS_TRAINED_LIFETIME</span><span class="p">,</span>
                                <span class="p">),</span>
                                <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                            <span class="p">),</span>
                        <span class="p">}</span>
                        <span class="c1"># Update from batch refs coming from AggregatorActors.</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_aggregator_actors_per_learner</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_ref_or_episode_list_ref</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_learners</span> <span class="ow">or</span> <span class="mi">1</span>
                            <span class="p">)</span>
                            <span class="n">training_data</span> <span class="o">=</span> <span class="n">TrainingData</span><span class="p">(</span>
                                <span class="n">batch_refs</span><span class="o">=</span><span class="n">batch_ref_or_episode_list_ref</span>
                            <span class="p">)</span>
                        <span class="c1"># Update from episodes refs coming from EnvRunner actors.</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">training_data</span> <span class="o">=</span> <span class="n">TrainingData</span><span class="p">(</span>
                                <span class="n">episodes_refs</span><span class="o">=</span><span class="n">batch_ref_or_episode_list_ref</span>
                            <span class="p">)</span>
                        <span class="n">learner_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learner_group</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                            <span class="n">training_data</span><span class="o">=</span><span class="n">training_data</span><span class="p">,</span>
                            <span class="n">async_update</span><span class="o">=</span><span class="n">do_async_updates</span><span class="p">,</span>
                            <span class="n">return_state</span><span class="o">=</span><span class="n">return_state</span><span class="p">,</span>
                            <span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span><span class="p">,</span>
                            <span class="n">num_epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">,</span>
                            <span class="n">minibatch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span>
                            <span class="n">shuffle_batch_per_epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">shuffle_batch_per_epoch</span><span class="p">,</span>
                        <span class="p">)</span>
                        <span class="c1"># Only request weights from 1st Learner - at most - once per</span>
                        <span class="c1"># `training_step` call.</span>
                        <span class="n">return_state</span> <span class="o">=</span> <span class="kc">False</span>

                        <span class="n">num_learner_group_results_received</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">learner_results</span><span class="p">)</span>
                        <span class="c1"># Extract the last (most recent) weights matrix, if available.</span>
                        <span class="k">for</span> <span class="n">result_from_1_learner</span> <span class="ow">in</span> <span class="n">learner_results</span><span class="p">:</span>
                            <span class="n">rl_module_state</span> <span class="o">=</span> <span class="n">result_from_1_learner</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                                <span class="s2">&quot;_rl_module_state_after_update&quot;</span><span class="p">,</span> <span class="n">rl_module_state</span>
                            <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span>
                            <span class="n">stats_dicts</span><span class="o">=</span><span class="n">learner_results</span><span class="p">,</span>
                            <span class="n">key</span><span class="o">=</span><span class="n">LEARNER_RESULTS</span><span class="p">,</span>
                        <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                    <span class="n">key</span><span class="o">=</span><span class="p">(</span><span class="n">LEARNER_GROUP</span><span class="p">,</span> <span class="n">MEAN_NUM_LEARNER_RESULTS_RECEIVED</span><span class="p">),</span>
                    <span class="n">value</span><span class="o">=</span><span class="n">num_learner_group_results_received</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                <span class="n">NUM_TRAINING_STEP_CALLS_SINCE_LAST_SYNCH_WORKER_WEIGHTS</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span>
            <span class="p">)</span>

            <span class="c1"># Update LearnerGroup&#39;s own stats.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learner_group</span><span class="o">.</span><span class="n">get_stats</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="n">LEARNER_GROUP</span><span class="p">)</span>

            <span class="c1"># Figure out, whether we should sync/broadcast the (remote) EnvRunner states.</span>
            <span class="c1"># Note: `learner_results` is a List of n (num async calls) Lists of m</span>
            <span class="c1"># (num Learner workers) ResultDicts each.</span>
            <span class="k">if</span> <span class="n">rl_module_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span>
                    <span class="n">NUM_TRAINING_STEP_CALLS_SINCE_LAST_SYNCH_WORKER_WEIGHTS</span><span class="p">,</span> <span class="mi">0</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span><span class="n">NUM_SYNCH_WORKER_WEIGHTS</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">)</span>
                <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_time</span><span class="p">((</span><span class="n">TIMERS</span><span class="p">,</span> <span class="n">SYNCH_WORKER_WEIGHTS_TIMER</span><span class="p">)):</span>
                    <span class="k">with</span> <span class="n">TimerAndPrometheusLogger</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_sync_env_runner_state_time</span>
                    <span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">env_runner_group</span><span class="o">.</span><span class="n">sync_env_runner_states</span><span class="p">(</span>
                            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                            <span class="n">connector_states</span><span class="o">=</span><span class="n">connector_states</span><span class="p">,</span>
                            <span class="n">rl_module_state</span><span class="o">=</span><span class="n">rl_module_state</span><span class="p">,</span>
                            <span class="n">env_to_module</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env_to_module_connector</span><span class="p">,</span>
                            <span class="n">module_to_env</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module_to_env_connector</span><span class="p">,</span>
                        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_sample_and_get_connector_states</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">TimerAndPrometheusLogger</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_sample_and_get_connector_states_time</span>
        <span class="p">):</span>
            <span class="n">env_runner_indices_to_update</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
            <span class="n">episode_refs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">connector_states</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">env_runner_metrics</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">num_healthy_remote_workers</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">env_runner_group</span><span class="o">.</span><span class="n">num_healthy_remote_workers</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="c1"># Perform asynchronous sampling on all (healthy) remote rollout workers.</span>
            <span class="k">if</span> <span class="n">num_healthy_remote_workers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">async_results</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">env_runner_group</span><span class="o">.</span><span class="n">foreach_env_runner_async_fetch_ready</span><span class="p">(</span>
                        <span class="n">func</span><span class="o">=</span><span class="s2">&quot;sample_get_state_and_metrics&quot;</span><span class="p">,</span>
                        <span class="n">tag</span><span class="o">=</span><span class="s2">&quot;sample_get_state_and_metrics&quot;</span><span class="p">,</span>
                        <span class="n">timeout_seconds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">timeout_s_sampler_manager</span><span class="p">,</span>
                        <span class="n">return_obj_refs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">return_actor_ids</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="c1"># Get results from the n different async calls and store those EnvRunner</span>
                <span class="c1"># indices we should update.</span>
                <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">async_results</span><span class="p">:</span>
                    <span class="n">env_runner_indices_to_update</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

                <span class="k">for</span> <span class="p">(</span><span class="n">episodes</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
                    <span class="n">episode_refs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episodes</span><span class="p">)</span>
                    <span class="n">connector_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
                    <span class="n">env_runner_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
            <span class="c1"># Sample from the local EnvRunner.</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">episodes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
                <span class="n">env_runner_metrics</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="o">.</span><span class="n">get_metrics</span><span class="p">()]</span>
                <span class="n">episode_refs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">episodes</span><span class="p">)]</span>
                <span class="n">connector_states</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="o">.</span><span class="n">get_state</span><span class="p">(</span>
                        <span class="n">components</span><span class="o">=</span><span class="p">[</span>
                            <span class="n">COMPONENT_ENV_TO_MODULE_CONNECTOR</span><span class="p">,</span>
                            <span class="n">COMPONENT_MODULE_TO_ENV_CONNECTOR</span><span class="p">,</span>
                        <span class="p">]</span>
                    <span class="p">)</span>
                <span class="p">]</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">episode_refs</span><span class="p">,</span>
            <span class="n">connector_states</span><span class="p">,</span>
            <span class="n">env_runner_metrics</span><span class="p">,</span>
            <span class="n">env_runner_indices_to_update</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_pre_queue_episode_refs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">episode_refs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">],</span> <span class="n">package_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">]]:</span>
        <span class="c1"># Each element in this list is itself a list of ObjRef[Episodes].</span>
        <span class="c1"># Each ObjRef was returned by one EnvRunner from a single sample() call.</span>
        <span class="n">episodes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">episode_refs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_episode_packs_being_built</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ref</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_episode_packs_being_built</span><span class="p">)</span>
                <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_envs_per_env_runner</span>
                <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get_rollout_fragment_length</span><span class="p">()</span>
                <span class="o">&gt;=</span> <span class="n">package_size</span>
            <span class="p">):</span>
                <span class="n">episodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_episode_packs_being_built</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_episode_packs_being_built</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">return</span> <span class="n">episodes</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_pre_queue_batch_refs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">batch_refs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">ObjectRef</span><span class="p">]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">]]:</span>
        <span class="c1"># `batch_refs` is a list of tuple(aggregator_actor_id, ObjRef[MABatch]).</span>

        <span class="c1"># Each ObjRef[MABatch] was returned by one AggregatorActor from a single</span>
        <span class="c1"># `get_batch()` call.</span>
        <span class="c1"># TODO (sven): Add this comment, once valid:</span>
        <span class="c1">#  .. and the underlying MABatch is already located on a particular GPU</span>
        <span class="c1">#  (matching one particular Learner).</span>
        <span class="k">for</span> <span class="n">agg_actor_id</span><span class="p">,</span> <span class="n">ma_batch_ref</span> <span class="ow">in</span> <span class="n">batch_refs</span><span class="p">:</span>
            <span class="n">learner_actor_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregator_actor_to_learner</span><span class="p">[</span><span class="n">agg_actor_id</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ma_batches_being_built</span><span class="p">[</span><span class="n">learner_actor_id</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ma_batch_ref</span><span class="p">)</span>

        <span class="c1"># Construct an n-group of batches (n=num_learners) as long as we still have</span>
        <span class="c1"># at least one batch per learner in our queue.</span>
        <span class="n">batch_refs_for_learner_group</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">while</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">learner_list</span> <span class="k">for</span> <span class="n">learner_list</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ma_batches_being_built</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="n">batch_refs_for_learner_group</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">learner_list</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">learner_list</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ma_batches_being_built</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                <span class="p">]</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">batch_refs_for_learner_group</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">Algorithm</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_set_up_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_set_up_metrics</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_time</span> <span class="o">=</span> <span class="n">Histogram</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rllib_algorithms_impala_training_step_time&quot;</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Time spent in IMPALA.training_step()&quot;</span><span class="p">,</span>
            <span class="n">boundaries</span><span class="o">=</span><span class="n">DEFAULT_HISTOGRAM_BOUNDARIES_SHORT_EVENTS</span><span class="p">,</span>
            <span class="n">tag_keys</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;rllib&quot;</span><span class="p">,),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_time</span><span class="o">.</span><span class="n">set_default_tags</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;rllib&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">}</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_aggregator_preprocessing_time</span> <span class="o">=</span> <span class="n">Histogram</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rllib_algorithms_impala_training_step_aggregator_preprocessing_time&quot;</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Time spent preprocessing episodes with aggregator actor in the IMPALA.training_step()&quot;</span><span class="p">,</span>
            <span class="n">boundaries</span><span class="o">=</span><span class="n">DEFAULT_HISTOGRAM_BOUNDARIES_SHORT_EVENTS</span><span class="p">,</span>
            <span class="n">tag_keys</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;rllib&quot;</span><span class="p">,),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_aggregator_preprocessing_time</span><span class="o">.</span><span class="n">set_default_tags</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;rllib&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">}</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_learner_group_loop_time</span> <span class="o">=</span> <span class="n">Histogram</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rllib_algorithms_impala_training_step_learner_group_loop_time&quot;</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Time spent in the learner group update calls loop, in the IMPALA.training_step()&quot;</span><span class="p">,</span>
            <span class="n">boundaries</span><span class="o">=</span><span class="n">DEFAULT_HISTOGRAM_BOUNDARIES_SHORT_EVENTS</span><span class="p">,</span>
            <span class="n">tag_keys</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;rllib&quot;</span><span class="p">,),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_learner_group_loop_time</span><span class="o">.</span><span class="n">set_default_tags</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;rllib&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">}</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_sync_env_runner_state_time</span> <span class="o">=</span> <span class="n">Histogram</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rllib_algorithms_impala_training_step_sync_env_runner_state_time&quot;</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Time spent on syncing EnvRunner states in the IMPALA.training_step()&quot;</span><span class="p">,</span>
            <span class="n">boundaries</span><span class="o">=</span><span class="n">DEFAULT_HISTOGRAM_BOUNDARIES_SHORT_EVENTS</span><span class="p">,</span>
            <span class="n">tag_keys</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;rllib&quot;</span><span class="p">,),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_sync_env_runner_state_time</span><span class="o">.</span><span class="n">set_default_tags</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;rllib&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">}</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_sample_and_get_connector_states_time</span> <span class="o">=</span> <span class="n">Histogram</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rllib_algorithms_impala_sample_and_get_connector_states_time&quot;</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Time spent in IMPALA._sample_and_get_connector_states()&quot;</span><span class="p">,</span>
            <span class="n">boundaries</span><span class="o">=</span><span class="n">DEFAULT_HISTOGRAM_BOUNDARIES_SHORT_EVENTS</span><span class="p">,</span>
            <span class="n">tag_keys</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;rllib&quot;</span><span class="p">,),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_sample_and_get_connector_states_time</span><span class="o">.</span><span class="n">set_default_tags</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;rllib&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">}</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_input_batches</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rllib_algorithms_impala_training_step_input_batches_counter&quot;</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Number of input batches processed and passed to the learner in the IMPALA.training_step()&quot;</span><span class="p">,</span>
            <span class="n">tag_keys</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;rllib&quot;</span><span class="p">,),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_input_batches</span><span class="o">.</span><span class="n">set_default_tags</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;rllib&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">}</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_zero_input_batches</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rllib_algorithms_impala_training_step_zero_input_batches_counter&quot;</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Number of times zero input batches were ready in the IMPALA.training_step()&quot;</span><span class="p">,</span>
            <span class="n">tag_keys</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;rllib&quot;</span><span class="p">,),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_zero_input_batches</span><span class="o">.</span><span class="n">set_default_tags</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;rllib&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">}</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_env_steps_dropped</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rllib_algorithms_impala_training_step_env_steps_dropped_counter&quot;</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Number of env steps dropped when sending data to the aggregator actors in the IMPALA.training_step()&quot;</span><span class="p">,</span>
            <span class="n">tag_keys</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;rllib&quot;</span><span class="p">,),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_impala_training_step_env_steps_dropped</span><span class="o">.</span><span class="n">set_default_tags</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;rllib&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">}</span>
        <span class="p">)</span>

    <span class="nd">@OldAPIStack</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_training_step_old_api_stack</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># First, check, whether our learner thread is still healthy.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learner_thread</span><span class="o">.</span><span class="n">is_alive</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;The learner thread died while training!&quot;</span><span class="p">)</span>

        <span class="c1"># Get sampled SampleBatches from our workers (by ray references if we use</span>
        <span class="c1"># tree-aggregation).</span>
        <span class="n">unprocessed_sample_batches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_samples_from_workers_old_api_stack</span><span class="p">(</span>
            <span class="n">return_object_refs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Tag workers that actually produced ready sample batches this iteration.</span>
        <span class="c1"># Those workers will have to get updated at the end of the iteration.</span>
        <span class="n">workers_that_need_updates</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">worker_id</span> <span class="k">for</span> <span class="n">worker_id</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">unprocessed_sample_batches</span>
        <span class="p">}</span>

        <span class="c1"># Resolve collected batches here on local process (using the mixin buffer).</span>
        <span class="n">batches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_experiences_old_api_stack</span><span class="p">(</span><span class="n">unprocessed_sample_batches</span><span class="p">)</span>

        <span class="c1"># Increase sampling counters now that we have the actual SampleBatches on</span>
        <span class="c1"># the local process (and can measure their sizes).</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_counters</span><span class="p">[</span><span class="n">NUM_ENV_STEPS_SAMPLED</span><span class="p">]</span> <span class="o">+=</span> <span class="n">batch</span><span class="o">.</span><span class="n">count</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_counters</span><span class="p">[</span><span class="n">NUM_AGENT_STEPS_SAMPLED</span><span class="p">]</span> <span class="o">+=</span> <span class="n">batch</span><span class="o">.</span><span class="n">agent_steps</span><span class="p">()</span>

        <span class="c1"># Concatenate single batches into batches of size `total_train_batch_size`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_concatenate_batches_and_pre_queue</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>
        <span class="c1"># Move train batches (of size `total_train_batch_size`) onto learner queue.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_place_processed_samples_on_learner_thread_queue</span><span class="p">()</span>
        <span class="c1"># Extract most recent train results from learner thread.</span>
        <span class="n">train_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_trained_results</span><span class="p">()</span>

        <span class="c1"># Sync worker weights (only those policies that were actually updated).</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_timers</span><span class="p">[</span><span class="n">SYNCH_WORKER_WEIGHTS_TIMER</span><span class="p">]:</span>
            <span class="n">pids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">train_results</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_workers_old_api_stack</span><span class="p">(</span>
                <span class="n">workers_that_need_updates</span><span class="o">=</span><span class="n">workers_that_need_updates</span><span class="p">,</span>
                <span class="n">policy_ids</span><span class="o">=</span><span class="n">pids</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># With a training step done, try to bring any aggregators back to life</span>
        <span class="c1"># if necessary.</span>
        <span class="c1"># AggregatorActor are stateless, so we do not need to restore any</span>
        <span class="c1"># state here.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregator_actor_manager</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_aggregator_actor_manager</span><span class="o">.</span><span class="n">probe_unhealthy_actors</span><span class="p">(</span>
                <span class="n">timeout_seconds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_runner_health_probe_timeout_s</span><span class="p">,</span>
                <span class="n">mark_healthy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">train_results</span>

    <span class="nd">@OldAPIStack</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_get_samples_from_workers_old_api_stack</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">return_object_refs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">,</span> <span class="n">SampleBatchType</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get samples from rollout workers for training.</span>

<span class="sd">        Args:</span>
<span class="sd">            return_object_refs: If True, return ObjectRefs instead of the samples</span>
<span class="sd">                directly. This is useful when using aggregator workers so that data</span>
<span class="sd">                collected on rollout workers is directly de referenced on the aggregator</span>
<span class="sd">                workers instead of first in the driver and then on the aggregator</span>
<span class="sd">                workers.</span>

<span class="sd">        Returns:</span>
<span class="sd">            a list of tuples of (worker_index, sample batch or ObjectRef to a sample</span>
<span class="sd">                batch)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_timers</span><span class="p">[</span><span class="n">SAMPLE_TIMER</span><span class="p">]:</span>
            <span class="c1"># Sample from healthy remote workers by default. If there is no healthy</span>
            <span class="c1"># worker (either because they have all died, or because there was none to</span>
            <span class="c1"># begin) check if the local_worker exists. If the local worker has an</span>
            <span class="c1"># env_instance (either because there are no remote workers or</span>
            <span class="c1"># self.config.create_local_env_runner == True), then sample from the</span>
            <span class="c1"># local worker. Otherwise just return an empty list.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_runner_group</span><span class="o">.</span><span class="n">num_healthy_remote_workers</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Perform asynchronous sampling on all (remote) rollout workers.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">env_runner_group</span><span class="o">.</span><span class="n">foreach_env_runner_async</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">worker</span><span class="p">:</span> <span class="n">worker</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
                <span class="p">)</span>
                <span class="n">sample_batches</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span>
                    <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">ObjectRef</span><span class="p">]</span>
                <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_runner_group</span><span class="o">.</span><span class="n">fetch_ready_async_reqs</span><span class="p">(</span>
                    <span class="n">timeout_seconds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">timeout_s_sampler_manager</span><span class="p">,</span>
                    <span class="n">return_obj_refs</span><span class="o">=</span><span class="n">return_object_refs</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_env_runners</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="o">.</span><span class="n">async_env</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="p">):</span>
                <span class="c1"># Sampling from the local worker</span>
                <span class="n">sample_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">return_object_refs</span><span class="p">:</span>
                    <span class="n">sample_batch</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">sample_batch</span><span class="p">)</span>
                <span class="n">sample_batches</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sample_batch</span><span class="p">)]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Not much we can do. Return empty list and wait.</span>
                <span class="n">sample_batches</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">return</span> <span class="n">sample_batches</span>

    <span class="nd">@OldAPIStack</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_process_experiences_old_api_stack</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">worker_to_sample_batches</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">SampleBatchType</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Process sample batches directly on the driver, for training.</span>

<span class="sd">        Args:</span>
<span class="sd">            worker_to_sample_batches: List of (worker_id, sample_batch) tuples.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Batches that have been processed by the mixin buffer.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batches</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">worker_to_sample_batches</span><span class="p">]</span>
        <span class="n">processed_batches</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
            <span class="k">assert</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">batch</span><span class="p">,</span> <span class="n">ObjectRef</span>
            <span class="p">),</span> <span class="s2">&quot;`IMPALA._process_experiences_old_api_stack` can not handle ObjectRefs!&quot;</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">decompress_if_needed</span><span class="p">()</span>
            <span class="c1"># Only make a pass through the buffer, if replay proportion is &gt; 0.0 (and</span>
            <span class="c1"># we actually have one).</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_mixin_buffer</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">local_mixin_buffer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_mixin_buffer</span><span class="o">.</span><span class="n">replay</span><span class="p">(</span><span class="n">_ALL_POLICIES</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># TODO(jjyao) somehow deep copy the batch</span>
                <span class="c1"># fix a memory leak issue. Need to investigate more</span>
                <span class="c1"># to know why.</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">batch</span><span class="p">:</span>
                <span class="n">processed_batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">processed_batches</span>

    <span class="nd">@OldAPIStack</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_concatenate_batches_and_pre_queue</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batches</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SampleBatch</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Concatenate batches that are being returned from rollout workers</span>

<span class="sd">        Args:</span>
<span class="sd">            batches: List of batches of experiences from EnvRunners.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">aggregate_into_larger_batch</span><span class="p">():</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">sum</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">count</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_being_built</span><span class="p">)</span>
                <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">total_train_batch_size</span>
            <span class="p">):</span>
                <span class="n">batch_to_add</span> <span class="o">=</span> <span class="n">concat_samples</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_being_built</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data_to_place_on_learner</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_to_add</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_batch_being_built</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
            <span class="c1"># TODO (sven): Strange bug after a RolloutWorker crash and proper</span>
            <span class="c1">#  restart. The bug is related to (old, non-V2) connectors being used and</span>
            <span class="c1">#  seems to happen inside the AgentCollector&#39;s `add_action_reward_next_obs`</span>
            <span class="c1">#  method, at the end of which the number of vf_preds (and all other</span>
            <span class="c1">#  extra action outs) in the batch is one smaller than the number of obs/</span>
            <span class="c1">#  actions/rewards, which then leads to a malformed train batch.</span>
            <span class="c1">#  IMPALA/APPO crash inside the loss function (during v-trace operations)</span>
            <span class="c1">#  b/c of the resulting shape mismatch. The following if-block prevents</span>
            <span class="c1">#  this from happening and it can be removed once we are on the new API</span>
            <span class="c1">#  stack for good (and use the new connectors and also no longer</span>
            <span class="c1">#  AgentCollectors, RolloutWorkers, Policies, TrajectoryView API, etc..):</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">batch_mode</span> <span class="o">==</span> <span class="s2">&quot;truncate_episodes&quot;</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">restart_failed_env_runners</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="nb">any</span><span class="p">(</span>
                    <span class="n">SampleBatch</span><span class="o">.</span><span class="n">VF_PREDS</span> <span class="ow">in</span> <span class="n">pb</span>
                    <span class="ow">and</span> <span class="p">(</span>
                        <span class="n">pb</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">VF_PREDS</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="o">!=</span> <span class="n">pb</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">REWARDS</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">pb</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">policy_batches</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                <span class="p">):</span>
                    <span class="k">continue</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_being_built</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">aggregate_into_larger_batch</span><span class="p">()</span>

    <span class="nd">@OldAPIStack</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_place_processed_samples_on_learner_thread_queue</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Place processed samples on the learner queue for training.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_to_place_on_learner</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_learner_thread</span><span class="o">.</span><span class="n">inqueue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span>
                    <span class="n">batch</span><span class="p">,</span>
                    <span class="c1"># Setting block = True for the very last item in our list prevents</span>
                    <span class="c1"># the learner thread, this main thread, and the GPU loader threads</span>
                    <span class="c1"># from thrashing when there are more samples than the learner can</span>
                    <span class="c1"># reasonably process.</span>
                    <span class="c1"># see https://github.com/ray-project/ray/pull/26581#issuecomment-1187877674  # noqa</span>
                    <span class="n">block</span><span class="o">=</span><span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_to_place_on_learner</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_counters</span><span class="p">[</span><span class="s2">&quot;num_samples_added_to_queue&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span>
                    <span class="n">batch</span><span class="o">.</span><span class="n">agent_steps</span><span class="p">()</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">count_steps_by</span> <span class="o">==</span> <span class="s2">&quot;agent_steps&quot;</span>
                    <span class="k">else</span> <span class="n">batch</span><span class="o">.</span><span class="n">count</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="n">queue</span><span class="o">.</span><span class="n">Full</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_counters</span><span class="p">[</span><span class="s2">&quot;num_times_learner_queue_full&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">data_to_place_on_learner</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

    <span class="nd">@OldAPIStack</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_process_trained_results</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ResultDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Process training results that are outputed by the learner thread.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Aggregated results from the learner thread after an update is completed.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get learner outputs/stats from output queue.</span>
        <span class="n">num_env_steps_trained</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">num_agent_steps_trained</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">learner_infos</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Loop through output queue and update our counts.</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_learner_thread</span><span class="o">.</span><span class="n">outqueue</span><span class="o">.</span><span class="n">qsize</span><span class="p">()):</span>
            <span class="p">(</span>
                <span class="n">env_steps</span><span class="p">,</span>
                <span class="n">agent_steps</span><span class="p">,</span>
                <span class="n">learner_results</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learner_thread</span><span class="o">.</span><span class="n">outqueue</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

            <span class="n">num_env_steps_trained</span> <span class="o">+=</span> <span class="n">env_steps</span>
            <span class="n">num_agent_steps_trained</span> <span class="o">+=</span> <span class="n">agent_steps</span>
            <span class="k">if</span> <span class="n">learner_results</span><span class="p">:</span>
                <span class="n">learner_infos</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">learner_results</span><span class="p">)</span>
        <span class="c1"># Nothing new happened since last time, use the same learner stats.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">learner_infos</span><span class="p">:</span>
            <span class="n">final_learner_info</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_learner_thread</span><span class="o">.</span><span class="n">learner_info</span><span class="p">)</span>
        <span class="c1"># Accumulate learner stats using the `LearnerInfoBuilder` utility.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">builder</span> <span class="o">=</span> <span class="n">LearnerInfoBuilder</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">info</span> <span class="ow">in</span> <span class="n">learner_infos</span><span class="p">:</span>
                <span class="n">builder</span><span class="o">.</span><span class="n">add_learn_on_batch_results_multi_agent</span><span class="p">(</span><span class="n">info</span><span class="p">)</span>
            <span class="n">final_learner_info</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">finalize</span><span class="p">()</span>

        <span class="c1"># Update the steps trained counters.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_counters</span><span class="p">[</span><span class="n">NUM_ENV_STEPS_TRAINED</span><span class="p">]</span> <span class="o">+=</span> <span class="n">num_env_steps_trained</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_counters</span><span class="p">[</span><span class="n">NUM_AGENT_STEPS_TRAINED</span><span class="p">]</span> <span class="o">+=</span> <span class="n">num_agent_steps_trained</span>

        <span class="k">return</span> <span class="n">final_learner_info</span>

    <span class="nd">@OldAPIStack</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_update_workers_old_api_stack</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">workers_that_need_updates</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">policy_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">PolicyID</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates all RolloutWorkers that require updating.</span>

<span class="sd">        Updates only if NUM_TRAINING_STEP_CALLS_SINCE_LAST_SYNCH_WORKER_WEIGHTS has been</span>
<span class="sd">        reached and the worker has sent samples in this iteration. Also only updates</span>
<span class="sd">        those policies, whose IDs are given via `policies` (if None, update all</span>
<span class="sd">        policies).</span>

<span class="sd">        Args:</span>
<span class="sd">            workers_that_need_updates: Set of worker IDs that need to be updated.</span>
<span class="sd">            policy_ids: Optional list of Policy IDs to update. If None, will update all</span>
<span class="sd">                policies on the to-be-updated workers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Update global vars of the local worker.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">policy_states_are_swappable</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="o">.</span><span class="n">lock</span><span class="p">()</span>
        <span class="n">global_vars</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;timestep&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counters</span><span class="p">[</span><span class="n">NUM_AGENT_STEPS_TRAINED</span><span class="p">],</span>
            <span class="s2">&quot;num_grad_updates_per_policy&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">pid</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="o">.</span><span class="n">policy_map</span><span class="p">[</span><span class="n">pid</span><span class="p">]</span><span class="o">.</span><span class="n">num_grad_updates</span>
                <span class="k">for</span> <span class="n">pid</span> <span class="ow">in</span> <span class="n">policy_ids</span> <span class="ow">or</span> <span class="p">[]</span>
            <span class="p">},</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="o">.</span><span class="n">set_global_vars</span><span class="p">(</span><span class="n">global_vars</span><span class="p">,</span> <span class="n">policy_ids</span><span class="o">=</span><span class="n">policy_ids</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">policy_states_are_swappable</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="o">.</span><span class="n">unlock</span><span class="p">()</span>

        <span class="c1"># Only need to update workers if there are remote workers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_counters</span><span class="p">[</span><span class="n">NUM_TRAINING_STEP_CALLS_SINCE_LAST_SYNCH_WORKER_WEIGHTS</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env_runner_group</span><span class="o">.</span><span class="n">num_remote_workers</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_counters</span><span class="p">[</span><span class="n">NUM_TRAINING_STEP_CALLS_SINCE_LAST_SYNCH_WORKER_WEIGHTS</span><span class="p">]</span>
            <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">broadcast_interval</span>
            <span class="ow">and</span> <span class="n">workers_that_need_updates</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">policy_states_are_swappable</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="o">.</span><span class="n">lock</span><span class="p">()</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="o">.</span><span class="n">get_weights</span><span class="p">(</span><span class="n">policy_ids</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">policy_states_are_swappable</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">env_runner</span><span class="o">.</span><span class="n">unlock</span><span class="p">()</span>
            <span class="n">weights_ref</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_learner_thread</span><span class="o">.</span><span class="n">policy_ids_updated</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_counters</span><span class="p">[</span><span class="n">NUM_TRAINING_STEP_CALLS_SINCE_LAST_SYNCH_WORKER_WEIGHTS</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_counters</span><span class="p">[</span><span class="n">NUM_SYNCH_WORKER_WEIGHTS</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env_runner_group</span><span class="o">.</span><span class="n">foreach_env_runner</span><span class="p">(</span>
                <span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">w</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">weights_ref</span><span class="p">),</span> <span class="n">global_vars</span><span class="p">),</span>
                <span class="n">local_env_runner</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">remote_worker_ids</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">workers_that_need_updates</span><span class="p">),</span>
                <span class="n">timeout_seconds</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># Don&#39;t wait for the workers to finish.</span>
            <span class="p">)</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">Algorithm</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_compile_iteration_results_old_api_stack</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_compile_iteration_results_old_api_stack</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">enable_rl_module_and_learner</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learner_thread</span><span class="o">.</span><span class="n">add_learner_metrics</span><span class="p">(</span>
                <span class="n">result</span><span class="p">,</span> <span class="n">overwrite_learner_info</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>


<span class="n">Impala</span> <span class="o">=</span> <span class="n">IMPALA</span>


<span class="nd">@OldAPIStack</span>
<span class="k">def</span><span class="w"> </span><span class="nf">make_learner_thread</span><span class="p">(</span><span class="n">local_worker</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;simple_optimizer&quot;</span><span class="p">]:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Enabling multi-GPU mode, </span><span class="si">{}</span><span class="s2"> GPUs, </span><span class="si">{}</span><span class="s2"> parallel tower-stacks&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_multi_gpu_tower_stacks&quot;</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">num_stacks</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_multi_gpu_tower_stacks&quot;</span><span class="p">]</span>
        <span class="n">buffer_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;minibatch_buffer_size&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">num_stacks</span> <span class="o">&lt;</span> <span class="n">buffer_size</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;In multi-GPU mode you should have at least as many &quot;</span>
                <span class="s2">&quot;multi-GPU tower stacks (to load data into on one device) as &quot;</span>
                <span class="s2">&quot;you have stack-index slots in the buffer! You have &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;configured </span><span class="si">{</span><span class="n">num_stacks</span><span class="si">}</span><span class="s2"> stacks and a buffer of size &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">buffer_size</span><span class="si">}</span><span class="s2">. Setting &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;`minibatch_buffer_size=</span><span class="si">{</span><span class="n">num_stacks</span><span class="si">}</span><span class="s2">`.&quot;</span>
            <span class="p">)</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;minibatch_buffer_size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_stacks</span>

        <span class="n">learner_thread</span> <span class="o">=</span> <span class="n">MultiGPULearnerThread</span><span class="p">(</span>
            <span class="n">local_worker</span><span class="p">,</span>
            <span class="n">num_gpus</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">],</span>
            <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span>
            <span class="n">train_batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;train_batch_size&quot;</span><span class="p">],</span>
            <span class="n">num_multi_gpu_tower_stacks</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_multi_gpu_tower_stacks&quot;</span><span class="p">],</span>
            <span class="n">num_sgd_iter</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">],</span>
            <span class="n">learner_queue_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;learner_queue_size&quot;</span><span class="p">],</span>
            <span class="n">learner_queue_timeout</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;learner_queue_timeout&quot;</span><span class="p">],</span>
            <span class="n">num_data_load_threads</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_gpu_loader_threads&quot;</span><span class="p">],</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">learner_thread</span> <span class="o">=</span> <span class="n">LearnerThread</span><span class="p">(</span>
            <span class="n">local_worker</span><span class="p">,</span>
            <span class="n">minibatch_buffer_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;minibatch_buffer_size&quot;</span><span class="p">],</span>
            <span class="n">num_sgd_iter</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">],</span>
            <span class="n">learner_queue_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;learner_queue_size&quot;</span><span class="p">],</span>
            <span class="n">learner_queue_timeout</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;learner_queue_timeout&quot;</span><span class="p">],</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">learner_thread</span>
</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="footer-content-items footer-content__inner">
  
    <div class="footer-content-item"><div id="csat">
  <div id="csat-feedback-received" class="csat-hidden">
    <span>Thanks for the feedback!</span>
  </div>
  <div id="csat-inputs">
    <span>Was this helpful?</span>
    <div id="csat-yes" class="csat-button">
      <svg id="csat-yes-icon" class="csat-hidden csat-icon" width="18" height="13" viewBox="0 0 18 13" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 10.172L16.1922 0.979004L17.6072 2.393L7.00023 13L0.63623 6.636L2.05023 5.222L7.00023 10.172Z" />
      </svg>
      <span>Yes</span>
    </div>
    <div id="csat-no" class="csat-button">
      <svg id="csat-no-icon" class="csat-hidden csat-icon" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 5.58599L11.9502 0.635986L13.3642 2.04999L8.41423 6.99999L13.3642 11.95L11.9502 13.364L7.00023 8.41399L2.05023 13.364L0.63623 11.95L5.58623 6.99999L0.63623 2.04999L2.05023 0.635986L7.00023 5.58599Z" />
      </svg>
      <span>No</span>
    </div>
  </div>
  <div id="csat-textarea-group" class="csat-hidden">
    <span id="csat-feedback-label">Feedback</span>
    <textarea id="csat-textarea"></textarea>
    <div id="csat-submit">Submit</div>
  </div>
</div></div>
  
</div>

          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
      © Copyright 2025, The Ray Team.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.14.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>