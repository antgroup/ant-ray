<!-- prettier-ignore -->

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.rllib.core.learner.learner &#8212; Ray 2.43.1</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../../../../../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../../../../../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../../../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/css/termynal.css?v=2fc3cb5e" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/css/csat.css?v=c8f39c76" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/css/assistant.css?v=d345c55e" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/css/custom.css?v=633d7681" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/docsearch.css?v=45fb5152" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/pydata-docsearch-custom.css?v=7fb92720" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../../../../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script src="../../../../../_static/documentation_options.js?v=3624d774"></script>
    <script src="../../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../../_static/copybutton.js?v=9a29e97e"></script>
    <script defer="defer" src="../../../../../_static/js/termynal.js?v=67cfcf08"></script>
    <script defer="defer" src="../../../../../_static/js/custom.js?v=9e3b357f"></script>
    <script src="../../../../../_static/js/csat.js?v=8e649b1c"></script>
    <script defer="defer" src="../../../../../_static/js/assistant.js?v=73fdc522"></script>
    <script defer="defer" src="../../../../../_static/docsearch.js?v=77274085"></script>
    <script defer="defer" src="../../../../../_static/docsearch_config.js?v=d25523ed"></script>
    <script src="../../../../../_static/design-tabs.js?v=36754332"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/ray/rllib/core/learner/learner';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.14.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://antgroup.github.io/ant-ray/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'releases/ant-2.43.1';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = false;
        </script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/rllib/core/learner/learner.html" />
    <link rel="icon" href="../../../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../../../genindex.html" /><!-- Extra header to include at the top of each template.
Kept separately so that it can easily be included in any templates
that need to be overridden for individual pages; e.g. included
both in the usual template (layout.html) as well as (index.html). -->

<link rel="preconnect" href="https://fonts.googleapis.com" />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link
  href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;900&family=Roboto:wght@400;500;700&display=swap"
  rel="stylesheet"
/>
<link
  rel="stylesheet"
  title="light"
  href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
  disabled="disabled"
/>
<link
  rel="stylesheet"
  title="dark"
  href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css"
  disabled="disabled"
/>
<link
  href="https://cdn.jsdelivr.net/npm/remixicon@4.1.0/fonts/remixicon.css"
  rel="stylesheet"
/>

<!-- Used for text embedded in html on the index page  -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- Parser used to call hljs on responses from Ray Assistant -->
<script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

<!-- Sanitizer for Ray Assistant AI -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/dompurify/2.3.3/purify.min.js"></script>

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<!-- Google Tag Manager -->
<script>
  (function (w, d, s, l, i) {
    w[l] = w[l] || [];
    w[l].push({
      'gtm.start': new Date().getTime(),
      event: 'gtm.js',
    });
    var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s),
      dl = l != 'dataLayer' ? '&l=' + l : '';
    j.async = true;
    j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
    f.parentNode.insertBefore(j, f);
  })(window, document, 'script', 'dataLayer', 'GTM-P8H6KQG');
</script>
<!-- End Google Tag Manager -->
<!-- Data to be shared with JS on every page -->
<script>
  window.data = {
      copyIconSrc: "../../../../../_static/copy-button.svg"
  };
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../../../../index.html">
  <svg width="400" height="201" viewBox="0 0 400 201" xmlns="http://www.w3.org/2000/svg">
<path id="ray-text" d="M325.949 134.356V109.785L302.442 66.6406H314.244L330.495 97.3062H331.946L348.198 66.6406H360L336.493 109.785V134.356H325.949ZM253.043 134.364L272.391 66.648H290.771L310.021 134.364H299.283L294.834 118.402H268.328L263.878 134.364H253.043ZM270.94 108.728H292.222L282.354 73.1294H280.807L270.94 108.728ZM198.887 134.364V66.648H227.327C231.519 66.648 235.195 67.3896 238.355 68.8729C241.58 70.2918 244.063 72.3555 245.804 75.0641C247.61 77.7727 248.513 80.9973 248.513 84.7378V85.8019C248.513 90.0583 247.481 93.4763 245.417 96.0559C243.418 98.5711 240.967 100.345 238.065 101.376V102.924C240.516 103.053 242.483 103.892 243.966 105.439C245.449 106.923 246.191 109.083 246.191 111.921V134.364H235.647V113.372C235.647 111.631 235.195 110.244 234.292 109.212C233.39 108.18 231.938 107.664 229.939 107.664H209.334V134.364H198.887ZM209.334 98.1842H226.166C229.907 98.1842 232.809 97.249 234.873 95.3788C236.937 93.4441 237.968 90.8322 237.968 87.5431V86.7692C237.968 83.4802 236.937 80.9005 234.873 79.0303C232.874 77.0956 229.971 76.1282 226.166 76.1282H209.334V98.1842Z" fill="black"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M143.63 101.311L98.3087 146.632L94.9903 143.313L140.311 97.9925L143.63 101.311ZM141.953 102.334L51.4454 102.334V97.6409L141.953 97.6409V102.334ZM94.992 55.9863L140.313 101.307L143.631 97.9886L98.3105 52.6679L94.992 55.9863Z" fill="#02A0CF"/>
<path d="M40 88.3163H62.6604V110.977H40V88.3163ZM85.3207 88.3163H107.981V110.977H85.3207V88.3163ZM85.3207 43H107.981V65.6604H85.3207V43ZM85.3207 133.645H107.981V156.306H85.3207V133.645ZM130.641 88.3163H153.301V110.977H130.641V88.3163Z" fill="#02A0CF"/>
</svg>

</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <div class="navbar-content docutils container">
<ul class="navbar-toplevel">
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/getting-started.html" title="Get Started"><span class="navbar-link-title">Get Started</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/use-cases.html" title="Use Cases"><span class="navbar-link-title">Use Cases</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/examples.html" title="Example Gallery"><span class="navbar-link-title">Example Gallery</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/installation.html" title="Library"><span class="navbar-link-title">Library</span></a></p>
<i class="fa-solid fa-chevron-down"></i></div>
<div class="navbar-dropdown docutils container">
<ul class="navbar-sublevel">
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-core/walkthrough.html" title="Ray Core"><span class="navbar-link-title">Ray Core</span>Scale general Python applications</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../data/data.html" title="Ray Data"><span class="navbar-link-title">Ray Data</span>Scale data ingest and preprocessing</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../train/train.html" title="Ray Train"><span class="navbar-link-title">Ray Train</span>Scale machine learning training</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../tune/index.html" title="Ray Tune"><span class="navbar-link-title">Ray Tune</span>Scale hyperparameter tuning</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../serve/index.html" title="Ray Serve"><span class="navbar-link-title">Ray Serve</span>Scale model serving</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../rllib/index.html" title="Ray RLlib"><span class="navbar-link-title">Ray RLlib</span>Scale reinforcement learning</a></p>
</div>
</li>
</ul>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../index.html" title="Docs"><span class="navbar-link-title">Docs</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://discuss.ray.io" title="Resources"><span class="navbar-link-title">Resources</span></a></p>
<i class="fa-solid fa-chevron-down"></i></div>
<div class="navbar-dropdown docutils container">
<ul class="navbar-sublevel">
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://discuss.ray.io" title="Discussion Forum"><span class="navbar-link-title">Discussion Forum</span>Get your Ray questions answered</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://github.com/ray-project/ray-educational-materials" title="Training"><span class="navbar-link-title">Training</span>Hands-on learning</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/blog" title="Blog"><span class="navbar-link-title">Blog</span>Updates, best practices, user-stories</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/events" title="Events"><span class="navbar-link-title">Events</span>Webinars, meetups, office hours</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/blog/how-ray-and-anyscale-make-it-easy-to-do-massive-scale-machine-learning-on" title="Success Stories"><span class="navbar-link-title">Success Stories</span>Real-world workload examples</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/ray-libraries.html" title="Ecosystem"><span class="navbar-link-title">Ecosystem</span>Libraries integrated with Ray</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.ray.io/community" title="Community"><span class="navbar-link-title">Community</span>Connect with us</a></p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>

</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          <div id="docsearch"></div>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="versionswitcherbutton" type="button" role="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-bs-toggle="dropdown" aria-haspopup="listbox" aria-controls="versionswitcherlist" aria-label="Version switcher list">
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="versionswitcherlist" class="version-switcher__menu dropdown-menu list-group-flush py-0" role="listbox" aria-labelledby="versionswitcherbutton">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
      
        <div class="navbar-item"><a
  id="try-anyscale-href"
  href="https://www.anyscale.com/ray-on-anyscale/?utm_source=ray_docs&utm_medium=docs&utm_campaign=navbar"
>
  <div id="try-anyscale-text">
    <span>Try Ray on Anyscale</span>
  </div>
</a></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile"><div id="docsearch"></div>
    </div>
  

  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <div class="navbar-content docutils container">
<ul class="navbar-toplevel">
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/getting-started.html" title="Get Started"><span class="navbar-link-title">Get Started</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/use-cases.html" title="Use Cases"><span class="navbar-link-title">Use Cases</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/examples.html" title="Example Gallery"><span class="navbar-link-title">Example Gallery</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/installation.html" title="Library"><span class="navbar-link-title">Library</span></a></p>
<i class="fa-solid fa-chevron-down"></i></div>
<div class="navbar-dropdown docutils container">
<ul class="navbar-sublevel">
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-core/walkthrough.html" title="Ray Core"><span class="navbar-link-title">Ray Core</span>Scale general Python applications</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../data/data.html" title="Ray Data"><span class="navbar-link-title">Ray Data</span>Scale data ingest and preprocessing</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../train/train.html" title="Ray Train"><span class="navbar-link-title">Ray Train</span>Scale machine learning training</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../tune/index.html" title="Ray Tune"><span class="navbar-link-title">Ray Tune</span>Scale hyperparameter tuning</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../serve/index.html" title="Ray Serve"><span class="navbar-link-title">Ray Serve</span>Scale model serving</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../rllib/index.html" title="Ray RLlib"><span class="navbar-link-title">Ray RLlib</span>Scale reinforcement learning</a></p>
</div>
</li>
</ul>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../index.html" title="Docs"><span class="navbar-link-title">Docs</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://discuss.ray.io" title="Resources"><span class="navbar-link-title">Resources</span></a></p>
<i class="fa-solid fa-chevron-down"></i></div>
<div class="navbar-dropdown docutils container">
<ul class="navbar-sublevel">
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://discuss.ray.io" title="Discussion Forum"><span class="navbar-link-title">Discussion Forum</span>Get your Ray questions answered</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://github.com/ray-project/ray-educational-materials" title="Training"><span class="navbar-link-title">Training</span>Hands-on learning</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/blog" title="Blog"><span class="navbar-link-title">Blog</span>Updates, best practices, user-stories</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/events" title="Events"><span class="navbar-link-title">Events</span>Webinars, meetups, office hours</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/blog/how-ray-and-anyscale-make-it-easy-to-do-massive-scale-machine-learning-on" title="Success Stories"><span class="navbar-link-title">Success Stories</span>Real-world workload examples</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../../../ray-overview/ray-libraries.html" title="Ecosystem"><span class="navbar-link-title">Ecosystem</span>Libraries integrated with Ray</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.ray.io/community" title="Community"><span class="navbar-link-title">Community</span>Connect with us</a></p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>

</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="versionswitcherbutton" type="button" role="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-bs-toggle="dropdown" aria-haspopup="listbox" aria-controls="versionswitcherlist" aria-label="Version switcher list">
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="versionswitcherlist" class="version-switcher__menu dropdown-menu list-group-flush py-0" role="listbox" aria-labelledby="versionswitcherbutton">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
        
          <div class="navbar-item"><a
  id="try-anyscale-href"
  href="https://www.anyscale.com/ray-on-anyscale/?utm_source=ray_docs&utm_medium=docs&utm_campaign=navbar"
>
  <div id="try-anyscale-text">
    <span>Try Ray on Anyscale</span>
  </div>
</a></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><nav id="main-sidebar" class="bd-docs-nav bd-links" aria-label="Section Navigation">
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-overview/index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-overview/getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-overview/installation.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../ray-overview/use-cases.html">Use Cases</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-air/getting-started.html">Ray for ML Infrastructure</a></li>

</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-overview/examples.html">Example Gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-overview/ray-libraries.html">Ecosystem</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../ray-core/walkthrough.html">Ray Core</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-core/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-core/user-guide.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/tasks.html">Tasks</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/tasks/nested-tasks.html">Nested Remote Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/tasks/generators.html">Dynamic generators</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/actors.html">Actors</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/named-actors.html">Named Actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/terminating-actors.html">Terminating Actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/async_api.html">AsyncIO / Concurrency for Actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/concurrency_group_api.html">Limiting Concurrency Per-Method with Concurrency Groups</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/actor-utils.html">Utility Classes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/out-of-band-communication.html">Out-of-band Communication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/actors/task-orders.html">Actor Task Execution Order</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/objects.html">Objects</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/objects/serialization.html">Serialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/objects/object-spilling.html">Object Spilling</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/handling-dependencies.html">Environment Dependencies</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/scheduling/index.html">Scheduling</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/scheduling/resources.html">Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/scheduling/accelerators.html">Accelerator Support</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/scheduling/placement-group.html">Placement Groups</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/scheduling/memory-management.html">Memory Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/scheduling/ray-oom-prevention.html">Out-Of-Memory Prevention</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/fault-tolerance.html">Fault Tolerance</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/fault_tolerance/tasks.html">Task Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/fault_tolerance/actors.html">Actor Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/fault_tolerance/objects.html">Object Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/fault_tolerance/nodes.html">Node Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/fault_tolerance/gcs.html">GCS Fault Tolerance</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/patterns/index.html">Design Patterns &amp; Anti-patterns</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/nested-tasks.html">Pattern: Using nested tasks to achieve nested parallelism</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/generators.html">Pattern: Using generators to reduce heap memory usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/limit-pending-tasks.html">Pattern: Using ray.wait to limit the number of pending tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/limit-running-tasks.html">Pattern: Using resources to limit the number of concurrently running tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/concurrent-operations-async-actor.html">Pattern: Using asyncio to run actor methods concurrently</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/actor-sync.html">Pattern: Using an actor to synchronize other tasks and actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/tree-of-actors.html">Pattern: Using a supervisor actor to manage a tree of actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/pipelining.html">Pattern: Using pipelining to increase throughput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/return-ray-put.html">Anti-pattern: Returning ray.put() ObjectRefs from a task harms performance and fault tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/ray-get-loop.html">Anti-pattern: Calling ray.get in a loop harms parallelism</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/unnecessary-ray-get.html">Anti-pattern: Calling ray.get unnecessarily harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/ray-get-submission-order.html">Anti-pattern: Processing results in submission order using ray.get increases runtime</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/ray-get-too-many-objects.html">Anti-pattern: Fetching too many objects at once with ray.get causes failure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/too-fine-grained-tasks.html">Anti-pattern: Over-parallelizing with too fine-grained tasks harms speedup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/redefine-task-actor-loop.html">Anti-pattern: Redefining the same remote function or class harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/pass-large-arg-by-value.html">Anti-pattern: Passing the same large argument by value repeatedly harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/closure-capture-large-objects.html">Anti-pattern: Closure capturing large objects harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/global-variables.html">Anti-pattern: Using global variables to share state between tasks and actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/out-of-band-object-ref-serialization.html">Anti-pattern: Serialize ray.ObjectRef out of band</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/patterns/fork-new-processes.html">Anti-pattern: Forking new processes in application code</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/compiled-graph/ray-compiled-graph.html">Ray Compiled Graph</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/compiled-graph/quickstart.html">Quickstart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/compiled-graph/profiling.html">Profiling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/compiled-graph/overlap.html">Experimental: Overlapping communication and computation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/compiled-graph/compiled-graph-api.html">Compiled Graph API</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-core/advanced-topics.html">Advanced Topics</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/tips-for-first-time.html">Tips for first-time users</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/starting-ray.html">Starting Ray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/ray-generator.html">Ray Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/namespaces.html">Using Namespaces</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/cross-language.html">Cross-Language Programming</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/using-ray-with-jupyter.html">Working with Jupyter Notebooks &amp; JupyterLab</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/ray-dag.html">Lazy Computation Graphs with the Ray DAG API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/miscellaneous.html">Miscellaneous Topics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/runtime_env_auth.html">Authenticating Remote URIs in runtime_env</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-core/user-spawn-processes.html">Lifetimes of a User-Spawn Process</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-core/examples/overview.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/automl_for_time_series.html">Simple AutoML for time series with Ray Core</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/batch_prediction.html">Batch Prediction with Ray Core</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/gentle_walkthrough.html">A Gentle Introduction to Ray Core by Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/highly_parallel.html">Using Ray for Highly Parallelizable Tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/map_reduce.html">A Simple MapReduce Example with Ray Core</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/monte_carlo_pi.html">Monte Carlo Estimation of Ï€</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/plot_hyperparameter.html">Simple Parallel Model Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/plot_parameter_server.html">Parameter Server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/plot_pong_example.html">Learning to Play Pong</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/examples/web-crawler.html">Speed up your web crawler by parallelizing it with Ray</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-core/api/index.html">Ray Core API</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/core.html">Core API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/scheduling.html">Scheduling API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/runtime-env.html">Runtime Env API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/utility.html">Utility</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/exceptions.html">Exceptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-core/api/cli.html">Ray Core CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/reference/cli.html">State CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/reference/api.html">State API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../data/data.html">Ray Data</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../data/quickstart.html">Ray Data Quickstart</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../data/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../data/user-guide.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/loading-data.html">Loading Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/inspecting-data.html">Inspecting Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/transforming-data.html">Transforming Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/iterating-over-data.html">Iterating over Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/shuffling-data.html">Shuffling Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/saving-data.html">Saving Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/working-with-images.html">Working with Images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/working-with-text.html">Working with Text</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/working-with-tensors.html">Working with Tensors / NumPy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/working-with-pytorch.html">Working with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/working-with-llms.html">Working with LLMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/monitoring-your-workload.html">Monitoring Your Workload</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/execution-configurations.html">Execution Configurations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/batch_inference.html">End-to-end: Offline Batch Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/performance-tips.html">Advanced: Performance Tips and Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/custom-datasource-example.html">Advanced: Read and Write Custom File Types</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../data/examples.html">Examples</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../data/api/api.html">Ray Data API</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/input_output.html">Input/Output</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/dataset.html">Dataset API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/data_iterator.html">DataIterator API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/execution_options.html">ExecutionOptions API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/aggregate.html">Aggregation API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/grouped_data.html">GroupedData API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/data_context.html">Global configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/preprocessor.html">Preprocessor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/llm.html">Large Language Model (LLM) API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../data/api/from_other_data_libs.html">API Guide for Users from Other Data Libraries</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../data/comparisons.html">Comparing Ray Data to other systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../data/data-internals.html">Ray Data Internals</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../train/train.html">Ray Train</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/getting-started-pytorch.html">PyTorch Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/getting-started-pytorch-lightning.html">PyTorch Lightning Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/getting-started-transformers.html">Hugging Face Transformers Guide</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../train/more-frameworks.html">More Frameworks</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/huggingface-accelerate.html">Hugging Face Accelerate Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/deepspeed.html">DeepSpeed Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/distributed-tensorflow-keras.html">TensorFlow and Keras Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/examples/xgboost/distributed-xgboost-lightgbm.html">XGBoost and LightGBM Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/horovod.html">Horovod Guide</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../train/user-guides.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/data-loading-preprocessing.html">Data Loading and Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/using-gpus.html">Configuring Scale and GPUs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/persistent-storage.html">Configuring Persistent Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/monitoring-logging.html">Monitoring and Logging Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/checkpoints.html">Saving and Loading Checkpoints</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/experiment-tracking.html">Experiment Tracking</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/results.html">Inspecting Training Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/fault-tolerance.html">Handling Failures and Node Preemption</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/reproducibility.html">Reproducibility</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../train/user-guides/hyperparameter-optimization.html">Hyperparameter Optimization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/benchmarks.html">Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../train/api/api.html">Ray Train API</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../tune/index.html">Ray Tune</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../tune/getting-started.html">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../tune/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../tune/tutorials/overview.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-run.html">Running Basic Experiments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-output.html">Logging and Outputs in Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-resources.html">Setting Trial Resources</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-search-spaces.html">Using Search Spaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-stopping.html">How to Define Stopping Criteria for a Ray Tune Experiment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-trial-checkpoints.html">How to Save and Load Trial Checkpoints</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-storage.html">How to Configure Persistent Storage in Ray Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-fault-tolerance.html">How to Enable Fault Tolerance in Ray Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-metrics.html">Using Callbacks and Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune_get_data_in_and_out.html">Getting Data in and out of Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/tune_analyze_results.html">Analyzing Tune Experiment Results</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../tune/examples/pbt_guide.html">A Guide to Population Based Training with Tune</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/pbt_visualization/pbt_visualization.html">Visualizing and Understanding PBT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-distributed.html">Deploying Tune in the Cloud</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-lifecycle.html">Tune Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/tutorials/tune-scalability.html">Scalability Benchmarks</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../tune/examples/index.html">Ray Tune Examples</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../tune/examples/ml-frameworks.html">Examples using Ray Tune with ML Frameworks</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/tune_mnist_keras.html">Keras Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/tune-pytorch-cifar.html">PyTorch Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/tune-pytorch-lightning.html">PyTorch Lightning Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/pbt_ppo_example.html">Ray RLlib Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/tune-xgboost.html">XGBoost Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/lightgbm_example.html">LightGBM Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/horovod_simple.html">Horovod Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/pbt_transformers.html">Hugging Face Transformers Example</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../tune/examples/experiment-tracking.html">Tune Experiment Tracking Examples</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/tune-wandb.html">Weights &amp; Biases Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/tune-mlflow.html">MLflow Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/tune-aim.html">Aim Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/tune-comet.html">Comet Example</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../tune/examples/hpo-frameworks.html">Tune Hyperparameter Optimization Framework Examples</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/ax_example.html">Ax Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/hyperopt_example.html">HyperOpt Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/bayesopt_example.html">Bayesopt Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/bohb_example.html">BOHB Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/nevergrad_example.html">Nevergrad Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../tune/examples/optuna_example.html">Optuna Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/other-examples.html">Other Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/examples/exercises.html">Exercises</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../tune/faq.html">Ray Tune FAQ</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../tune/api/api.html">Ray Tune API</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/execution.html">Tune Execution (tune.Tuner)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/result_grid.html">Tune Experiment Results (tune.ResultGrid)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/trainable.html">Training in Tune (tune.Trainable, tune.report)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/search_space.html">Tune Search Space API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/suggestion.html">Tune Search Algorithms (tune.search)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/schedulers.html">Tune Trial Schedulers (tune.schedulers)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/stoppers.html">Tune Stopping Mechanisms (tune.stopper)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/reporters.html">Tune Console Output (Reporters)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/syncing.html">Syncing in Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/logging.html">Tune Loggers (tune.logger)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/callbacks.html">Tune Callbacks (tune.Callback)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/env.html">Environment variables used by Ray Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/integration.html">External library integrations for Ray Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/internals.html">Tune Internals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../tune/api/cli.html">Tune CLI (Experimental)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../serve/index.html">Ray Serve</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/getting_started.html">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/develop-and-deploy.html">Develop and Deploy an ML Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/model_composition.html">Deploy Compositions of Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/multi-app.html">Deploy Multiple Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/model-multiplexing.html">Model Multiplexing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/configure-serve-deployment.html">Configure Ray Serve deployments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/http-guide.html">Set Up FastAPI and HTTP</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../serve/llm/index.html">Serving LLMs</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/llm/overview.html">Overview</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../serve/llm/api.html">Ray Serve LLM API</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.builders.build_vllm_deployment.html">ray.serve.llm.builders.build_vllm_deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.builders.build_openai_app.html">ray.serve.llm.builders.build_openai_app</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.configs.LLMConfig.html">ray.serve.llm.configs.LLMConfig</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.configs.LLMServingArgs.html">ray.serve.llm.configs.LLMServingArgs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.configs.ModelLoadingConfig.html">ray.serve.llm.configs.ModelLoadingConfig</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.configs.CloudMirrorConfig.html">ray.serve.llm.configs.CloudMirrorConfig</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.configs.LoraConfig.html">ray.serve.llm.configs.LoraConfig</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.deployments.VLLMService.html">ray.serve.llm.deployments.VLLMService</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.deployments.LLMRouter.html">ray.serve.llm.deployments.LLMRouter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.openai_api_models.ChatCompletionRequest.html">ray.serve.llm.openai_api_models.ChatCompletionRequest</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.openai_api_models.CompletionRequest.html">ray.serve.llm.openai_api_models.CompletionRequest</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.openai_api_models.ChatCompletionStreamResponse.html">ray.serve.llm.openai_api_models.ChatCompletionStreamResponse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.openai_api_models.ChatCompletionResponse.html">ray.serve.llm.openai_api_models.ChatCompletionResponse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.openai_api_models.CompletionStreamResponse.html">ray.serve.llm.openai_api_models.CompletionStreamResponse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.openai_api_models.CompletionResponse.html">ray.serve.llm.openai_api_models.CompletionResponse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../serve/llm/doc/ray.serve.llm.openai_api_models.ErrorResponse.html">ray.serve.llm.openai_api_models.ErrorResponse</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../serve/production-guide/index.html">Production Guide</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-31"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/production-guide/config.html">Serve Config Files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/production-guide/kubernetes.html">Deploy on Kubernetes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/production-guide/docker.html">Custom Docker Images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/production-guide/fault-tolerance.html">Add End-to-End Fault Tolerance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/production-guide/handling-dependencies.html">Handle Dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/production-guide/best-practices.html">Best practices in production</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/monitoring.html">Monitor Your Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/resource-allocation.html">Resource Allocation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/autoscaling-guide.html">Ray Serve Autoscaling</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../serve/advanced-guides/index.html">Advanced Guides</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-32"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/app-builder-guide.html">Pass Arguments to Applications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/advanced-autoscaling.html">Advanced Ray Serve Autoscaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/performance.html">Performance Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/dyn-req-batch.html">Dynamic Request Batching</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/inplace-updates.html">Updating Applications In-Place</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/dev-workflow.html">Development Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/grpc-guide.html">Set Up a gRPC Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/managing-java-deployments.html">Experimental Java API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/deploy-vm.html">Deploy on VM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../serve/advanced-guides/multi-app-container.html">Run Multiple Applications in Different Containers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/architecture.html">Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../serve/api/index.html">Ray Serve API</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../rllib/index.html">Ray RLlib</a><input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-33"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../rllib/getting-started.html">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../rllib/key-concepts.html">Key concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../rllib/rllib-env.html">Environments</a><input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-34"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/multi-agent-envs.html">Multi-Agent Environments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/hierarchical-envs.html">Hierarchical Environments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/external-envs.html">External Environments and Applications</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../rllib/algorithm-config.html">AlgorithmConfig API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../rllib/rllib-algorithms.html">Algorithms</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../rllib/user-guides.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-35"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-advanced-api.html">Advanced Python APIs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-callback.html">Callbacks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/checkpoints.html">Checkpointing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/metrics-logger.html">MetricsLogger API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/single-agent-episode.html">Episodes</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-replay-buffers.html">Replay Buffers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-offline.html">Working with offline data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rl-modules.html">RL Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-learner.html">Learner (Alpha)</a></li>



<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-torch2x.html">Using RLlib with torch 2.x compile</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-fault-tolerance.html">Fault Tolerance And Elastic Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/rllib-dev.html">Install RLlib for Development</a></li>




<li class="toctree-l3"><a class="reference internal" href="../../../../../rllib/scaling-guide.html">RLlib scaling guide</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../rllib/rllib-examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../rllib/new-api-stack-migration-guide.html">New API stack migration guide</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/index.html">Ray RLlib API</a><input class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-36"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/algorithm-config.html">Algorithm Configuration API</a><input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-37"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_algo.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_algo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.is_multi_agent.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.is_multi_agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.is_offline.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.is_offline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learner_class.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learner_class</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.model_config.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.model_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.rl_module_spec.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.rl_module_spec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.total_train_batch_size.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.total_train_batch_size</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_learner_class.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_learner_class</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_rl_module_spec.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_rl_module_spec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_evaluation_config_object.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_evaluation_config_object</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_rl_module_spec.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_rl_module_spec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_agent_setup.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_agent_setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_rollout_fragment_length.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_rollout_fragment_length</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.copy.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.validate.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.validate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.freeze.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.freeze</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/algorithm.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-38"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.html">ray.rllib.algorithms.algorithm.Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.setup.html">ray.rllib.algorithms.algorithm.Algorithm.setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.get_default_config.html">ray.rllib.algorithms.algorithm.Algorithm.get_default_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.env_runner.html">ray.rllib.algorithms.algorithm.Algorithm.env_runner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.eval_env_runner.html">ray.rllib.algorithms.algorithm.Algorithm.eval_env_runner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.train.html">ray.rllib.algorithms.algorithm.Algorithm.train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.training_step.html">ray.rllib.algorithms.algorithm.Algorithm.training_step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.save_to_path.html">ray.rllib.algorithms.algorithm.Algorithm.save_to_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.restore_from_path.html">ray.rllib.algorithms.algorithm.Algorithm.restore_from_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.from_checkpoint.html">ray.rllib.algorithms.algorithm.Algorithm.from_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.get_state.html">ray.rllib.algorithms.algorithm.Algorithm.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.set_state.html">ray.rllib.algorithms.algorithm.Algorithm.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.evaluate.html">ray.rllib.algorithms.algorithm.Algorithm.evaluate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.get_module.html">ray.rllib.algorithms.algorithm.Algorithm.get_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.add_policy.html">ray.rllib.algorithms.algorithm.Algorithm.add_policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.remove_policy.html">ray.rllib.algorithms.algorithm.Algorithm.remove_policy</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/callback.html">Callback APIs</a><input class="toctree-checkbox" id="toctree-checkbox-39" name="toctree-checkbox-39" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-39"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.html">ray.rllib.callbacks.callbacks.RLlibCallback</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_algorithm_init.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_algorithm_init</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_sample_end.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_sample_end</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_train_result.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_train_result</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_evaluate_start.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_evaluate_start</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_evaluate_end.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_evaluate_end</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_env_runners_recreated.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_env_runners_recreated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_checkpoint_loaded.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_checkpoint_loaded</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_environment_created.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_environment_created</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_created.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_created</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_start.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_start</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_step.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_end.html">ray.rllib.callbacks.callbacks.RLlibCallback.on_episode_end</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/env.html">Environments</a><input class="toctree-checkbox" id="toctree-checkbox-40" name="toctree-checkbox-40" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-40"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/env_runner.html">EnvRunner API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/single_agent_env_runner.html">SingleAgentEnvRunner API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/single_agent_episode.html">SingleAgentEpisode API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/multi_agent_env.html">MultiAgentEnv API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/multi_agent_env_runner.html">MultiAgentEnvRunner API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/multi_agent_episode.html">MultiAgentEpisode API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/env/utils.html">Env Utils</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/rl_modules.html">RLModule APIs</a><input class="toctree-checkbox" id="toctree-checkbox-41" name="toctree-checkbox-41" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-41"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.build.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.build</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.module_class.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.module_class</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.observation_space.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.observation_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.action_space.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.action_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.inference_only.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.inference_only</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.learner_only.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.learner_only</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.model_config.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.model_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.build.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.build</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.default_model_config.DefaultModelConfig.html">ray.rllib.core.rl_module.default_model_config.DefaultModelConfig</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.html">ray.rllib.core.rl_module.rl_module.RLModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.observation_space.html">ray.rllib.core.rl_module.rl_module.RLModule.observation_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.action_space.html">ray.rllib.core.rl_module.rl_module.RLModule.action_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.inference_only.html">ray.rllib.core.rl_module.rl_module.RLModule.inference_only</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.model_config.html">ray.rllib.core.rl_module.rl_module.RLModule.model_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.setup.html">ray.rllib.core.rl_module.rl_module.RLModule.setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.as_multi_rl_module.html">ray.rllib.core.rl_module.rl_module.RLModule.as_multi_rl_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration.html">ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_inference.html">ray.rllib.core.rl_module.rl_module.RLModule.forward_inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_train.html">ray.rllib.core.rl_module.rl_module.RLModule.forward_train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule._forward.html">ray.rllib.core.rl_module.rl_module.RLModule._forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule._forward_exploration.html">ray.rllib.core.rl_module.rl_module.RLModule._forward_exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule._forward_inference.html">ray.rllib.core.rl_module.rl_module.RLModule._forward_inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule._forward_train.html">ray.rllib.core.rl_module.rl_module.RLModule._forward_train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.save_to_path.html">ray.rllib.core.rl_module.rl_module.RLModule.save_to_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.restore_from_path.html">ray.rllib.core.rl_module.rl_module.RLModule.restore_from_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.from_checkpoint.html">ray.rllib.core.rl_module.rl_module.RLModule.from_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.get_state.html">ray.rllib.core.rl_module.rl_module.RLModule.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.set_state.html">ray.rllib.core.rl_module.rl_module.RLModule.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.setup.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.as_multi_rl_module.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.as_multi_rl_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.add_module.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.add_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.remove_module.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.remove_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.save_to_path.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.save_to_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.restore_from_path.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.restore_from_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.from_checkpoint.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.from_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.get_state.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.set_state.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.set_state</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/distributions.html">Distribution API</a><input class="toctree-checkbox" id="toctree-checkbox-42" name="toctree-checkbox-42" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-42"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.html">ray.rllib.models.distributions.Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.from_logits.html">ray.rllib.models.distributions.Distribution.from_logits</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.sample.html">ray.rllib.models.distributions.Distribution.sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.rsample.html">ray.rllib.models.distributions.Distribution.rsample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.logp.html">ray.rllib.models.distributions.Distribution.logp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.kl.html">ray.rllib.models.distributions.Distribution.kl</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/learner.html">LearnerGroup API</a><input class="toctree-checkbox" id="toctree-checkbox-43" name="toctree-checkbox-43" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-43"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learners.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learners</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner_group.LearnerGroup.html">ray.rllib.core.learner.learner_group.LearnerGroup</a></li>
</ul>
</li>

<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/offline.html">Offline RL API</a><input class="toctree-checkbox" id="toctree-checkbox-44" name="toctree-checkbox-44" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-44"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learners.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.learners</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.env_runners.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.env_runners</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_env_runner.OfflineSingleAgentEnvRunner.html">ray.rllib.offline.offline_env_runner.OfflineSingleAgentEnvRunner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_data.OfflineData.html">ray.rllib.offline.offline_data.OfflineData</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_data.OfflineData.__init__.html">ray.rllib.offline.offline_data.OfflineData.__init__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_data.OfflineData.sample.html">ray.rllib.offline.offline_data.OfflineData.sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_data.OfflineData.default_map_batches_kwargs.html">ray.rllib.offline.offline_data.OfflineData.default_map_batches_kwargs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_data.OfflineData.default_iter_batches_kwargs.html">ray.rllib.offline.offline_data.OfflineData.default_iter_batches_kwargs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner.__init__.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner.__init__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.SCHEMA.html">ray.rllib.offline.offline_prelearner.SCHEMA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner.__call__.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner.__call__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner._map_to_episodes.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner._map_to_episodes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner._map_sample_batch_to_episode.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner._map_sample_batch_to_episode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner._should_module_be_updated.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner._should_module_be_updated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner.default_prelearner_buffer_class.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner.default_prelearner_buffer_class</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.offline.offline_prelearner.OfflinePreLearner.default_prelearner_buffer_kwargs.html">ray.rllib.offline.offline_prelearner.OfflinePreLearner.default_prelearner_buffer_kwargs</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/replay-buffers.html">Replay Buffer API</a><input class="toctree-checkbox" id="toctree-checkbox-45" name="toctree-checkbox-45" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-45"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.StorageUnit.html">ray.rllib.utils.replay_buffers.replay_buffer.StorageUnit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.prioritized_replay_buffer.PrioritizedReplayBuffer.html">ray.rllib.utils.replay_buffers.prioritized_replay_buffer.PrioritizedReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.reservoir_replay_buffer.ReservoirReplayBuffer.html">ray.rllib.utils.replay_buffers.reservoir_replay_buffer.ReservoirReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.sample.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.add.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.add</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.get_state.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.set_state.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.multi_agent_replay_buffer.MultiAgentReplayBuffer.html">ray.rllib.utils.replay_buffers.multi_agent_replay_buffer.MultiAgentReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer.html">ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.utils.update_priorities_in_replay_buffer.html">ray.rllib.utils.replay_buffers.utils.update_priorities_in_replay_buffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.utils.sample_min_n_steps_from_buffer.html">ray.rllib.utils.replay_buffers.utils.sample_min_n_steps_from_buffer</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../rllib/package_ref/utils.html">RLlib Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-46" name="toctree-checkbox-46" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-46"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.metrics.metrics_logger.MetricsLogger.html">ray.rllib.utils.metrics.metrics_logger.MetricsLogger</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.metrics.metrics_logger.MetricsLogger.peek.html">ray.rllib.utils.metrics.metrics_logger.MetricsLogger.peek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_value.html">ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_value</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_dict.html">ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_dict</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.metrics.metrics_logger.MetricsLogger.merge_and_log_n_dicts.html">ray.rllib.utils.metrics.metrics_logger.MetricsLogger.merge_and_log_n_dicts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_time.html">ray.rllib.utils.metrics.metrics_logger.MetricsLogger.log_time</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.schedules.scheduler.Scheduler.html">ray.rllib.utils.schedules.scheduler.Scheduler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.schedules.scheduler.Scheduler.validate.html">ray.rllib.utils.schedules.scheduler.Scheduler.validate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.schedules.scheduler.Scheduler.get_current_value.html">ray.rllib.utils.schedules.scheduler.Scheduler.get_current_value</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.schedules.scheduler.Scheduler.update.html">ray.rllib.utils.schedules.scheduler.Scheduler.update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.schedules.scheduler.Scheduler._create_tensor_variable.html">ray.rllib.utils.schedules.scheduler.Scheduler._create_tensor_variable</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.framework.try_import_torch.html">ray.rllib.utils.framework.try_import_torch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.clip_gradients.html">ray.rllib.utils.torch_utils.clip_gradients</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.compute_global_norm.html">ray.rllib.utils.torch_utils.compute_global_norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.convert_to_torch_tensor.html">ray.rllib.utils.torch_utils.convert_to_torch_tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.explained_variance.html">ray.rllib.utils.torch_utils.explained_variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.flatten_inputs_to_1d_tensor.html">ray.rllib.utils.torch_utils.flatten_inputs_to_1d_tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.global_norm.html">ray.rllib.utils.torch_utils.global_norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.one_hot.html">ray.rllib.utils.torch_utils.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.reduce_mean_ignore_inf.html">ray.rllib.utils.torch_utils.reduce_mean_ignore_inf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.sequence_mask.html">ray.rllib.utils.torch_utils.sequence_mask</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.set_torch_seed.html">ray.rllib.utils.torch_utils.set_torch_seed</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.softmax_cross_entropy_with_logits.html">ray.rllib.utils.torch_utils.softmax_cross_entropy_with_logits</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.update_target_network.html">ray.rllib.utils.torch_utils.update_target_network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.aligned_array.html">ray.rllib.utils.numpy.aligned_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.concat_aligned.html">ray.rllib.utils.numpy.concat_aligned</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.convert_to_numpy.html">ray.rllib.utils.numpy.convert_to_numpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.fc.html">ray.rllib.utils.numpy.fc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.flatten_inputs_to_1d_tensor.html">ray.rllib.utils.numpy.flatten_inputs_to_1d_tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.make_action_immutable.html">ray.rllib.utils.numpy.make_action_immutable</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.huber_loss.html">ray.rllib.utils.numpy.huber_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.l2_loss.html">ray.rllib.utils.numpy.l2_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.lstm.html">ray.rllib.utils.numpy.lstm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.one_hot.html">ray.rllib.utils.numpy.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.relu.html">ray.rllib.utils.numpy.relu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.sigmoid.html">ray.rllib.utils.numpy.sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.numpy.softmax.html">ray.rllib.utils.numpy.softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.checkpoints.try_import_msgpack.html">ray.rllib.utils.checkpoints.try_import_msgpack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../rllib/package_ref/doc/ray.rllib.utils.checkpoints.Checkpointable.html">ray.rllib.utils.checkpoints.Checkpointable</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../ray-more-libs/index.html">More Libraries</a><input class="toctree-checkbox" id="toctree-checkbox-47" name="toctree-checkbox-47" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-47"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/joblib.html">Distributed Scikit-learn / Joblib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/multiprocessing.html">Distributed multiprocessing.Pool</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/ray-collective.html">Ray Collective Communication Lib</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-more-libs/dask-on-ray.html">Using Dask on Ray</a><input class="toctree-checkbox" id="toctree-checkbox-48" name="toctree-checkbox-48" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-48"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.RayDaskCallback.html">ray.util.dask.RayDaskCallback</a><input class="toctree-checkbox" id="toctree-checkbox-49" name="toctree-checkbox-49" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-49"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.RayDaskCallback.ray_active.html">ray.util.dask.RayDaskCallback.ray_active</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_presubmit.html">ray.util.dask.callbacks.RayDaskCallback._ray_presubmit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit.html">ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_pretask.html">ray.util.dask.callbacks.RayDaskCallback._ray_pretask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_posttask.html">ray.util.dask.callbacks.RayDaskCallback._ray_posttask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit_all.html">ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_finish.html">ray.util.dask.callbacks.RayDaskCallback._ray_finish</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/raydp.html">Using Spark on Ray (RayDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/mars-on-ray.html">Using Mars on Ray</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-more-libs/modin/index.html">Using Pandas on Ray (Modin)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../workflows/index.html">Ray Workflows (Alpha)</a><input class="toctree-checkbox" id="toctree-checkbox-50" name="toctree-checkbox-50" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-50"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../workflows/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../workflows/basics.html">Getting Started</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../workflows/management.html">Workflow Management</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../workflows/metadata.html">Workflow Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../workflows/events.html">Events</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../workflows/comparison.html">API Comparisons</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../workflows/advanced.html">Advanced Topics</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../workflows/api/api.html">Ray Workflows API</a><input class="toctree-checkbox" id="toctree-checkbox-51" name="toctree-checkbox-51" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-51"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../workflows/api/execution.html">Workflow Execution API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../workflows/api/management.html">Workflow Management API</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../cluster/getting-started.html">Ray Clusters</a><input class="toctree-checkbox" id="toctree-checkbox-52" name="toctree-checkbox-52" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-52"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../cluster/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/index.html">Deploying on Kubernetes</a><input class="toctree-checkbox" id="toctree-checkbox-53" name="toctree-checkbox-53" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-53"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/getting-started.html">Getting Started with KubeRay</a><input class="toctree-checkbox" id="toctree-checkbox-54" name="toctree-checkbox-54" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-54"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/getting-started/raycluster-quick-start.html">RayCluster Quickstart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/getting-started/rayjob-quick-start.html">RayJob Quickstart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/getting-started/rayservice-quick-start.html">RayService Quickstart</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-55" name="toctree-checkbox-55" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-55"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/rayservice.html">Deploy Ray Serve Apps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/rayservice-high-availability.html">RayService high availability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/observability.html">KubeRay Observability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/upgrade-guide.html">KubeRay upgrade guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/k8s-cluster-setup.html">Managed Kubernetes services</a></li>



<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/storage.html">Best Practices for Storage and Dependencies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/config.html">RayCluster Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/configuring-autoscaling.html">KubeRay Autoscaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/kuberay-gcs-ft.html">GCS fault tolerance in KubeRay</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/kuberay-gcs-persistent-ft.html">Tuning Redis for a Persistent Fault Tolerant GCS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/gke-gcs-bucket.html">Configuring KubeRay to use Google Cloud Storage Buckets in GKE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/persist-kuberay-custom-resource-logs.html">Persist KubeRay custom resource logs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/persist-kuberay-operator-logs.html">Persist KubeRay Operator Logs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/gpu.html">Using GPUs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/tpu.html">Use TPUs with KubeRay</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/rayserve-dev-doc.html">Developing Ray Serve Python scripts on a RayCluster</a></li>









<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/pod-command.html">Specify container commands for Ray head/worker Pods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/helm-chart-rbac.html">Helm Chart RBAC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/tls.html">TLS Authentication</a></li>






<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/k8s-autoscaler.html">(Advanced) Understanding the Ray Autoscaler in the Context of Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/static-ray-cluster-without-kuberay.html">(Advanced) Deploying a static Ray cluster without KubeRay</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/kubectl-plugin.html">Use kubectl plugin (beta)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/kuberay-auth.html">Configure Ray clusters with authentication and access control using KubeRay</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/user-guides/reduce-image-pull-latency.html">Reducing image pull latency on Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/examples.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-56" name="toctree-checkbox-56" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-56"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/ml-example.html">Ray Train XGBoostTrainer on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/gpu-training-example.html">Train PyTorch ResNet model with GPUs on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/mnist-training-example.html">Train a PyTorch model on Fashion MNIST with CPUs on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/stable-diffusion-rayservice.html">Serve a StableDiffusion text-to-image model on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/tpu-serve-stable-diffusion.html">Serve a Stable Diffusion model on GKE with TPUs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/mobilenet-rayservice.html">Serve a MobileNet image classifier on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/text-summarizer-rayservice.html">Serve a text summarizer on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/rayjob-batch-inference-example.html">RayJob Batch Inference Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/rayjob-kueue-priority-scheduling.html">Priority Scheduling with RayJob and Kueue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/rayjob-kueue-gang-scheduling.html">Gang Scheduling with RayJob and Kueue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/distributed-checkpointing-with-gcsfuse.html">Distributed checkpointing with KubeRay and GCSFuse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/modin-example.html">Use Modin with Ray on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/examples/vllm-rayservice.html">Serve a Large Language Model with vLLM on Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem.html">KubeRay Ecosystem</a><input class="toctree-checkbox" id="toctree-checkbox-57" name="toctree-checkbox-57" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-57"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/ingress.html">Ingress</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/prometheus-grafana.html">Using Prometheus and Grafana</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/pyspy.html">Profiling with py-spy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/volcano.html">KubeRay integration with Volcano</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/yunikorn.html">KubeRay integration with Apache YuniKorn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/kueue.html">Gang scheduling and priority scheduling for RayJob with Kueue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/k8s-ecosystem/istio.html">mTLS and L7 observability with Istio</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/benchmarks.html">KubeRay Benchmarks</a><input class="toctree-checkbox" id="toctree-checkbox-58" name="toctree-checkbox-58" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-58"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/benchmarks/memory-scalability-benchmark.html">KubeRay memory and scalability benchmark</a></li>

</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/kubernetes/troubleshooting.html">KubeRay Troubleshooting</a><input class="toctree-checkbox" id="toctree-checkbox-59" name="toctree-checkbox-59" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-59"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/troubleshooting/troubleshooting.html">Troubleshooting guide</a></li>

<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/kubernetes/troubleshooting/rayservice-troubleshooting.html">RayService troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/kubernetes/references.html">API Reference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../cluster/vms/index.html">Deploying on VMs</a><input class="toctree-checkbox" id="toctree-checkbox-60" name="toctree-checkbox-60" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-60"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/vms/getting-started.html">Getting Started</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/vms/user-guides/index.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-61" name="toctree-checkbox-61" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-61"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/user-guides/launching-clusters/index.html">Launching Ray Clusters on AWS, GCP, Azure, vSphere, On-Prem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/user-guides/large-cluster-best-practices.html">Best practices for deploying large clusters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/user-guides/configuring-autoscaling.html">Configuring Autoscaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/user-guides/logging.html">Log Persistence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/user-guides/community/index.html">Community Supported Cluster Managers</a></li>

</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/vms/examples/index.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-62" name="toctree-checkbox-62" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-62"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/examples/ml-example.html">Ray Train XGBoostTrainer on VMs</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/vms/references/index.html">API References</a><input class="toctree-checkbox" id="toctree-checkbox-63" name="toctree-checkbox-63" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-63"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/references/ray-cluster-cli.html">Cluster Launcher Commands</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/vms/references/ray-cluster-configuration.html">Cluster YAML Configuration Options</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../cluster/metrics.html">Collecting and monitoring metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../cluster/configure-manage-dashboard.html">Configuring and Managing Ray Dashboard</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../cluster/running-applications/index.html">Applications Guide</a><input class="toctree-checkbox" id="toctree-checkbox-64" name="toctree-checkbox-64" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-64"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/index.html">Ray Jobs Overview</a><input class="toctree-checkbox" id="toctree-checkbox-65" name="toctree-checkbox-65" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-65"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/quickstart.html">Quickstart using the Ray Jobs CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/sdk.html">Python SDK Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/jobs-package-ref.html">Python SDK API Reference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/cli.html">Ray Jobs CLI API Reference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/rest.html">Ray Jobs REST API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/ray-client.html">Ray Client</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/running-applications/autoscaling/reference.html">Programmatic Cluster Scaling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../cluster/faq.html">FAQ</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../cluster/package-overview.html">Ray Cluster Management API</a><input class="toctree-checkbox" id="toctree-checkbox-66" name="toctree-checkbox-66" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-66"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/cli.html">Cluster Management CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/jobs-package-ref.html">Python SDK API Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/running-applications/job-submission/cli.html">Ray Jobs CLI API Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../cluster/running-applications/autoscaling/reference.html">Programmatic Cluster Scaling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../cluster/usage-stats.html">Usage Stats Collection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../virtual-cluster/getting-started.html">Ray Virtual Clusters</a><input class="toctree-checkbox" id="toctree-checkbox-67" name="toctree-checkbox-67" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-67"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../virtual-cluster/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../virtual-cluster/design-overview.html">Design Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../virtual-cluster/management.html">Virtual Cluster Management API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../virtual-cluster/cli.html">Virtual Cluster CLI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../virtual-cluster/examples.html">Examples</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../ray-observability/index.html">Monitoring and Debugging</a><input class="toctree-checkbox" id="toctree-checkbox-68" name="toctree-checkbox-68" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-68"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-observability/getting-started.html">Ray Dashboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-observability/ray-distributed-debugger.html">Ray Distributed Debugger</a></li>



<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-observability/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-observability/user-guides/index.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-69" name="toctree-checkbox-69" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-69"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/index.html">Debugging Applications</a><input class="toctree-checkbox" id="toctree-checkbox-70" name="toctree-checkbox-70" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-70"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/general-debugging.html">General Debugging</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/debug-memory.html">Debugging Memory Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/debug-hangs.html">Debugging Hangs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/debug-failures.html">Debugging Failures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/optimize-performance.html">Optimizing Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/ray-distributed-debugger.html">Ray Distributed Debugger</a></li>



<li class="toctree-l4"><a class="reference internal" href="../../../../../ray-observability/user-guides/debug-apps/ray-debugging.html">Using the Ray Debugger</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/user-guides/cli-sdk.html">Monitoring with the CLI or SDK</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/user-guides/configure-logging.html">Configuring Logging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/user-guides/profiling.html">Profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/user-guides/add-app-metrics.html">Adding Application-Level Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/user-guides/ray-tracing.html">Tracing</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-observability/reference/index.html">Reference</a><input class="toctree-checkbox" id="toctree-checkbox-71" name="toctree-checkbox-71" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-71"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/reference/api.html">State API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/reference/cli.html">State CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-observability/reference/system-metrics.html">System Metrics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../../ray-contribute/index.html">Developer Guides</a><input class="toctree-checkbox" id="toctree-checkbox-72" name="toctree-checkbox-72" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-72"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-contribute/stability.html">API Stability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-contribute/api-policy.html">API Policy</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../../ray-contribute/getting-involved.html">Getting Involved / Contributing</a><input class="toctree-checkbox" id="toctree-checkbox-73" name="toctree-checkbox-73" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-73"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/development.html">Building Ray from Source</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/ci.html">CI Testing Workflow on PRs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/docs.html">Contributing to the Ray Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/writing-code-snippets.html">How to write code snippets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/fake-autoscaler.html">Testing Autoscaling Locally</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/testing-tips.html">Tips for testing Ray programs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/debugging.html">Debugging for Ray Developers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../ray-contribute/profiling.html">Profiling for Ray Developers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-core/configure.html">Configuring Ray</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../ray-contribute/whitepaper.html">Architecture Whitepapers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-references/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ray-security/index.html">Security</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">ray.rllib.co...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <h1>Source code for ray.rllib.core.learner.learner</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">abc</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Collection</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Hashable</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Sequence</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">tree</span>  <span class="c1"># pip install dm_tree</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">from</span> <span class="nn">ray.data.iterator</span> <span class="kn">import</span> <span class="n">DataIterator</span>
<span class="kn">from</span> <span class="nn">ray.rllib.connectors.learner.learner_connector_pipeline</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LearnerConnectorPipeline</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">COMPONENT_METRICS_LOGGER</span><span class="p">,</span>
    <span class="n">COMPONENT_OPTIMIZER</span><span class="p">,</span>
    <span class="n">COMPONENT_RL_MODULE</span><span class="p">,</span>
    <span class="n">DEFAULT_MODULE_ID</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.apis</span> <span class="kn">import</span> <span class="n">SelfSupervisedLossAPI</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module</span> <span class="kn">import</span> <span class="n">validate_module_id</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.multi_rl_module</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">MultiRLModule</span><span class="p">,</span>
    <span class="n">MultiRLModuleSpec</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.core.rl_module.rl_module</span> <span class="kn">import</span> <span class="n">RLModule</span><span class="p">,</span> <span class="n">RLModuleSpec</span>
<span class="kn">from</span> <span class="nn">ray.rllib.policy.policy</span> <span class="kn">import</span> <span class="n">PolicySpec</span>
<span class="kn">from</span> <span class="nn">ray.rllib.policy.sample_batch</span> <span class="kn">import</span> <span class="n">MultiAgentBatch</span><span class="p">,</span> <span class="n">SampleBatch</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.annotations</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">override</span><span class="p">,</span>
    <span class="n">OverrideToImplementCustomLogic</span><span class="p">,</span>
    <span class="n">OverrideToImplementCustomLogic_CallToSuperRecommended</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.checkpoints</span> <span class="kn">import</span> <span class="n">Checkpointable</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.debug</span> <span class="kn">import</span> <span class="n">update_global_seed_if_necessary</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.deprecation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Deprecated</span><span class="p">,</span>
    <span class="n">DEPRECATED_VALUE</span><span class="p">,</span>
    <span class="n">deprecation_warning</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.framework</span> <span class="kn">import</span> <span class="n">try_import_tf</span><span class="p">,</span> <span class="n">try_import_torch</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.metrics</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ALL_MODULES</span><span class="p">,</span>
    <span class="n">DATASET_NUM_ITERS_TRAINED</span><span class="p">,</span>
    <span class="n">DATASET_NUM_ITERS_TRAINED_LIFETIME</span><span class="p">,</span>
    <span class="n">NUM_ENV_STEPS_SAMPLED_LIFETIME</span><span class="p">,</span>
    <span class="n">NUM_ENV_STEPS_TRAINED</span><span class="p">,</span>
    <span class="n">NUM_ENV_STEPS_TRAINED_LIFETIME</span><span class="p">,</span>
    <span class="n">NUM_MODULE_STEPS_TRAINED</span><span class="p">,</span>
    <span class="n">NUM_MODULE_STEPS_TRAINED_LIFETIME</span><span class="p">,</span>
    <span class="n">MODULE_TRAIN_BATCH_SIZE_MEAN</span><span class="p">,</span>
    <span class="n">WEIGHTS_SEQ_NO</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.metrics.metrics_logger</span> <span class="kn">import</span> <span class="n">MetricsLogger</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.minibatch_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">MiniBatchDummyIterator</span><span class="p">,</span>
    <span class="n">MiniBatchCyclicIterator</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.numpy</span> <span class="kn">import</span> <span class="n">convert_to_numpy</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.schedules.scheduler</span> <span class="kn">import</span> <span class="n">Scheduler</span>
<span class="kn">from</span> <span class="nn">ray.rllib.utils.typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">EpisodeType</span><span class="p">,</span>
    <span class="n">LearningRateOrSchedule</span><span class="p">,</span>
    <span class="n">ModuleID</span><span class="p">,</span>
    <span class="n">Optimizer</span><span class="p">,</span>
    <span class="n">Param</span><span class="p">,</span>
    <span class="n">ParamRef</span><span class="p">,</span>
    <span class="n">ParamDict</span><span class="p">,</span>
    <span class="n">ResultDict</span><span class="p">,</span>
    <span class="n">ShouldModuleBeUpdatedFn</span><span class="p">,</span>
    <span class="n">StateDict</span><span class="p">,</span>
    <span class="n">TensorType</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.util.annotations</span> <span class="kn">import</span> <span class="n">PublicAPI</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">ray.rllib.algorithms.algorithm_config</span> <span class="kn">import</span> <span class="n">AlgorithmConfig</span>


<span class="n">torch</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">try_import_torch</span><span class="p">()</span>
<span class="n">tf1</span><span class="p">,</span> <span class="n">tf</span><span class="p">,</span> <span class="n">tfv</span> <span class="o">=</span> <span class="n">try_import_tf</span><span class="p">()</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="n">DEFAULT_OPTIMIZER</span> <span class="o">=</span> <span class="s2">&quot;default_optimizer&quot;</span>

<span class="c1"># COMMON LEARNER LOSS_KEYS</span>
<span class="n">POLICY_LOSS_KEY</span> <span class="o">=</span> <span class="s2">&quot;policy_loss&quot;</span>
<span class="n">VF_LOSS_KEY</span> <span class="o">=</span> <span class="s2">&quot;vf_loss&quot;</span>
<span class="n">ENTROPY_KEY</span> <span class="o">=</span> <span class="s2">&quot;entropy&quot;</span>

<span class="c1"># Additional update keys</span>
<span class="n">LR_KEY</span> <span class="o">=</span> <span class="s2">&quot;learning_rate&quot;</span>


<div class="viewcode-block" id="Learner">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.html#ray.rllib.core.learner.learner.Learner">[docs]</a>
<span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Learner</span><span class="p">(</span><span class="n">Checkpointable</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for Learners.</span>

<span class="sd">    This class will be used to train RLModules. It is responsible for defining the loss</span>
<span class="sd">    function, and updating the neural network weights that it owns. It also provides a</span>
<span class="sd">    way to add/remove modules to/from RLModules in a multi-agent scenario, in the</span>
<span class="sd">    middle of training (This is useful for league based training).</span>

<span class="sd">    TF and Torch specific implementation of this class fills in the framework-specific</span>
<span class="sd">    implementation details for distributed training, and for computing and applying</span>
<span class="sd">    gradients. User should not need to sub-class this class, but instead inherit from</span>
<span class="sd">    the TF or Torch specific sub-classes to implement their algorithm-specific update</span>
<span class="sd">    logic.</span>

<span class="sd">    Args:</span>
<span class="sd">        config: The AlgorithmConfig object from which to derive most of the settings</span>
<span class="sd">            needed to build the Learner.</span>
<span class="sd">        module_spec: The module specification for the RLModule that is being trained.</span>
<span class="sd">            If the module is a single agent module, after building the module it will</span>
<span class="sd">            be converted to a multi-agent module with a default key. Can be none if the</span>
<span class="sd">            module is provided directly via the `module` argument. Refer to</span>
<span class="sd">            ray.rllib.core.rl_module.RLModuleSpec</span>
<span class="sd">            or ray.rllib.core.rl_module.MultiRLModuleSpec for more info.</span>
<span class="sd">        module: If learner is being used stand-alone, the RLModule can be optionally</span>
<span class="sd">            passed in directly instead of the through the `module_spec`.</span>

<span class="sd">    Note: We use PPO and torch as an example here because many of the showcased</span>
<span class="sd">    components need implementations to come together. However, the same</span>
<span class="sd">    pattern is generally applicable.</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            import gymnasium as gym</span>

<span class="sd">            from ray.rllib.algorithms.ppo.ppo import PPOConfig</span>
<span class="sd">            from ray.rllib.algorithms.ppo.ppo_catalog import PPOCatalog</span>
<span class="sd">            from ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module import (</span>
<span class="sd">                PPOTorchRLModule</span>
<span class="sd">            )</span>
<span class="sd">            from ray.rllib.core import COMPONENT_RL_MODULE, DEFAULT_MODULE_ID</span>
<span class="sd">            from ray.rllib.core.rl_module.default_model_config import DefaultModelConfig</span>
<span class="sd">            from ray.rllib.core.rl_module.rl_module import RLModuleSpec</span>

<span class="sd">            env = gym.make(&quot;CartPole-v1&quot;)</span>

<span class="sd">            # Create a PPO config object first.</span>
<span class="sd">            config = (</span>
<span class="sd">                PPOConfig()</span>
<span class="sd">                .framework(&quot;torch&quot;)</span>
<span class="sd">                .training(model={&quot;fcnet_hiddens&quot;: [128, 128]})</span>
<span class="sd">            )</span>

<span class="sd">            # Create a learner instance directly from our config. All we need as</span>
<span class="sd">            # extra information here is the env to be able to extract space information</span>
<span class="sd">            # (needed to construct the RLModule inside the Learner).</span>
<span class="sd">            learner = config.build_learner(env=env)</span>

<span class="sd">            # Take one gradient update on the module and report the results.</span>
<span class="sd">            # results = learner.update(...)</span>

<span class="sd">            # Add a new module, perhaps for league based training.</span>
<span class="sd">            learner.add_module(</span>
<span class="sd">                module_id=&quot;new_player&quot;,</span>
<span class="sd">                module_spec=RLModuleSpec(</span>
<span class="sd">                    module_class=PPOTorchRLModule,</span>
<span class="sd">                    observation_space=env.observation_space,</span>
<span class="sd">                    action_space=env.action_space,</span>
<span class="sd">                    model_config=DefaultModelConfig(fcnet_hiddens=[64, 64]),</span>
<span class="sd">                    catalog_class=PPOCatalog,</span>
<span class="sd">                )</span>
<span class="sd">            )</span>

<span class="sd">            # Take another gradient update with both previous and new modules.</span>
<span class="sd">            # results = learner.update(...)</span>

<span class="sd">            # Remove a module.</span>
<span class="sd">            learner.remove_module(&quot;new_player&quot;)</span>

<span class="sd">            # Will train previous modules only.</span>
<span class="sd">            # results = learner.update(...)</span>

<span class="sd">            # Get the state of the learner.</span>
<span class="sd">            state = learner.get_state()</span>

<span class="sd">            # Set the state of the learner.</span>
<span class="sd">            learner.set_state(state)</span>

<span class="sd">            # Get the weights of the underlying MultiRLModule.</span>
<span class="sd">            weights = learner.get_state(components=COMPONENT_RL_MODULE)</span>

<span class="sd">            # Set the weights of the underlying MultiRLModule.</span>
<span class="sd">            learner.set_state({COMPONENT_RL_MODULE: weights})</span>


<span class="sd">    Extension pattern:</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            from ray.rllib.core.learner.torch.torch_learner import TorchLearner</span>

<span class="sd">            class MyLearner(TorchLearner):</span>

<span class="sd">               def compute_losses(self, fwd_out, batch):</span>
<span class="sd">                   # Compute the losses per module based on `batch` and output of the</span>
<span class="sd">                   # forward pass (`fwd_out`). To access the (algorithm) config for a</span>
<span class="sd">                   # specific RLModule, do:</span>
<span class="sd">                   # `self.config.get_config_for_module([moduleID])`.</span>
<span class="sd">                   return {DEFAULT_MODULE_ID: module_loss}</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">framework</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">TOTAL_LOSS_KEY</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;total_loss&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="s2">&quot;AlgorithmConfig&quot;</span><span class="p">,</span>
        <span class="n">module_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">RLModuleSpec</span><span class="p">,</span> <span class="n">MultiRLModuleSpec</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">RLModule</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># TODO (sven): Figure out how to do this</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">copy_frozen</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultiRLModuleSpec</span><span class="p">]</span> <span class="o">=</span> <span class="n">module_spec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module_obj</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultiRLModule</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span>

        <span class="c1"># Make node and device of this Learner available.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_node</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">node</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Set a seed, if necessary.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">update_global_seed_if_necessary</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">framework</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Whether self.build has already been called.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_built</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># These are the attributes that are set during build.</span>

        <span class="c1"># The actual MultiRLModule used by this Learner.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultiRLModule</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights_seq_no</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># Our Learner connector pipeline.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_learner_connector</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LearnerConnectorPipeline</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># These are set for properly applying optimizers and adding or removing modules.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_parameters</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ParamRef</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_named_optimizers</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">:</span> <span class="n">ParamDict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># Dict mapping ModuleID to a list of optimizer names. Note that the optimizer</span>
        <span class="c1"># name includes the ModuleID as a prefix: optimizer_name=`[ModuleID]_[.. rest]`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module_optimizers</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">ModuleID</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_name_to_module</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ModuleID</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Only manage optimizer&#39;s learning rate if user has NOT overridden</span>
        <span class="c1"># the `configure_optimizers_for_module` method. Otherwise, leave responsibility</span>
        <span class="c1"># to handle lr-updates entirely in user&#39;s hands.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_lr_schedules</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">Scheduler</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># The Learner&#39;s own MetricsLogger to be used to log RLlib&#39;s built-in metrics or</span>
        <span class="c1"># custom user-defined ones (e.g. custom loss values). When returning from an</span>
        <span class="c1"># `update_from_...()` method call, the Learner will do a `self.metrics.reduce()`</span>
        <span class="c1"># and return the resulting (reduced) dict.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="n">MetricsLogger</span><span class="p">()</span>

        <span class="c1"># In case of offline learning and multiple learners, each learner receives a</span>
        <span class="c1"># repeatable iterator that iterates over a split of the streamed data.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">:</span> <span class="n">DataIterator</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># TODO (sven): Do we really need this API? It seems like LearnerGroup constructs</span>
    <span class="c1">#  all Learner workers and then immediately builds them any ways? Unless there is</span>
    <span class="c1">#  a reason related to Train worker group setup.</span>
<div class="viewcode-block" id="Learner.build">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.build.html#ray.rllib.core.learner.learner.Learner.build">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic_CallToSuperRecommended</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Builds the Learner.</span>

<span class="sd">        This method should be called before the learner is used. It is responsible for</span>
<span class="sd">        setting up the LearnerConnectorPipeline, the RLModule, optimizer(s), and</span>
<span class="sd">        (optionally) the optimizers&#39; learning rate schedulers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_built</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Learner already built. Skipping build.&quot;</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="c1"># Build learner connector pipeline used on this Learner worker.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_learner_connector</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># If the Algorithm uses aggregation actors to run episodes through the learner</span>
        <span class="c1"># connector, its Learners don&#39;t need a connector pipelines and instead learn</span>
        <span class="c1"># directly from pre-loaded batches already on the GPU.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_aggregator_actors_per_learner</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># TODO (sven): Figure out which space to provide here. For now,</span>
            <span class="c1">#  it doesn&#39;t matter, as the default connector piece doesn&#39;t use</span>
            <span class="c1">#  this information anyway.</span>
            <span class="c1">#  module_spec = self._module_spec.as_multi_rl_module_spec()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_learner_connector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">build_learner_connector</span><span class="p">(</span>
                <span class="n">input_observation_space</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">input_action_space</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Build the module to be trained by this learner.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_module</span><span class="p">()</span>

        <span class="c1"># Configure, construct, and register all optimizers needed to train</span>
        <span class="c1"># `self.module`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">configure_optimizers</span><span class="p">()</span>

        <span class="c1"># Log the number of trainable/non-trainable parameters.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_trainable_parameters</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_is_built</span> <span class="o">=</span> <span class="kc">True</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">distributed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether the learner is running in distributed mode.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_learners</span> <span class="o">&gt;</span> <span class="mi">1</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">module</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultiRLModule</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The MultiRLModule that is being trained.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">node</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>

<div class="viewcode-block" id="Learner.register_optimizer">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.register_optimizer.html#ray.rllib.core.learner.learner.Learner.register_optimizer">[docs]</a>
    <span class="k">def</span> <span class="nf">register_optimizer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">module_id</span><span class="p">:</span> <span class="n">ModuleID</span> <span class="o">=</span> <span class="n">ALL_MODULES</span><span class="p">,</span>
        <span class="n">optimizer_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">DEFAULT_OPTIMIZER</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizer</span><span class="p">,</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Param</span><span class="p">],</span>
        <span class="n">lr_or_lr_schedule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LearningRateOrSchedule</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Registers an optimizer with a ModuleID, name, param list and lr-scheduler.</span>

<span class="sd">        Use this method in your custom implementations of either</span>
<span class="sd">        `self.configure_optimizers()` or `self.configure_optimzers_for_module()` (you</span>
<span class="sd">        should only override one of these!). If you register a learning rate Scheduler</span>
<span class="sd">        setting together with an optimizer, RLlib will automatically keep this</span>
<span class="sd">        optimizer&#39;s learning rate updated throughout the training process.</span>
<span class="sd">        Alternatively, you can construct your optimizers directly with a learning rate</span>
<span class="sd">        and manage learning rate scheduling or updating yourself.</span>

<span class="sd">        Args:</span>
<span class="sd">            module_id: The `module_id` under which to register the optimizer. If not</span>
<span class="sd">                provided, will assume ALL_MODULES.</span>
<span class="sd">            optimizer_name: The name (str) of the optimizer. If not provided, will</span>
<span class="sd">                assume DEFAULT_OPTIMIZER.</span>
<span class="sd">            optimizer: The already instantiated optimizer object to register.</span>
<span class="sd">            params: A list of parameters (framework-specific variables) that will be</span>
<span class="sd">                trained/updated</span>
<span class="sd">            lr_or_lr_schedule: An optional fixed learning rate or learning rate schedule</span>
<span class="sd">                setup. If provided, RLlib will automatically keep the optimizer&#39;s</span>
<span class="sd">                learning rate updated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Validate optimizer instance and its param list.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_registered_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

        <span class="n">full_registration_name</span> <span class="o">=</span> <span class="n">module_id</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">optimizer_name</span>

        <span class="c1"># Store the given optimizer under the given `module_id`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module_optimizers</span><span class="p">[</span><span class="n">module_id</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_registration_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_name_to_module</span><span class="p">[</span><span class="n">full_registration_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">module_id</span>

        <span class="c1"># Store the optimizer instance under its full `module_id`_`optimizer_name`</span>
        <span class="c1"># key.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_named_optimizers</span><span class="p">[</span><span class="n">full_registration_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer</span>

        <span class="c1"># Store all given parameters under the given optimizer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_parameters</span><span class="p">[</span><span class="n">optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">param_ref</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_param_ref</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_parameters</span><span class="p">[</span><span class="n">optimizer</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param_ref</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">[</span><span class="n">param_ref</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span>

        <span class="c1"># Optionally, store a scheduler object along with this optimizer. If such a</span>
        <span class="c1"># setting is provided, RLlib will handle updating the optimizer&#39;s learning rate</span>
        <span class="c1"># over time.</span>
        <span class="k">if</span> <span class="n">lr_or_lr_schedule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Validate the given setting.</span>
            <span class="n">Scheduler</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span>
                <span class="n">fixed_value_or_schedule</span><span class="o">=</span><span class="n">lr_or_lr_schedule</span><span class="p">,</span>
                <span class="n">setting_name</span><span class="o">=</span><span class="s2">&quot;lr_or_lr_schedule&quot;</span><span class="p">,</span>
                <span class="n">description</span><span class="o">=</span><span class="s2">&quot;learning rate or schedule&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Create the scheduler object for this optimizer.</span>
            <span class="n">scheduler</span> <span class="o">=</span> <span class="n">Scheduler</span><span class="p">(</span>
                <span class="n">fixed_value_or_schedule</span><span class="o">=</span><span class="n">lr_or_lr_schedule</span><span class="p">,</span>
                <span class="n">framework</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">framework</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_lr_schedules</span><span class="p">[</span><span class="n">optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="n">scheduler</span>
            <span class="c1"># Set the optimizer to the current (first) learning rate.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_optimizer_lr</span><span class="p">(</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                <span class="n">lr</span><span class="o">=</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_current_value</span><span class="p">(),</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="Learner.configure_optimizers">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.configure_optimizers.html#ray.rllib.core.learner.learner.Learner.configure_optimizers">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Configures, creates, and registers the optimizers for this Learner.</span>

<span class="sd">        Optimizers are responsible for updating the model&#39;s parameters during training,</span>
<span class="sd">        based on the computed gradients.</span>

<span class="sd">        Normally, you should not override this method for your custom algorithms</span>
<span class="sd">        (which require certain optimizers), but rather override the</span>
<span class="sd">        `self.configure_optimizers_for_module(module_id=..)` method and register those</span>
<span class="sd">        optimizers in there that you need for the given `module_id`.</span>

<span class="sd">        You can register an optimizer for any RLModule within `self.module` (or for</span>
<span class="sd">        the ALL_MODULES ID) by calling `self.register_optimizer()` and passing the</span>
<span class="sd">        module_id, optimizer_name (only in case you would like to register more than</span>
<span class="sd">        one optimizer for a given module), the optimizer instane itself, a list</span>
<span class="sd">        of all the optimizer&#39;s parameters (to be updated by the optimizer), and</span>
<span class="sd">        an optional learning rate or learning rate schedule setting.</span>

<span class="sd">        This method is called once during building (`self.build()`).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The default implementation simply calls `self.configure_optimizers_for_module`</span>
        <span class="c1"># on each RLModule within `self.module`.</span>
        <span class="k">for</span> <span class="n">module_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rl_module_is_compatible</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="n">module_id</span><span class="p">]):</span>
                <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get_config_for_module</span><span class="p">(</span><span class="n">module_id</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">configure_optimizers_for_module</span><span class="p">(</span><span class="n">module_id</span><span class="o">=</span><span class="n">module_id</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span></div>


<div class="viewcode-block" id="Learner.configure_optimizers_for_module">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.configure_optimizers_for_module.html#ray.rllib.core.learner.learner.Learner.configure_optimizers_for_module">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">configure_optimizers_for_module</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">module_id</span><span class="p">:</span> <span class="n">ModuleID</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="s2">&quot;AlgorithmConfig&quot;</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Configures an optimizer for the given module_id.</span>

<span class="sd">        This method is called for each RLModule in the MultiRLModule being</span>
<span class="sd">        trained by the Learner, as well as any new module added during training via</span>
<span class="sd">        `self.add_module()`. It should configure and construct one or more optimizers</span>
<span class="sd">        and register them via calls to `self.register_optimizer()` along with the</span>
<span class="sd">        `module_id`, an optional optimizer name (str), a list of the optimizer&#39;s</span>
<span class="sd">        framework specific parameters (variables), and an optional learning rate value</span>
<span class="sd">        or -schedule.</span>

<span class="sd">        Args:</span>
<span class="sd">            module_id: The module_id of the RLModule that is being configured.</span>
<span class="sd">            config: The AlgorithmConfig specific to the given `module_id`.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="Learner.compute_gradients">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.compute_gradients.html#ray.rllib.core.learner.learner.Learner.compute_gradients">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">compute_gradients</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">loss_per_module</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">ModuleID</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ParamDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the gradients based on the given losses.</span>

<span class="sd">        Args:</span>
<span class="sd">            loss_per_module: Dict mapping module IDs to their individual total loss</span>
<span class="sd">                terms, computed by the individual `compute_loss_for_module()` calls.</span>
<span class="sd">                The overall total loss (sum of loss terms over all modules) is stored</span>
<span class="sd">                under `loss_per_module[ALL_MODULES]`.</span>
<span class="sd">            **kwargs: Forward compatibility kwargs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The gradients in the same (flat) format as self._params. Note that all</span>
<span class="sd">            top-level structures, such as module IDs, will not be present anymore in</span>
<span class="sd">            the returned dict. It will merely map parameter tensor references to their</span>
<span class="sd">            respective gradient tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="Learner.postprocess_gradients">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.postprocess_gradients.html#ray.rllib.core.learner.learner.Learner.postprocess_gradients">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="k">def</span> <span class="nf">postprocess_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients_dict</span><span class="p">:</span> <span class="n">ParamDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ParamDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Applies potential postprocessing operations on the gradients.</span>

<span class="sd">        This method is called after gradients have been computed and modifies them</span>
<span class="sd">        before they are applied to the respective module(s) by the optimizer(s).</span>
<span class="sd">        This might include grad clipping by value, norm, or global-norm, or other</span>
<span class="sd">        algorithm specific gradient postprocessing steps.</span>

<span class="sd">        This default implementation calls `self.postprocess_gradients_for_module()`</span>
<span class="sd">        on each of the sub-modules in our MultiRLModule: `self.module` and</span>
<span class="sd">        returns the accumulated gradients dicts.</span>

<span class="sd">        Args:</span>
<span class="sd">            gradients_dict: A dictionary of gradients in the same (flat) format as</span>
<span class="sd">                self._params. Note that top-level structures, such as module IDs,</span>
<span class="sd">                will not be present anymore in this dict. It will merely map gradient</span>
<span class="sd">                tensor references to gradient tensors.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary with the updated gradients and the exact same (flat) structure</span>
<span class="sd">            as the incoming `gradients_dict` arg.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># The flat gradients dict (mapping param refs to params), returned by this</span>
        <span class="c1"># method.</span>
        <span class="n">postprocessed_gradients</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">module_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="c1"># Send a gradients dict for only this `module_id` to the</span>
            <span class="c1"># `self.postprocess_gradients_for_module()` method.</span>
            <span class="n">module_grads_dict</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">optimizer_name</span><span class="p">,</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_optimizers_for_module</span><span class="p">(</span><span class="n">module_id</span><span class="p">):</span>
                <span class="n">module_grads_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">filter_param_dict_for_optimizer</span><span class="p">(</span><span class="n">gradients_dict</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="n">module_grads_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocess_gradients_for_module</span><span class="p">(</span>
                <span class="n">module_id</span><span class="o">=</span><span class="n">module_id</span><span class="p">,</span>
                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get_config_for_module</span><span class="p">(</span><span class="n">module_id</span><span class="p">),</span>
                <span class="n">module_gradients_dict</span><span class="o">=</span><span class="n">module_grads_dict</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module_grads_dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>

            <span class="c1"># Update our return dict.</span>
            <span class="n">postprocessed_gradients</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">module_grads_dict</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">postprocessed_gradients</span></div>


<div class="viewcode-block" id="Learner.postprocess_gradients_for_module">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.postprocess_gradients_for_module.html#ray.rllib.core.learner.learner.Learner.postprocess_gradients_for_module">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic_CallToSuperRecommended</span>
    <span class="k">def</span> <span class="nf">postprocess_gradients_for_module</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">module_id</span><span class="p">:</span> <span class="n">ModuleID</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;AlgorithmConfig&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">module_gradients_dict</span><span class="p">:</span> <span class="n">ParamDict</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ParamDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Applies postprocessing operations on the gradients of the given module.</span>

<span class="sd">        Args:</span>
<span class="sd">            module_id: The module ID for which we will postprocess computed gradients.</span>
<span class="sd">                Note that `module_gradients_dict` already only carries those gradient</span>
<span class="sd">                tensors that belong to this `module_id`. Other `module_id`&#39;s gradients</span>
<span class="sd">                are not available in this call.</span>
<span class="sd">            config: The AlgorithmConfig specific to the given `module_id`.</span>
<span class="sd">            module_gradients_dict: A dictionary of gradients in the same (flat) format</span>
<span class="sd">                as self._params, mapping gradient refs to gradient tensors, which are to</span>
<span class="sd">                be postprocessed. You may alter these tensors in place or create new</span>
<span class="sd">                ones and return these in a new dict.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary with the updated gradients and the exact same (flat) structure</span>
<span class="sd">            as the incoming `module_gradients_dict` arg.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">postprocessed_grads</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">grad_clip</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">log_gradients</span><span class="p">:</span>
            <span class="n">postprocessed_grads</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">module_gradients_dict</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">postprocessed_grads</span>

        <span class="k">for</span> <span class="n">optimizer_name</span><span class="p">,</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_optimizers_for_module</span><span class="p">(</span><span class="n">module_id</span><span class="p">):</span>
            <span class="n">grad_dict_to_clip</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filter_param_dict_for_optimizer</span><span class="p">(</span>
                <span class="n">param_dict</span><span class="o">=</span><span class="n">module_gradients_dict</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">grad_clip</span><span class="p">:</span>
                <span class="c1"># Perform gradient clipping, if configured.</span>
                <span class="n">global_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_clip_function</span><span class="p">()(</span>
                    <span class="n">grad_dict_to_clip</span><span class="p">,</span>
                    <span class="n">grad_clip</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">grad_clip</span><span class="p">,</span>
                    <span class="n">grad_clip_by</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">grad_clip_by</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">grad_clip_by</span> <span class="o">==</span> <span class="s2">&quot;global_norm&quot;</span> <span class="ow">or</span> <span class="n">config</span><span class="o">.</span><span class="n">log_gradients</span><span class="p">:</span>
                    <span class="c1"># If we want to log gradients, but do not use the global norm</span>
                    <span class="c1"># for clipping compute it here.</span>
                    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">log_gradients</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">grad_clip_by</span> <span class="o">!=</span> <span class="s2">&quot;global_norm&quot;</span><span class="p">:</span>
                        <span class="c1"># Compute the global norm of gradients.</span>
                        <span class="n">global_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_global_norm_function</span><span class="p">()(</span>
                            <span class="c1"># Note, `tf.linalg.global_norm` needs a list of tensors.</span>
                            <span class="nb">list</span><span class="p">(</span><span class="n">grad_dict_to_clip</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span>
                        <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                        <span class="n">key</span><span class="o">=</span><span class="p">(</span><span class="n">module_id</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;gradients_</span><span class="si">{</span><span class="n">optimizer_name</span><span class="si">}</span><span class="s2">_global_norm&quot;</span><span class="p">),</span>
                        <span class="n">value</span><span class="o">=</span><span class="n">global_norm</span><span class="p">,</span>
                        <span class="n">window</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="n">postprocessed_grads</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">grad_dict_to_clip</span><span class="p">)</span>
            <span class="c1"># In the other case check, if we want to log gradients only.</span>
            <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">log_gradients</span><span class="p">:</span>
                <span class="c1"># Compute the global norm of gradients and log it.</span>
                <span class="n">global_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_global_norm_function</span><span class="p">()(</span>
                    <span class="c1"># Note, `tf.linalg.global_norm` needs a list of tensors.</span>
                    <span class="nb">list</span><span class="p">(</span><span class="n">grad_dict_to_clip</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                    <span class="n">key</span><span class="o">=</span><span class="p">(</span><span class="n">module_id</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;gradients_</span><span class="si">{</span><span class="n">optimizer_name</span><span class="si">}</span><span class="s2">_global_norm&quot;</span><span class="p">),</span>
                    <span class="n">value</span><span class="o">=</span><span class="n">global_norm</span><span class="p">,</span>
                    <span class="n">window</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">postprocessed_grads</span></div>


<div class="viewcode-block" id="Learner.apply_gradients">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.apply_gradients.html#ray.rllib.core.learner.learner.Learner.apply_gradients">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">apply_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients_dict</span><span class="p">:</span> <span class="n">ParamDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Applies the gradients to the MultiRLModule parameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            gradients_dict: A dictionary of gradients in the same (flat) format as</span>
<span class="sd">                self._params. Note that top-level structures, such as module IDs,</span>
<span class="sd">                will not be present anymore in this dict. It will merely map gradient</span>
<span class="sd">                tensor references to gradient tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="Learner.get_optimizer">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.get_optimizer.html#ray.rllib.core.learner.learner.Learner.get_optimizer">[docs]</a>
    <span class="k">def</span> <span class="nf">get_optimizer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module_id</span><span class="p">:</span> <span class="n">ModuleID</span> <span class="o">=</span> <span class="n">DEFAULT_MODULE_ID</span><span class="p">,</span>
        <span class="n">optimizer_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">DEFAULT_OPTIMIZER</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optimizer</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the optimizer object, configured under the given module_id and name.</span>

<span class="sd">        If only one optimizer was registered under `module_id` (or ALL_MODULES)</span>
<span class="sd">        via the `self.register_optimizer` method, `optimizer_name` is assumed to be</span>
<span class="sd">        DEFAULT_OPTIMIZER.</span>

<span class="sd">        Args:</span>
<span class="sd">            module_id: The ModuleID for which to return the configured optimizer.</span>
<span class="sd">                If not provided, will assume DEFAULT_MODULE_ID.</span>
<span class="sd">            optimizer_name: The name of the optimizer (registered under `module_id` via</span>
<span class="sd">                `self.register_optimizer()`) to return. If not provided, will assume</span>
<span class="sd">                DEFAULT_OPTIMIZER.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The optimizer object, configured under the given `module_id` and</span>
<span class="sd">            `optimizer_name`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># `optimizer_name` could possibly be the full optimizer name (including the</span>
        <span class="c1"># module_id under which it is registered).</span>
        <span class="k">if</span> <span class="n">optimizer_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_named_optimizers</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_named_optimizers</span><span class="p">[</span><span class="n">optimizer_name</span><span class="p">]</span>

        <span class="c1"># Normally, `optimizer_name` is just the optimizer&#39;s name, not including the</span>
        <span class="c1"># `module_id`.</span>
        <span class="n">full_registration_name</span> <span class="o">=</span> <span class="n">module_id</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">optimizer_name</span>
        <span class="k">if</span> <span class="n">full_registration_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_named_optimizers</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_named_optimizers</span><span class="p">[</span><span class="n">full_registration_name</span><span class="p">]</span>

        <span class="c1"># No optimizer found.</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Optimizer not found! module_id=</span><span class="si">{</span><span class="n">module_id</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;optimizer_name=</span><span class="si">{</span><span class="n">optimizer_name</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Learner.get_optimizers_for_module">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.get_optimizers_for_module.html#ray.rllib.core.learner.learner.Learner.get_optimizers_for_module">[docs]</a>
    <span class="k">def</span> <span class="nf">get_optimizers_for_module</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">module_id</span><span class="p">:</span> <span class="n">ModuleID</span> <span class="o">=</span> <span class="n">ALL_MODULES</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Optimizer</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a list of (optimizer_name, optimizer instance)-tuples for module_id.</span>

<span class="sd">        Args:</span>
<span class="sd">            module_id: The ModuleID for which to return the configured</span>
<span class="sd">                (optimizer name, optimizer)-pairs. If not provided, will return</span>
<span class="sd">                optimizers registered under ALL_MODULES.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of tuples of the format: ([optimizer_name], [optimizer object]),</span>
<span class="sd">            where optimizer_name is the name under which the optimizer was registered</span>
<span class="sd">            in `self.register_optimizer`. If only a single optimizer was</span>
<span class="sd">            configured for `module_id`, [optimizer_name] will be DEFAULT_OPTIMIZER.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">named_optimizers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">full_registration_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_optimizers</span><span class="p">[</span><span class="n">module_id</span><span class="p">]:</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_named_optimizers</span><span class="p">[</span><span class="n">full_registration_name</span><span class="p">]</span>
            <span class="c1"># TODO (sven): How can we avoid registering optimziers under this</span>
            <span class="c1">#  constructed `[module_id]_[optim_name]` format?</span>
            <span class="n">optim_name</span> <span class="o">=</span> <span class="n">full_registration_name</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">module_id</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span>
            <span class="n">named_optimizers</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">optim_name</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">named_optimizers</span></div>


<div class="viewcode-block" id="Learner.filter_param_dict_for_optimizer">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.filter_param_dict_for_optimizer.html#ray.rllib.core.learner.learner.Learner.filter_param_dict_for_optimizer">[docs]</a>
    <span class="k">def</span> <span class="nf">filter_param_dict_for_optimizer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">param_dict</span><span class="p">:</span> <span class="n">ParamDict</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizer</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ParamDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reduces the given ParamDict to contain only parameters for given optimizer.</span>

<span class="sd">        Args:</span>
<span class="sd">            param_dict: The ParamDict to reduce/filter down to the given `optimizer`.</span>
<span class="sd">                The returned dict will be a subset of `param_dict` only containing keys</span>
<span class="sd">                (param refs) that were registered together with `optimizer` (and thus</span>
<span class="sd">                that `optimizer` is responsible for applying gradients to).</span>
<span class="sd">            optimizer: The optimizer object to whose parameter refs the given</span>
<span class="sd">                `param_dict` should be reduced.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A new ParamDict only containing param ref keys that belong to `optimizer`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Return a sub-dict only containing those param_ref keys (and their values)</span>
        <span class="c1"># that belong to the `optimizer`.</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">ref</span><span class="p">:</span> <span class="n">param_dict</span><span class="p">[</span><span class="n">ref</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_parameters</span><span class="p">[</span><span class="n">optimizer</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">param_dict</span> <span class="ow">and</span> <span class="n">param_dict</span><span class="p">[</span><span class="n">ref</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">}</span></div>


<div class="viewcode-block" id="Learner.get_param_ref">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.get_param_ref.html#ray.rllib.core.learner.learner.Learner.get_param_ref">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">get_param_ref</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="n">Param</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Hashable</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a hashable reference to a trainable parameter.</span>

<span class="sd">        This should be overridden in framework specific specialization. For example in</span>
<span class="sd">        torch it will return the parameter itself, while in tf it returns the .ref() of</span>
<span class="sd">        the variable. The purpose is to retrieve a unique reference to the parameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            param: The parameter to get the reference to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A reference to the parameter.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="Learner.get_parameters">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.get_parameters.html#ray.rllib.core.learner.learner.Learner.get_parameters">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">get_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">RLModule</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Param</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the list of parameters of a module.</span>

<span class="sd">        This should be overridden in framework specific learner. For example in torch it</span>
<span class="sd">        will return .parameters(), while in tf it returns .trainable_variables.</span>

<span class="sd">        Args:</span>
<span class="sd">            module: The module to get the parameters from.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The parameters of the module.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_convert_batch_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">MultiAgentBatch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultiAgentBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts the elements of a MultiAgentBatch to Tensors on the correct device.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: The MultiAgentBatch object to convert.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The resulting MultiAgentBatch with framework-specific tensor values placed</span>
<span class="sd">            on the correct device.</span>
<span class="sd">        &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Learner.add_module">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.add_module.html#ray.rllib.core.learner.learner.Learner.add_module">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic_CallToSuperRecommended</span>
    <span class="k">def</span> <span class="nf">add_module</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">module_id</span><span class="p">:</span> <span class="n">ModuleID</span><span class="p">,</span>
        <span class="n">module_spec</span><span class="p">:</span> <span class="n">RLModuleSpec</span><span class="p">,</span>
        <span class="n">config_overrides</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">new_should_module_be_updated</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ShouldModuleBeUpdatedFn</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultiRLModuleSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Adds a module to the underlying MultiRLModule.</span>

<span class="sd">        Changes this Learner&#39;s config in order to make this architectural change</span>
<span class="sd">        permanent wrt. to checkpointing.</span>

<span class="sd">        Args:</span>
<span class="sd">            module_id: The ModuleID of the module to be added.</span>
<span class="sd">            module_spec: The ModuleSpec of the module to be added.</span>
<span class="sd">            config_overrides: The `AlgorithmConfig` overrides that should apply to</span>
<span class="sd">                the new Module, if any.</span>
<span class="sd">            new_should_module_be_updated: An optional sequence of ModuleIDs or a</span>
<span class="sd">                callable taking ModuleID and SampleBatchType and returning whether the</span>
<span class="sd">                ModuleID should be updated (trained).</span>
<span class="sd">                If None, will keep the existing setup in place. RLModules,</span>
<span class="sd">                whose IDs are not in the list (or for which the callable</span>
<span class="sd">                returns False) will not be updated.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The new MultiRLModuleSpec (after the RLModule has been added).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">validate_module_id</span><span class="p">(</span><span class="n">module_id</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_built</span><span class="p">()</span>

        <span class="c1"># Force-set inference-only = False.</span>
        <span class="n">module_spec</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">module_spec</span><span class="p">)</span>
        <span class="n">module_spec</span><span class="o">.</span><span class="n">inference_only</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Build the new RLModule and add it to self.module.</span>
        <span class="n">module</span> <span class="o">=</span> <span class="n">module_spec</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">module_id</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>

        <span class="c1"># Change our config (AlgorithmConfig) to contain the new Module.</span>
        <span class="c1"># TODO (sven): This is a hack to manipulate the AlgorithmConfig directly,</span>
        <span class="c1">#  but we&#39;ll deprecate config.policies soon anyway.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">policies</span><span class="p">[</span><span class="n">module_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">PolicySpec</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">config_overrides</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">multi_agent</span><span class="p">(</span>
                <span class="n">algorithm_config_overrides_per_module</span><span class="o">=</span><span class="p">{</span><span class="n">module_id</span><span class="p">:</span> <span class="n">config_overrides</span><span class="p">}</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rl_module</span><span class="p">(</span><span class="n">rl_module_spec</span><span class="o">=</span><span class="n">MultiRLModuleSpec</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rl_module_spec</span>
        <span class="k">if</span> <span class="n">new_should_module_be_updated</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">multi_agent</span><span class="p">(</span><span class="n">policies_to_train</span><span class="o">=</span><span class="n">new_should_module_be_updated</span><span class="p">)</span>

        <span class="c1"># Allow the user to configure one or more optimizers for this new module.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">configure_optimizers_for_module</span><span class="p">(</span>
            <span class="n">module_id</span><span class="o">=</span><span class="n">module_id</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get_config_for_module</span><span class="p">(</span><span class="n">module_id</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rl_module_spec</span></div>


<div class="viewcode-block" id="Learner.remove_module">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.remove_module.html#ray.rllib.core.learner.learner.Learner.remove_module">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic_CallToSuperRecommended</span>
    <span class="k">def</span> <span class="nf">remove_module</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module_id</span><span class="p">:</span> <span class="n">ModuleID</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">new_should_module_be_updated</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ShouldModuleBeUpdatedFn</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultiRLModuleSpec</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Removes a module from the Learner.</span>

<span class="sd">        Args:</span>
<span class="sd">            module_id: The ModuleID of the module to be removed.</span>
<span class="sd">            new_should_module_be_updated: An optional sequence of ModuleIDs or a</span>
<span class="sd">                callable taking ModuleID and SampleBatchType and returning whether the</span>
<span class="sd">                ModuleID should be updated (trained).</span>
<span class="sd">                If None, will keep the existing setup in place. RLModules,</span>
<span class="sd">                whose IDs are not in the list (or for which the callable</span>
<span class="sd">                returns False) will not be updated.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The new MultiRLModuleSpec (after the RLModule has been removed).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_built</span><span class="p">()</span>
        <span class="n">module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="n">module_id</span><span class="p">]</span>

        <span class="c1"># Delete the removed module&#39;s parameters and optimizers.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rl_module_is_compatible</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
            <span class="n">parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
                <span class="n">param_ref</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_param_ref</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">param_ref</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">:</span>
                    <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="p">[</span><span class="n">param_ref</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">optimizer_name</span><span class="p">,</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_optimizers_for_module</span><span class="p">(</span><span class="n">module_id</span><span class="p">):</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_parameters</span><span class="p">[</span><span class="n">optimizer</span><span class="p">]</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">module_id</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">optimizer_name</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_named_optimizers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_lr_schedules</span><span class="p">:</span>
                    <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_lr_schedules</span><span class="p">[</span><span class="n">optimizer</span><span class="p">]</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_optimizers</span><span class="p">[</span><span class="n">module_id</span><span class="p">]</span>

        <span class="c1"># Remove the module from the MultiRLModule.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">remove_module</span><span class="p">(</span><span class="n">module_id</span><span class="p">)</span>

        <span class="c1"># Change self.config to reflect the new architecture.</span>
        <span class="c1"># TODO (sven): This is a hack to manipulate the AlgorithmConfig directly,</span>
        <span class="c1">#  but we&#39;ll deprecate config.policies soon anyway.</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">policies</span><span class="p">[</span><span class="n">module_id</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm_config_overrides_per_module</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">module_id</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">new_should_module_be_updated</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">multi_agent</span><span class="p">(</span><span class="n">policies_to_train</span><span class="o">=</span><span class="n">new_should_module_be_updated</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rl_module</span><span class="p">(</span><span class="n">rl_module_spec</span><span class="o">=</span><span class="n">MultiRLModuleSpec</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">))</span>

        <span class="c1"># Remove all stats from the module from our metrics logger, so we don&#39;t report</span>
        <span class="c1"># results from this module again.</span>
        <span class="k">if</span> <span class="n">module_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">stats</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">stats</span><span class="p">[</span><span class="n">module_id</span><span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rl_module_spec</span></div>


<div class="viewcode-block" id="Learner.should_module_be_updated">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.should_module_be_updated.html#ray.rllib.core.learner.learner.Learner.should_module_be_updated">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="k">def</span> <span class="nf">should_module_be_updated</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module_id</span><span class="p">,</span> <span class="n">multi_agent_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns whether a module should be updated or not based on `self.config`.</span>

<span class="sd">        Args:</span>
<span class="sd">            module_id: The ModuleID that we want to query on whether this module</span>
<span class="sd">                should be updated or not.</span>
<span class="sd">            multi_agent_batch: An optional MultiAgentBatch to possibly provide further</span>
<span class="sd">                information on the decision on whether the RLModule should be updated</span>
<span class="sd">                or not.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">should_module_be_updated_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">policies_to_train</span>
        <span class="c1"># If None, return True (by default, all modules should be updated).</span>
        <span class="k">if</span> <span class="n">should_module_be_updated_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="c1"># If collection given, return whether `module_id` is in that container.</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">should_module_be_updated_fn</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">module_id</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">should_module_be_updated_fn</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">should_module_be_updated_fn</span><span class="p">(</span><span class="n">module_id</span><span class="p">,</span> <span class="n">multi_agent_batch</span><span class="p">)</span></div>


<div class="viewcode-block" id="Learner.compute_losses">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.compute_losses.html#ray.rllib.core.learner.learner.Learner.compute_losses">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="k">def</span> <span class="nf">compute_losses</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">fwd_out</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the loss(es) for the module being optimized.</span>

<span class="sd">        This method must be overridden by MultiRLModule-specific Learners in order to</span>
<span class="sd">        define the specific loss computation logic. If the algorithm is single-agent,</span>
<span class="sd">        only `compute_loss_for_module()` should be overridden instead. If the algorithm</span>
<span class="sd">        uses independent multi-agent learning (default behavior for RLlib&#39;s multi-agent</span>
<span class="sd">        setups), also only `compute_loss_for_module()` should be overridden, but it will</span>
<span class="sd">        be called for each individual RLModule inside the MultiRLModule.</span>
<span class="sd">        It is recommended to not compute any forward passes within this method, and to</span>
<span class="sd">        use the `forward_train()` outputs of the RLModule(s) to compute the required</span>
<span class="sd">        loss tensors.</span>
<span class="sd">        See here for a custom loss function example script:</span>
<span class="sd">        https://github.com/ray-project/ray/blob/master/rllib/examples/learners/ppo_with_custom_loss_fn.py  # noqa</span>

<span class="sd">        Args:</span>
<span class="sd">            fwd_out: Output from a call to the `forward_train()` method of the</span>
<span class="sd">                underlying MultiRLModule (`self.module`) during training</span>
<span class="sd">                (`self.update()`).</span>
<span class="sd">            batch: The train batch that was used to compute `fwd_out`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary mapping module IDs to individual loss terms.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loss_per_module</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">module_id</span> <span class="ow">in</span> <span class="n">fwd_out</span><span class="p">:</span>
            <span class="n">module_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">module_id</span><span class="p">]</span>
            <span class="n">module_fwd_out</span> <span class="o">=</span> <span class="n">fwd_out</span><span class="p">[</span><span class="n">module_id</span><span class="p">]</span>

            <span class="n">module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="n">module_id</span><span class="p">]</span><span class="o">.</span><span class="n">unwrapped</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">SelfSupervisedLossAPI</span><span class="p">):</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">compute_self_supervised_loss</span><span class="p">(</span>
                    <span class="n">learner</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
                    <span class="n">module_id</span><span class="o">=</span><span class="n">module_id</span><span class="p">,</span>
                    <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get_config_for_module</span><span class="p">(</span><span class="n">module_id</span><span class="p">),</span>
                    <span class="n">batch</span><span class="o">=</span><span class="n">module_batch</span><span class="p">,</span>
                    <span class="n">fwd_out</span><span class="o">=</span><span class="n">module_fwd_out</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss_for_module</span><span class="p">(</span>
                    <span class="n">module_id</span><span class="o">=</span><span class="n">module_id</span><span class="p">,</span>
                    <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get_config_for_module</span><span class="p">(</span><span class="n">module_id</span><span class="p">),</span>
                    <span class="n">batch</span><span class="o">=</span><span class="n">module_batch</span><span class="p">,</span>
                    <span class="n">fwd_out</span><span class="o">=</span><span class="n">module_fwd_out</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">loss_per_module</span><span class="p">[</span><span class="n">module_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span>

        <span class="k">return</span> <span class="n">loss_per_module</span></div>


<div class="viewcode-block" id="Learner.compute_loss_for_module">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.compute_loss_for_module.html#ray.rllib.core.learner.learner.Learner.compute_loss_for_module">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">compute_loss_for_module</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">module_id</span><span class="p">:</span> <span class="n">ModuleID</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="s2">&quot;AlgorithmConfig&quot;</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">fwd_out</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the loss for a single module.</span>

<span class="sd">        Think of this as computing loss for a single agent. For multi-agent use-cases</span>
<span class="sd">        that require more complicated computation for loss, consider overriding the</span>
<span class="sd">        `compute_losses` method instead.</span>

<span class="sd">        Args:</span>
<span class="sd">            module_id: The id of the module.</span>
<span class="sd">            config: The AlgorithmConfig specific to the given `module_id`.</span>
<span class="sd">            batch: The train batch for this particular module.</span>
<span class="sd">            fwd_out: The output of the forward pass for this particular module.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A single total loss tensor. If you have more than one optimizer on the</span>
<span class="sd">            provided `module_id` and would like to compute gradients separately using</span>
<span class="sd">            these different optimizers, simply add up the individual loss terms for</span>
<span class="sd">            each optimizer and return the sum. Also, for recording/logging any</span>
<span class="sd">            individual loss terms, you can use the `Learner.metrics.log_value(</span>
<span class="sd">            key=..., value=...)` or `Learner.metrics.log_dict()` APIs. See:</span>
<span class="sd">            :py:class:`~ray.rllib.utils.metrics.metrics_logger.MetricsLogger` for more</span>
<span class="sd">            information.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="Learner.update_from_batch">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.update_from_batch.html#ray.rllib.core.learner.learner.Learner.update_from_batch">[docs]</a>
    <span class="k">def</span> <span class="nf">update_from_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">MultiAgentBatch</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="c1"># TODO (sven): Make this a more formal structure with its own type.</span>
        <span class="n">timesteps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">minibatch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">shuffle_batch_per_epoch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="c1"># Deprecated args.</span>
        <span class="n">num_iters</span><span class="o">=</span><span class="n">DEPRECATED_VALUE</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ResultDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run `num_epochs` epochs over the given train batch.</span>

<span class="sd">        You can use this method to take more than one backward pass on the batch.</span>
<span class="sd">        The same `minibatch_size` and `num_epochs` will be used for all module ids in</span>
<span class="sd">        MultiRLModule.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: A batch of training data to update from.</span>
<span class="sd">            timesteps: Timesteps dict, which must have the key</span>
<span class="sd">                `NUM_ENV_STEPS_SAMPLED_LIFETIME`.</span>
<span class="sd">                # TODO (sven): Make this a more formal structure with its own type.</span>
<span class="sd">            num_epochs: The number of complete passes over the entire train batch. Each</span>
<span class="sd">                pass might be further split into n minibatches (if `minibatch_size`</span>
<span class="sd">                provided).</span>
<span class="sd">            minibatch_size: The size of minibatches to use to further split the train</span>
<span class="sd">                `batch` into sub-batches. The `batch` is then iterated over n times</span>
<span class="sd">                where n is `len(batch) // minibatch_size`.</span>
<span class="sd">            shuffle_batch_per_epoch: Whether to shuffle the train batch once per epoch.</span>
<span class="sd">                If the train batch has a time rank (axis=1), shuffling will only take</span>
<span class="sd">                place along the batch axis to not disturb any intact (episode)</span>
<span class="sd">                trajectories. Also, shuffling is always skipped if `minibatch_size` is</span>
<span class="sd">                None, meaning the entire train batch is processed each epoch, making it</span>
<span class="sd">                unnecessary to shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `ResultDict` object produced by a call to `self.metrics.reduce()`. The</span>
<span class="sd">            returned dict may be arbitrarily nested and must have `Stats` objects at</span>
<span class="sd">            all its leafs, allowing components further downstream (i.e. a user of this</span>
<span class="sd">            Learner) to further reduce these results (for example over n parallel</span>
<span class="sd">            Learners).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">num_iters</span> <span class="o">!=</span> <span class="n">DEPRECATED_VALUE</span><span class="p">:</span>
            <span class="n">deprecation_warning</span><span class="p">(</span>
                <span class="n">old</span><span class="o">=</span><span class="s2">&quot;Learner.update_from_episodes(num_iters=...)&quot;</span><span class="p">,</span>
                <span class="n">new</span><span class="o">=</span><span class="s2">&quot;Learner.update_from_episodes(num_epochs=...)&quot;</span><span class="p">,</span>
                <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_from_batch_or_episodes</span><span class="p">(</span>
            <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
            <span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span><span class="p">,</span>
            <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
            <span class="n">minibatch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">,</span>
            <span class="n">shuffle_batch_per_epoch</span><span class="o">=</span><span class="n">shuffle_batch_per_epoch</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">reduce</span><span class="p">()</span></div>


<div class="viewcode-block" id="Learner.update_from_episodes">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.update_from_episodes.html#ray.rllib.core.learner.learner.Learner.update_from_episodes">[docs]</a>
    <span class="k">def</span> <span class="nf">update_from_episodes</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">episodes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">EpisodeType</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="c1"># TODO (sven): Make this a more formal structure with its own type.</span>
        <span class="n">timesteps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">minibatch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">shuffle_batch_per_epoch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">num_total_minibatches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="c1"># Deprecated args.</span>
        <span class="n">num_iters</span><span class="o">=</span><span class="n">DEPRECATED_VALUE</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ResultDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run `num_epochs` epochs over the train batch generated from `episodes`.</span>

<span class="sd">        You can use this method to take more than one backward pass on the batch.</span>
<span class="sd">        The same `minibatch_size` and `num_epochs` will be used for all module ids in</span>
<span class="sd">        MultiRLModule.</span>

<span class="sd">        Args:</span>
<span class="sd">            episodes: An list of episode objects to update from.</span>
<span class="sd">            timesteps: Timesteps dict, which must have the key</span>
<span class="sd">                `NUM_ENV_STEPS_SAMPLED_LIFETIME`.</span>
<span class="sd">                # TODO (sven): Make this a more formal structure with its own type.</span>
<span class="sd">            num_epochs: The number of complete passes over the entire train batch. Each</span>
<span class="sd">                pass might be further split into n minibatches (if `minibatch_size`</span>
<span class="sd">                provided). The train batch is generated from the given `episodes`</span>
<span class="sd">                through the Learner connector pipeline.</span>
<span class="sd">            minibatch_size: The size of minibatches to use to further split the train</span>
<span class="sd">                `batch` into sub-batches. The `batch` is then iterated over n times</span>
<span class="sd">                where n is `len(batch) // minibatch_size`. The train batch is generated</span>
<span class="sd">                from the given `episodes` through the Learner connector pipeline.</span>
<span class="sd">            shuffle_batch_per_epoch: Whether to shuffle the train batch once per epoch.</span>
<span class="sd">                If the train batch has a time rank (axis=1), shuffling will only take</span>
<span class="sd">                place along the batch axis to not disturb any intact (episode)</span>
<span class="sd">                trajectories. Also, shuffling is always skipped if `minibatch_size` is</span>
<span class="sd">                None, meaning the entire train batch is processed each epoch, making it</span>
<span class="sd">                unnecessary to shuffle. The train batch is generated from the given</span>
<span class="sd">                `episodes` through the Learner connector pipeline.</span>
<span class="sd">            num_total_minibatches: The total number of minibatches to loop through</span>
<span class="sd">                (over all `num_epochs` epochs). It&#39;s only required to set this to != 0</span>
<span class="sd">                in multi-agent + multi-GPU situations, in which the MultiAgentEpisodes</span>
<span class="sd">                themselves are roughly sharded equally, however, they might contain</span>
<span class="sd">                SingleAgentEpisodes with very lopsided length distributions. Thus,</span>
<span class="sd">                without this fixed, pre-computed value, one Learner might go through a</span>
<span class="sd">                different number of minibatche passes than others causing a deadlock.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `ResultDict` object produced by a call to `self.metrics.reduce()`. The</span>
<span class="sd">            returned dict may be arbitrarily nested and must have `Stats` objects at</span>
<span class="sd">            all its leafs, allowing components further downstream (i.e. a user of this</span>
<span class="sd">            Learner) to further reduce these results (for example over n parallel</span>
<span class="sd">            Learners).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">num_iters</span> <span class="o">!=</span> <span class="n">DEPRECATED_VALUE</span><span class="p">:</span>
            <span class="n">deprecation_warning</span><span class="p">(</span>
                <span class="n">old</span><span class="o">=</span><span class="s2">&quot;Learner.update_from_episodes(num_iters=...)&quot;</span><span class="p">,</span>
                <span class="n">new</span><span class="o">=</span><span class="s2">&quot;Learner.update_from_episodes(num_epochs=...)&quot;</span><span class="p">,</span>
                <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_from_batch_or_episodes</span><span class="p">(</span>
            <span class="n">episodes</span><span class="o">=</span><span class="n">episodes</span><span class="p">,</span>
            <span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span><span class="p">,</span>
            <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
            <span class="n">minibatch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">,</span>
            <span class="n">shuffle_batch_per_epoch</span><span class="o">=</span><span class="n">shuffle_batch_per_epoch</span><span class="p">,</span>
            <span class="n">num_total_minibatches</span><span class="o">=</span><span class="n">num_total_minibatches</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">reduce</span><span class="p">()</span></div>


<div class="viewcode-block" id="Learner.update_from_iterator">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.update_from_iterator.html#ray.rllib.core.learner.learner.Learner.update_from_iterator">[docs]</a>
    <span class="k">def</span> <span class="nf">update_from_iterator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">iterator</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">timesteps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">minibatch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_iters</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="s2">&quot;num_epochs&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;`num_epochs` arg NOT supported by Learner.update_from_iterator! Use &quot;</span>
                <span class="s2">&quot;`num_iters` instead.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span> <span class="o">=</span> <span class="n">iterator</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_built</span><span class="p">()</span>

        <span class="c1"># Call `before_gradient_based_update` to allow for non-gradient based</span>
        <span class="c1"># preparations-, logging-, and update logic to happen.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">before_gradient_based_update</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span> <span class="ow">or</span> <span class="p">{})</span>

        <span class="k">def</span> <span class="nf">_finalize_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
            <span class="c1"># Note, the incoming batch is a dictionary with a numpy array</span>
            <span class="c1"># holding the `MultiAgentBatch`.</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_batch_type</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;batch&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;batch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_slicing_by_batch_id</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="kc">True</span><span class="p">)}</span>

        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;===&gt; [Learner </span><span class="si">{</span><span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">]: Looping through batches ... &quot;</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">num_iters</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_iters</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="o">.</span><span class="n">iter_batches</span><span class="p">(</span>
                <span class="c1"># Note, this needs to be one b/c data is already mapped to</span>
                <span class="c1"># `MultiAgentBatch`es of `minibatch_size`.</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">_finalize_fn</span><span class="o">=</span><span class="n">_finalize_fn</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">):</span>
                <span class="c1"># TODO (simon): Add metrics for the `dataset_num_iter`.</span>
                <span class="c1"># Update the iteration counter.</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># Note, `_finalize_fn`  must return a dictionary.</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;batch&quot;</span><span class="p">]</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;===&gt; [Learner </span><span class="si">{</span><span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">]: batch </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> with </span><span class="si">{</span><span class="n">batch</span><span class="o">.</span><span class="n">env_steps</span><span class="p">()</span><span class="si">}</span><span class="s2"> rows.&quot;</span>
                <span class="p">)</span>
                <span class="c1"># Check the MultiAgentBatch, whether our RLModule contains all ModuleIDs</span>
                <span class="c1"># found in this batch. If not, throw an error.</span>
                <span class="n">unknown_module_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">policy_batches</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unknown_module_ids</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;Batch contains one or more ModuleIDs that are not in this &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Learner! Found IDs: </span><span class="si">{</span><span class="n">unknown_module_ids</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

                <span class="c1"># Log metrics.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_steps_trained_metrics</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

                <span class="c1"># Make the actual in-graph/traced `_update` call. This should return</span>
                <span class="c1"># all tensor values (no numpy).</span>
                <span class="n">fwd_out</span><span class="p">,</span> <span class="n">loss_per_module</span><span class="p">,</span> <span class="n">tensor_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update</span><span class="p">(</span>
                    <span class="n">batch</span><span class="o">.</span><span class="n">policy_batches</span>
                <span class="p">)</span>
                <span class="c1"># Convert logged tensor metrics (logged during tensor-mode of</span>
                <span class="c1"># MetricsLogger) to actual (numpy) values.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">tensors_to_numpy</span><span class="p">(</span><span class="n">tensor_metrics</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_set_slicing_by_batch_id</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="c1"># If `num_iters` is reached break and return.</span>
                <span class="k">if</span> <span class="n">num_iters</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">==</span> <span class="n">num_iters</span><span class="p">:</span>
                    <span class="k">break</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;===&gt; [Learner </span><span class="si">{</span><span class="nb">id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="si">}</span><span class="s2">] number of iterations run in this epoch: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="c1"># Log all individual RLModules&#39; loss terms and its registered optimizers&#39;</span>
        <span class="c1"># current learning rates.</span>
        <span class="k">for</span> <span class="n">mid</span><span class="p">,</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">convert_to_numpy</span><span class="p">(</span><span class="n">loss_per_module</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                <span class="n">key</span><span class="o">=</span><span class="p">(</span><span class="n">mid</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">TOTAL_LOSS_KEY</span><span class="p">),</span>
                <span class="n">value</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                <span class="n">window</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="c1"># Record the number of batches pulled from the dataset in this RLlib iteration.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
            <span class="n">DATASET_NUM_ITERS_TRAINED</span><span class="p">,</span>
            <span class="n">i</span><span class="p">,</span>
            <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
            <span class="n">clear_on_reduce</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
            <span class="n">DATASET_NUM_ITERS_TRAINED_LIFETIME</span><span class="p">,</span>
            <span class="n">i</span><span class="p">,</span>
            <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Call `after_gradient_based_update` to allow for non-gradient based</span>
        <span class="c1"># cleanups-, logging-, and update logic to happen.</span>
        <span class="c1"># TODO (simon): Check, if this should stay here, when running multiple</span>
        <span class="c1"># gradient steps inside the iterator loop above (could be a complete epoch)</span>
        <span class="c1"># the target networks might need to be updated earlier.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">after_gradient_based_update</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span> <span class="ow">or</span> <span class="p">{})</span>

        <span class="c1"># Reduce results across all minibatch update steps.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">reduce</span><span class="p">()</span></div>


    <span class="nd">@OverrideToImplementCustomLogic</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Contains all logic for an in-graph/traceable update step.</span>

<span class="sd">        Framework specific subclasses must implement this method. This should include</span>
<span class="sd">        calls to the RLModule&#39;s `forward_train`, `compute_loss`, compute_gradients`,</span>
<span class="sd">        `postprocess_gradients`, and `apply_gradients` methods and return a tuple</span>
<span class="sd">        with all the individual results.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: The train batch already converted to a Dict mapping str to (possibly</span>
<span class="sd">                nested) tensors.</span>
<span class="sd">            kwargs: Forward compatibility kwargs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tuple consisting of:</span>
<span class="sd">                1) The `forward_train()` output of the RLModule,</span>
<span class="sd">                2) the loss_per_module dictionary mapping module IDs to individual loss</span>
<span class="sd">                    tensors</span>
<span class="sd">                3) a metrics dict mapping module IDs to metrics key/value pairs.</span>

<span class="sd">        &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Learner.get_state">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.get_state.html#ray.rllib.core.learner.learner.Learner.get_state">[docs]</a>
    <span class="nd">@override</span><span class="p">(</span><span class="n">Checkpointable</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">components</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Collection</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">not_components</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Collection</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">StateDict</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_built</span><span class="p">()</span>

        <span class="n">state</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;should_module_be_updated&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">policies_to_train</span><span class="p">,</span>
            <span class="n">WEIGHTS_SEQ_NO</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_seq_no</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_component</span><span class="p">(</span><span class="n">COMPONENT_RL_MODULE</span><span class="p">,</span> <span class="n">components</span><span class="p">,</span> <span class="n">not_components</span><span class="p">):</span>
            <span class="n">state</span><span class="p">[</span><span class="n">COMPONENT_RL_MODULE</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">get_state</span><span class="p">(</span>
                <span class="n">components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_subcomponents</span><span class="p">(</span><span class="n">COMPONENT_RL_MODULE</span><span class="p">,</span> <span class="n">components</span><span class="p">),</span>
                <span class="n">not_components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_subcomponents</span><span class="p">(</span>
                    <span class="n">COMPONENT_RL_MODULE</span><span class="p">,</span> <span class="n">not_components</span>
                <span class="p">),</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_component</span><span class="p">(</span><span class="n">COMPONENT_OPTIMIZER</span><span class="p">,</span> <span class="n">components</span><span class="p">,</span> <span class="n">not_components</span><span class="p">):</span>
            <span class="n">state</span><span class="p">[</span><span class="n">COMPONENT_OPTIMIZER</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_optimizer_state</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_component</span><span class="p">(</span><span class="n">COMPONENT_METRICS_LOGGER</span><span class="p">,</span> <span class="n">components</span><span class="p">,</span> <span class="n">not_components</span><span class="p">):</span>
            <span class="c1"># TODO (sven): Make `MetricsLogger` a Checkpointable.</span>
            <span class="n">state</span><span class="p">[</span><span class="n">COMPONENT_METRICS_LOGGER</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">state</span></div>


<div class="viewcode-block" id="Learner.set_state">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.set_state.html#ray.rllib.core.learner.learner.Learner.set_state">[docs]</a>
    <span class="nd">@override</span><span class="p">(</span><span class="n">Checkpointable</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">set_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">StateDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_built</span><span class="p">()</span>

        <span class="n">weights_seq_no</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">WEIGHTS_SEQ_NO</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">COMPONENT_RL_MODULE</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">weights_seq_no</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_seq_no</span> <span class="o">&lt;</span> <span class="n">weights_seq_no</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="n">COMPONENT_RL_MODULE</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">COMPONENT_OPTIMIZER</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_optimizer_state</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="n">COMPONENT_OPTIMIZER</span><span class="p">])</span>

        <span class="c1"># Update our weights_seq_no, if the new one is &gt; 0.</span>
        <span class="k">if</span> <span class="n">weights_seq_no</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_weights_seq_no</span> <span class="o">=</span> <span class="n">weights_seq_no</span>

        <span class="c1"># Update our trainable Modules information/function via our config.</span>
        <span class="c1"># If not provided in state (None), all Modules will be trained by default.</span>
        <span class="k">if</span> <span class="s2">&quot;should_module_be_updated&quot;</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">multi_agent</span><span class="p">(</span><span class="n">policies_to_train</span><span class="o">=</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;should_module_be_updated&quot;</span><span class="p">])</span>

        <span class="c1"># TODO (sven): Make `MetricsLogger` a Checkpointable.</span>
        <span class="k">if</span> <span class="n">COMPONENT_METRICS_LOGGER</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="n">COMPONENT_METRICS_LOGGER</span><span class="p">])</span></div>


    <span class="nd">@override</span><span class="p">(</span><span class="n">Checkpointable</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">get_ctor_args_and_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="p">(),</span>  <span class="c1"># *args,</span>
            <span class="p">{</span>
                <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
                <span class="s2">&quot;module_spec&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_spec</span><span class="p">,</span>
                <span class="s2">&quot;module&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_obj</span><span class="p">,</span>
            <span class="p">},</span>  <span class="c1"># **kwargs</span>
        <span class="p">)</span>

    <span class="nd">@override</span><span class="p">(</span><span class="n">Checkpointable</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">get_checkpointable_components</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_built</span><span class="p">(</span><span class="n">error</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">COMPONENT_RL_MODULE</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">),</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">_get_optimizer_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">StateDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the state of all optimizers currently registered in this Learner.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The current state of all optimizers currently registered in this Learner.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">_set_optimizer_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">StateDict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sets the state of all optimizers currently registered in this Learner.</span>

<span class="sd">        Args:</span>
<span class="sd">            state: The state of the optimizers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">_update_from_batch_or_episodes</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="c1"># TODO (sven): We should allow passing in a single agent batch here</span>
        <span class="c1">#  as well for simplicity.</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MultiAgentBatch</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">episodes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">EpisodeType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># TODO (sven): Make this a more formal structure with its own type.</span>
        <span class="n">timesteps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># TODO (sven): Deprecate these in favor of config attributes for only those</span>
        <span class="c1">#  algos that actually need (and know how) to do minibatching.</span>
        <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">minibatch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">shuffle_batch_per_epoch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">num_total_minibatches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_check_is_built</span><span class="p">()</span>

        <span class="c1"># Call `before_gradient_based_update` to allow for non-gradient based</span>
        <span class="c1"># preparations-, logging-, and update logic to happen.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">before_gradient_based_update</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span> <span class="ow">or</span> <span class="p">{})</span>

        <span class="c1"># Resolve batch/episodes being ray object refs (instead of</span>
        <span class="c1"># actual batch/episodes objects).</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">episodes</span><span class="p">,</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
            <span class="n">episodes</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">episodes</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">episodes</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">episodes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">):</span>
            <span class="c1"># It&#39;s possible that individual refs are invalid due to the EnvRunner</span>
            <span class="c1"># that produced the ref has crashed or had its entire node go down.</span>
            <span class="c1"># In this case, try each ref individually and collect only valid results.</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">episodes</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">episodes</span><span class="p">))</span>
            <span class="k">except</span> <span class="n">ray</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">OwnerDiedError</span><span class="p">:</span>
                <span class="n">episode_refs</span> <span class="o">=</span> <span class="n">episodes</span>
                <span class="n">episodes</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">episode_refs</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">episodes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ref</span><span class="p">))</span>
                    <span class="k">except</span> <span class="n">ray</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">OwnerDiedError</span><span class="p">:</span>
                        <span class="k">pass</span>

        <span class="c1"># Call the learner connector on the given `episodes` (if we have one).</span>
        <span class="k">if</span> <span class="n">episodes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learner_connector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Call the learner connector pipeline.</span>
            <span class="n">shared_data</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learner_connector</span><span class="p">(</span>
                <span class="n">rl_module</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">,</span>
                <span class="n">batch</span><span class="o">=</span><span class="n">batch</span> <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{},</span>
                <span class="n">episodes</span><span class="o">=</span><span class="n">episodes</span><span class="p">,</span>
                <span class="n">shared_data</span><span class="o">=</span><span class="n">shared_data</span><span class="p">,</span>
                <span class="n">metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Convert to a batch.</span>
            <span class="c1"># TODO (sven): Try to not require MultiAgentBatch anymore.</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">MultiAgentBatch</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="n">module_id</span><span class="p">:</span> <span class="p">(</span>
                        <span class="n">SampleBatch</span><span class="p">(</span><span class="n">module_data</span><span class="p">,</span> <span class="n">_zero_padded</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">shared_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_zero_padded_for_mid=</span><span class="si">{</span><span class="n">module_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="k">else</span> <span class="n">SampleBatch</span><span class="p">(</span><span class="n">module_data</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">module_id</span><span class="p">,</span> <span class="n">module_data</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="p">},</span>
                <span class="n">env_steps</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">episodes</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="c1"># Single-agent SampleBatch: Have to convert to MultiAgentBatch.</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">):</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">MultiAgentBatch</span><span class="p">(</span>
                <span class="p">{</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span> <span class="n">batch</span><span class="p">},</span> <span class="n">env_steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="c1"># If we have already an `MultiAgentBatch` but with `numpy` array, convert to</span>
        <span class="c1"># tensors.</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">MultiAgentBatch</span><span class="p">)</span>
            <span class="ow">and</span> <span class="n">batch</span><span class="o">.</span><span class="n">policy_batches</span>
            <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">policy_batches</span><span class="o">.</span><span class="n">values</span><span class="p">()))[</span><span class="s2">&quot;obs&quot;</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>
            <span class="p">)</span>
        <span class="p">):</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_batch_type</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

        <span class="c1"># Check the MultiAgentBatch, whether our RLModule contains all ModuleIDs</span>
        <span class="c1"># found in this batch. If not, throw an error.</span>
        <span class="n">unknown_module_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">policy_batches</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unknown_module_ids</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Batch contains one or more ModuleIDs that are not in this Learner! &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Found IDs: </span><span class="si">{</span><span class="n">unknown_module_ids</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># TODO: Move this into LearnerConnector pipeline?</span>
        <span class="c1"># Filter out those RLModules from the final train batch that should not be</span>
        <span class="c1"># updated.</span>
        <span class="k">for</span> <span class="n">module_id</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">policy_batches</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">should_module_be_updated</span><span class="p">(</span><span class="n">module_id</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
                <span class="k">del</span> <span class="n">batch</span><span class="o">.</span><span class="n">policy_batches</span><span class="p">[</span><span class="n">module_id</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">batch</span><span class="o">.</span><span class="n">policy_batches</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Log all timesteps (env, agent, modules) based on given episodes/batch.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_steps_trained_metrics</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">minibatch_size</span><span class="p">:</span>
            <span class="n">batch_iter</span> <span class="o">=</span> <span class="n">MiniBatchCyclicIterator</span>
        <span class="k">elif</span> <span class="n">num_epochs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># `minibatch_size` was not set but `num_epochs` &gt; 1.</span>
            <span class="c1"># Under the old training stack, users could do multiple epochs</span>
            <span class="c1"># over a batch without specifying a minibatch size. We enable</span>
            <span class="c1"># this behavior here by setting the minibatch size to be the size</span>
            <span class="c1"># of the batch (e.g. 1 minibatch of size batch.count)</span>
            <span class="n">minibatch_size</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">count</span>
            <span class="c1"># Note that there is no need to shuffle here, b/c we don&#39;t have minibatches.</span>
            <span class="n">batch_iter</span> <span class="o">=</span> <span class="n">MiniBatchCyclicIterator</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># `minibatch_size` and `num_epochs` are not set by the user.</span>
            <span class="n">batch_iter</span> <span class="o">=</span> <span class="n">MiniBatchDummyIterator</span>

        <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_slicing_by_batch_id</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">tensor_minibatch</span> <span class="ow">in</span> <span class="n">batch_iter</span><span class="p">(</span>
            <span class="n">batch</span><span class="p">,</span>
            <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
            <span class="n">minibatch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">,</span>
            <span class="n">shuffle_batch_per_epoch</span><span class="o">=</span><span class="n">shuffle_batch_per_epoch</span> <span class="ow">and</span> <span class="p">(</span><span class="n">num_epochs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">num_total_minibatches</span><span class="o">=</span><span class="n">num_total_minibatches</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="c1"># Make the actual in-graph/traced `_update` call. This should return</span>
            <span class="c1"># all tensor values (no numpy).</span>
            <span class="n">fwd_out</span><span class="p">,</span> <span class="n">loss_per_module</span><span class="p">,</span> <span class="n">tensor_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update</span><span class="p">(</span>
                <span class="n">tensor_minibatch</span><span class="o">.</span><span class="n">policy_batches</span>
            <span class="p">)</span>

            <span class="c1"># Convert logged tensor metrics (logged during tensor-mode of MetricsLogger)</span>
            <span class="c1"># to actual (numpy) values.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">tensors_to_numpy</span><span class="p">(</span><span class="n">tensor_metrics</span><span class="p">)</span>

            <span class="c1"># Log all individual RLModules&#39; loss terms and its registered optimizers&#39;</span>
            <span class="c1"># current learning rates.</span>
            <span class="k">for</span> <span class="n">mid</span><span class="p">,</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">convert_to_numpy</span><span class="p">(</span><span class="n">loss_per_module</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                    <span class="n">key</span><span class="o">=</span><span class="p">(</span><span class="n">mid</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">TOTAL_LOSS_KEY</span><span class="p">),</span>
                    <span class="n">value</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                    <span class="n">window</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_weights_seq_no</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="p">(</span><span class="n">mid</span><span class="p">,</span> <span class="n">WEIGHTS_SEQ_NO</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights_seq_no</span>
                <span class="k">for</span> <span class="n">mid</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">policy_batches</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="p">},</span>
            <span class="n">window</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_slicing_by_batch_id</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Call `after_gradient_based_update` to allow for non-gradient based</span>
        <span class="c1"># cleanups-, logging-, and update logic to happen.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">after_gradient_based_update</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span> <span class="ow">or</span> <span class="p">{})</span>

<div class="viewcode-block" id="Learner.before_gradient_based_update">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.before_gradient_based_update.html#ray.rllib.core.learner.learner.Learner.before_gradient_based_update">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic_CallToSuperRecommended</span>
    <span class="k">def</span> <span class="nf">before_gradient_based_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called before gradient-based updates are completed.</span>

<span class="sd">        Should be overridden to implement custom preparation-, logging-, or</span>
<span class="sd">        non-gradient-based Learner/RLModule update logic before(!) gradient-based</span>
<span class="sd">        updates are performed.</span>

<span class="sd">        Args:</span>
<span class="sd">            timesteps: Timesteps dict, which must have the key</span>
<span class="sd">                `NUM_ENV_STEPS_SAMPLED_LIFETIME`.</span>
<span class="sd">                # TODO (sven): Make this a more formal structure with its own type.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="Learner.after_gradient_based_update">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.after_gradient_based_update.html#ray.rllib.core.learner.learner.Learner.after_gradient_based_update">[docs]</a>
    <span class="nd">@OverrideToImplementCustomLogic_CallToSuperRecommended</span>
    <span class="k">def</span> <span class="nf">after_gradient_based_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Called after gradient-based updates are completed.</span>

<span class="sd">        Should be overridden to implement custom cleanup-, logging-, or non-gradient-</span>
<span class="sd">        based Learner/RLModule update logic after(!) gradient-based updates have been</span>
<span class="sd">        completed.</span>

<span class="sd">        Args:</span>
<span class="sd">            timesteps: Timesteps dict, which must have the key</span>
<span class="sd">                `NUM_ENV_STEPS_SAMPLED_LIFETIME`.</span>
<span class="sd">                # TODO (sven): Make this a more formal structure with its own type.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Only update this optimizer&#39;s lr, if a scheduler has been registered</span>
        <span class="c1"># along with it.</span>
        <span class="k">for</span> <span class="n">module_id</span><span class="p">,</span> <span class="n">optimizer_names</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_optimizers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">optimizer_name</span> <span class="ow">in</span> <span class="n">optimizer_names</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_named_optimizers</span><span class="p">[</span><span class="n">optimizer_name</span><span class="p">]</span>
                <span class="c1"># Update and log learning rate of this optimizer.</span>
                <span class="n">lr_schedule</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_lr_schedules</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">lr_schedule</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">new_lr</span> <span class="o">=</span> <span class="n">lr_schedule</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="n">timestep</span><span class="o">=</span><span class="n">timesteps</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">NUM_ENV_STEPS_SAMPLED_LIFETIME</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_set_optimizer_lr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">new_lr</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                    <span class="c1"># Cut out the module ID from the beginning since it&#39;s already part</span>
                    <span class="c1"># of the key sequence: (ModuleID, &quot;[optim name]_lr&quot;).</span>
                    <span class="n">key</span><span class="o">=</span><span class="p">(</span><span class="n">module_id</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">optimizer_name</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">module_id</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">:]</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">LR_KEY</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">),</span>
                    <span class="n">value</span><span class="o">=</span><span class="n">convert_to_numpy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_optimizer_lr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)),</span>
                    <span class="n">window</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">_set_slicing_by_batch_id</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">MultiAgentBatch</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultiAgentBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Enables slicing by batch id in the given batch.</span>

<span class="sd">        If the input batch contains batches of sequences we need to make sure when</span>
<span class="sd">        slicing happens it is sliced via batch id and not timestamp. Calling this</span>
<span class="sd">        method enables the same flag on each SampleBatch within the input</span>
<span class="sd">        MultiAgentBatch.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch: The MultiAgentBatch to enable slicing by batch id on.</span>
<span class="sd">            value: The value to set the flag to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The input MultiAgentBatch with the indexing flag is enabled / disabled on.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">pid</span><span class="p">,</span> <span class="n">policy_batch</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">policy_batches</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># We assume that arriving batches for recurrent modules OR batches that</span>
            <span class="c1"># have a SEQ_LENS column are already zero-padded to the max sequence length</span>
            <span class="c1"># and have tensors of shape [B, T, ...]. Therefore, we slice sequence</span>
            <span class="c1"># lengths in B. See SampleBatch for more information.</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">[</span><span class="n">pid</span><span class="p">]</span><span class="o">.</span><span class="n">is_stateful</span><span class="p">()</span>
                <span class="ow">or</span> <span class="n">policy_batch</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seq_lens&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="n">value</span><span class="p">:</span>
                    <span class="n">policy_batch</span><span class="o">.</span><span class="n">enable_slicing_by_batch_id</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">policy_batch</span><span class="o">.</span><span class="n">disable_slicing_by_batch_id</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">batch</span>

<div class="viewcode-block" id="Learner._make_module">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner._make_module.html#ray.rllib.core.learner.learner.Learner._make_module">[docs]</a>
    <span class="k">def</span> <span class="nf">_make_module</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MultiRLModule</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Construct the multi-agent RL module for the learner.</span>

<span class="sd">        This method uses `self._module_specs` or `self._module_obj` to construct the</span>
<span class="sd">        module. If the module_class is a single agent RL module it will be wrapped to a</span>
<span class="sd">        multi-agent RL module. Override this method if there are other things that</span>
<span class="sd">        need to happen for instantiation of the module.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A constructed MultiRLModule.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Module was provided directly through constructor -&gt; Use as-is.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_obj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_obj</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_module_spec</span> <span class="o">=</span> <span class="n">MultiRLModuleSpec</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
        <span class="c1"># RLModuleSpec was provided directly through constructor -&gt; Use it to build the</span>
        <span class="c1"># RLModule.</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_spec</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
        <span class="c1"># Try using our config object. Note that this would only work if the config</span>
        <span class="c1"># object has all the necessary space information already in it.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get_multi_rl_module_spec</span><span class="p">()</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>

        <span class="c1"># If not already, convert to MultiRLModule.</span>
        <span class="n">module</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">as_multi_rl_module</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">module</span></div>


<div class="viewcode-block" id="Learner.rl_module_is_compatible">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.rl_module_is_compatible.html#ray.rllib.core.learner.learner.Learner.rl_module_is_compatible">[docs]</a>
    <span class="k">def</span> <span class="nf">rl_module_is_compatible</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">RLModule</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check whether the given `module` is compatible with this Learner.</span>

<span class="sd">        The default implementation checks the Learner-required APIs and whether the</span>
<span class="sd">        given `module` implements all of them (if not, returns False).</span>

<span class="sd">        Args:</span>
<span class="sd">            module: The RLModule to check.</span>

<span class="sd">        Returns:</span>
<span class="sd">            True if the module is compatible with this Learner.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">api</span><span class="p">)</span> <span class="k">for</span> <span class="n">api</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rl_module_required_apis</span><span class="p">())</span></div>


<div class="viewcode-block" id="Learner.rl_module_required_apis">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner.rl_module_required_apis.html#ray.rllib.core.learner.learner.Learner.rl_module_required_apis">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">rl_module_required_apis</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">type</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the required APIs for an RLModule to be compatible with this Learner.</span>

<span class="sd">        The returned values may or may not be used inside the `rl_module_is_compatible`</span>
<span class="sd">        method.</span>

<span class="sd">        Args:</span>
<span class="sd">            module: The RLModule to check.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of RLModule API classes that an RLModule must implement in order</span>
<span class="sd">            to be compatible with this Learner.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[]</span></div>


<div class="viewcode-block" id="Learner._check_registered_optimizer">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner._check_registered_optimizer.html#ray.rllib.core.learner.learner.Learner._check_registered_optimizer">[docs]</a>
    <span class="k">def</span> <span class="nf">_check_registered_optimizer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizer</span><span class="p">,</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Param</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Checks that the given optimizer and parameters are valid for the framework.</span>

<span class="sd">        Args:</span>
<span class="sd">            optimizer: The optimizer object to check.</span>
<span class="sd">            params: The list of parameters to check.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`params` (</span><span class="si">{</span><span class="n">params</span><span class="si">}</span><span class="s2">) must be a list of framework-specific parameters &quot;</span>
                <span class="s2">&quot;(variables)!&quot;</span>
            <span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">_log_trainable_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Logs the number of trainable and non-trainable parameters to self.metrics.</span>

<span class="sd">        Use MetricsLogger (self.metrics) tuple-keys:</span>
<span class="sd">        (ALL_MODULES, NUM_TRAINABLE_PARAMETERS) and</span>
<span class="sd">        (ALL_MODULES, NUM_NON_TRAINABLE_PARAMETERS) with EMA.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>

<div class="viewcode-block" id="Learner._check_is_built">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner._check_is_built.html#ray.rllib.core.learner.learner.Learner._check_is_built">[docs]</a>
    <span class="k">def</span> <span class="nf">_check_is_built</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">error</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">error</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Learner.build() must be called after constructing a &quot;</span>
                    <span class="s2">&quot;Learner and before calling any methods on it.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span></div>


    <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_parameters</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_named_optimizers</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module_optimizers</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_lr_schedules</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="n">MetricsLogger</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_built</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="n">_args</span><span class="p">,</span> <span class="o">**</span><span class="n">_kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">_args</span><span class="p">,</span> <span class="o">**</span><span class="n">_kwargs</span><span class="p">)</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_get_tensor_variable</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trainable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a framework-specific tensor variable with the initial given value.</span>

<span class="sd">        This is a framework specific method that should be implemented by the</span>
<span class="sd">        framework specific sub-classes.</span>

<span class="sd">        Args:</span>
<span class="sd">            value: The initial value for the tensor variable variable.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The framework specific tensor variable of the given initial value,</span>
<span class="sd">            dtype and trainable/requires_grad property.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@staticmethod</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_get_optimizer_lr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the current learning rate of the given local optimizer.</span>

<span class="sd">        Args:</span>
<span class="sd">            optimizer: The local optimizer to get the current learning rate for.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The learning rate value (float) of the given optimizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Learner._set_optimizer_lr">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner._set_optimizer_lr.html#ray.rllib.core.learner.learner.Learner._set_optimizer_lr">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_set_optimizer_lr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizer</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updates the learning rate of the given local optimizer.</span>

<span class="sd">        Args:</span>
<span class="sd">            optimizer: The local optimizer to update the learning rate for.</span>
<span class="sd">            lr: The new learning rate.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="Learner._get_clip_function">
<a class="viewcode-back" href="../../../../../rllib/package_ref/doc/ray.rllib.core.learner.learner.Learner._get_clip_function.html#ray.rllib.core.learner.learner.Learner._get_clip_function">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_get_clip_function</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the gradient clipping function to use.&quot;&quot;&quot;</span></div>


    <span class="nd">@staticmethod</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_get_global_norm_function</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the global norm function to use, given the framework.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_log_steps_trained_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">MultiAgentBatch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Logs this iteration&#39;s steps trained, based on given `batch`.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">mid</span><span class="p">,</span> <span class="n">module_batch</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">policy_batches</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">module_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">module_batch</span><span class="p">)</span>
            <span class="c1"># Log average batch size (for each module).</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                <span class="n">key</span><span class="o">=</span><span class="p">(</span><span class="n">mid</span><span class="p">,</span> <span class="n">MODULE_TRAIN_BATCH_SIZE_MEAN</span><span class="p">),</span>
                <span class="n">value</span><span class="o">=</span><span class="n">module_batch_size</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Log module steps (for each module).</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                <span class="n">key</span><span class="o">=</span><span class="p">(</span><span class="n">mid</span><span class="p">,</span> <span class="n">NUM_MODULE_STEPS_TRAINED</span><span class="p">),</span>
                <span class="n">value</span><span class="o">=</span><span class="n">module_batch_size</span><span class="p">,</span>
                <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
                <span class="n">clear_on_reduce</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                <span class="n">key</span><span class="o">=</span><span class="p">(</span><span class="n">mid</span><span class="p">,</span> <span class="n">NUM_MODULE_STEPS_TRAINED_LIFETIME</span><span class="p">),</span>
                <span class="n">value</span><span class="o">=</span><span class="n">module_batch_size</span><span class="p">,</span>
                <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Log module steps (sum of all modules).</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                <span class="n">key</span><span class="o">=</span><span class="p">(</span><span class="n">ALL_MODULES</span><span class="p">,</span> <span class="n">NUM_MODULE_STEPS_TRAINED</span><span class="p">),</span>
                <span class="n">value</span><span class="o">=</span><span class="n">module_batch_size</span><span class="p">,</span>
                <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
                <span class="n">clear_on_reduce</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
                <span class="n">key</span><span class="o">=</span><span class="p">(</span><span class="n">ALL_MODULES</span><span class="p">,</span> <span class="n">NUM_MODULE_STEPS_TRAINED_LIFETIME</span><span class="p">),</span>
                <span class="n">value</span><span class="o">=</span><span class="n">module_batch_size</span><span class="p">,</span>
                <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="c1"># Log env steps (all modules).</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
            <span class="p">(</span><span class="n">ALL_MODULES</span><span class="p">,</span> <span class="n">NUM_ENV_STEPS_TRAINED</span><span class="p">),</span>
            <span class="n">batch</span><span class="o">.</span><span class="n">env_steps</span><span class="p">(),</span>
            <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
            <span class="n">clear_on_reduce</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">log_value</span><span class="p">(</span>
            <span class="p">(</span><span class="n">ALL_MODULES</span><span class="p">,</span> <span class="n">NUM_ENV_STEPS_TRAINED_LIFETIME</span><span class="p">),</span>
            <span class="n">batch</span><span class="o">.</span><span class="n">env_steps</span><span class="p">(),</span>
            <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
            <span class="n">with_throughput</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@Deprecated</span><span class="p">(</span>
        <span class="n">new</span><span class="o">=</span><span class="s2">&quot;Learner.before_gradient_based_update(&quot;</span>
        <span class="s2">&quot;timesteps={&#39;num_env_steps_sampled_lifetime&#39;: ...}) and/or &quot;</span>
        <span class="s2">&quot;Learner.after_gradient_based_update(&quot;</span>
        <span class="s2">&quot;timesteps={&#39;num_env_steps_sampled_lifetime&#39;: ...})&quot;</span><span class="p">,</span>
        <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">def</span> <span class="nf">additional_update_for_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">new</span><span class="o">=</span><span class="s2">&quot;Learner.save_to_path(...)&quot;</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">save_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">new</span><span class="o">=</span><span class="s2">&quot;Learner.restore_from_path(...)&quot;</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">load_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">new</span><span class="o">=</span><span class="s2">&quot;Learner.module.get_state()&quot;</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">get_module_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">new</span><span class="o">=</span><span class="s2">&quot;Learner.module.set_state()&quot;</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">set_module_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">new</span><span class="o">=</span><span class="s2">&quot;Learner._get_optimizer_state()&quot;</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">get_optimizer_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">new</span><span class="o">=</span><span class="s2">&quot;Learner._set_optimizer_state()&quot;</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">set_optimizer_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="nd">@Deprecated</span><span class="p">(</span><span class="n">new</span><span class="o">=</span><span class="s2">&quot;Learner.compute_losses(...)&quot;</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">losses_per_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_losses</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># To continue supporting the old `compute_loss` behavior (instead of</span>
        <span class="c1"># the new `compute_losses`, add the ALL_MODULES key here holding the sum</span>
        <span class="c1"># of all individual loss terms.</span>
        <span class="k">if</span> <span class="n">ALL_MODULES</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">losses_per_module</span><span class="p">:</span>
            <span class="n">losses_per_module</span><span class="p">[</span><span class="n">ALL_MODULES</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">losses_per_module</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">losses_per_module</span></div>

</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="footer-content-items footer-content__inner">
  
    <div class="footer-content-item"><div id="csat">
  <div id="csat-feedback-received" class="csat-hidden">
    <span>Thanks for the feedback!</span>
  </div>
  <div id="csat-inputs">
    <span>Was this helpful?</span>
    <div id="csat-yes" class="csat-button">
      <svg id="csat-yes-icon" class="csat-hidden csat-icon" width="18" height="13" viewBox="0 0 18 13" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 10.172L16.1922 0.979004L17.6072 2.393L7.00023 13L0.63623 6.636L2.05023 5.222L7.00023 10.172Z" />
      </svg>
      <span>Yes<span>
    </div>
    <div id="csat-no" class="csat-button">
      <svg id="csat-no-icon" class="csat-hidden csat-icon" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 5.58599L11.9502 0.635986L13.3642 2.04999L8.41423 6.99999L13.3642 11.95L11.9502 13.364L7.00023 8.41399L2.05023 13.364L0.63623 11.95L5.58623 6.99999L0.63623 2.04999L2.05023 0.635986L7.00023 5.58599Z" />
      </svg>
      <span>No<span>
    </div>
  </div>
  <div id="csat-textarea-group" class="csat-hidden">
    <span id="csat-feedback-label">Feedback</span>
    <textarea id="csat-textarea"></textarea>
    <div id="csat-submit">Submit</div>
  </div>
</div></div>
  
</div>

          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
      Â© Copyright 2025, The Ray Team.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.14.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>